<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# AutoPipeline

Diffusersã¯æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ã“ã¨ãŒã§ãã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã€ç”»åƒã‹ã‚‰ç”»åƒã€ç”»åƒã®ä¿®å¾©ãªã©ã€è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦åŒã˜ã‚ˆã†ã«äº‹å‰å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ã‚’å†åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã—ã‹ã—ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã€ã©ã®ã‚¿ã‚¹ã‚¯ã«ã©ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ãˆã°ã„ã„ã®ã‹ãŒã‚ã‹ã‚Šã«ãã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã«å¤‰æ›ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ãã‚Œãã‚Œ[`StableDiffusionImg2ImgPipeline`]ã‚¯ãƒ©ã‚¹ã¨[`StableDiffusionInpaintPipeline`]ã‚¯ãƒ©ã‚¹ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã€ç”»åƒã‹ã‚‰ç”»åƒã‚„ç”»åƒã®ä¿®å¾©ã«ã‚‚ä½¿ãˆã‚‹ã“ã¨ã‚’çŸ¥ã‚‰ãªã„å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚

`AutoPipeline` ã‚¯ãƒ©ã‚¹ã¯ã€ğŸ¤— Diffusers ã®æ§˜ã€…ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®æ±ç”¨çš„ã§ã‚¿ã‚¹ã‚¯é‡è¦–ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã£ã¦ã‚¿ã‚¹ã‚¯ãã®ã‚‚ã®ã«é›†ä¸­ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚`AutoPipeline` ã¯ã€ä½¿ç”¨ã™ã‚‹ã¹ãæ­£ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã‚’è‡ªå‹•çš„ã«æ¤œå‡ºã™ã‚‹ãŸã‚ã€ç‰¹å®šã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹åã‚’çŸ¥ã‚‰ãªãã¦ã‚‚ã€ã‚¿ã‚¹ã‚¯ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç°¡å˜ã«ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚

<Tip>

ã©ã®ã‚¿ã‚¹ã‚¯ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ã¯ã€[AutoPipeline](../api/pipelines/auto_pipeline) ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’ã”è¦§ãã ã•ã„ã€‚ç¾åœ¨ã€text-to-imageã€image-to-imageã€inpaintingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

</Tip>

ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€`AutoPipeline` ã‚’ä½¿ç”¨ã—ã¦ã€äº‹å‰ã«å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã‚’è‡ªå‹•çš„ã«æ¨æ¸¬ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

## ã‚¿ã‚¹ã‚¯ã«åˆã‚ã›ã¦AutoPipeline ã‚’é¸æŠã™ã‚‹
ã¾ãšã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸ã¶ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€ [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®å¤‰æ›ã—ãŸã„ãªã‚‰ã€[`AutoPipelineForText2Image`]ã‚’ä½¿ã„ã¾ã™:

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
prompt = "peasant and dragon combat, wood cutting style, viking era, bevel with rune"

image = pipeline(prompt, num_inference_steps=25).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-text2img.png" alt="generated image of peasant fighting dragon in wood cutting style"/>
</div>

[`AutoPipelineForText2Image`] ã‚’å…·ä½“çš„ã«è¦‹ã¦ã„ãã¾ã—ã‚‡ã†:

1. [`model_index.json`](https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json) ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ `"stable-diffusion"` ã‚¯ãƒ©ã‚¹ã‚’è‡ªå‹•çš„ã«æ¤œå‡ºã—ã¾ã™ã€‚
2. `"stable-diffusion"` ã®ã‚¯ãƒ©ã‚¹åã«åŸºã¥ã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸å¤‰æ›ã™ã‚‹ [`StableDiffusionPipeline`] ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

åŒæ§˜ã«ã€ç”»åƒã‹ã‚‰ç”»åƒã¸å¤‰æ›ã™ã‚‹å ´åˆã€[`AutoPipelineForImage2Image`] ã¯ `model_index.json` ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ `"stable-diffusion"` ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡ºã—ã€å¯¾å¿œã™ã‚‹ [`StableDiffusionImg2ImgPipeline`] ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚ã¾ãŸã€å…¥åŠ›ç”»åƒã«ãƒã‚¤ã‚ºã®é‡ã‚„ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚’æ±ºã‚ã‚‹ãŸã‚ã®å¼·ã•ãªã©ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã«å›ºæœ‰ã®è¿½åŠ å¼•æ•°ã‚’æ¸¡ã™ã“ã¨ã‚‚ã§ãã¾ã™:

```py
from diffusers import AutoPipelineForImage2Image
import torch
import requests
from PIL import Image
from io import BytesIO

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True,
).to("cuda")
prompt = "a portrait of a dog wearing a pearl earring"

url = "https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/1665_Girl_with_a_Pearl_Earring.jpg/800px-1665_Girl_with_a_Pearl_Earring.jpg"

response = requests.get(url)
image = Image.open(BytesIO(response.content)).convert("RGB")
image.thumbnail((768, 768))

image = pipeline(prompt, image, num_inference_steps=200, strength=0.75, guidance_scale=10.5).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-img2img.png" alt="generated image of a vermeer portrait of a dog wearing a pearl earring"/>
</div>

ã¾ãŸã€ç”»åƒã®ä¿®å¾©ã‚’è¡Œã„ãŸã„å ´åˆã¯ã€ [`AutoPipelineForInpainting`] ãŒã€åŒæ§˜ã«ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹[`StableDiffusionInpaintPipeline`]ã‚¯ãƒ©ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã™ï¼š

```py
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
import torch

pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = load_image(img_url).convert("RGB")
mask_image = load_image(mask_url).convert("RGB")

prompt = "A majestic tiger sitting on a bench"
image = pipeline(prompt, image=init_image, mask_image=mask_image, num_inference_steps=50, strength=0.80).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-inpaint.png" alt="generated image of a tiger sitting on a bench"/>
</div>

ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚‚ã†ã¨ã™ã‚‹ã¨ã€ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™:

```py
from diffusers import AutoPipelineForImage2Image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "openai/shap-e-img2img", torch_dtype=torch.float16, use_safetensors=True
)
"ValueError: AutoPipeline can't find a pipeline linked to ShapEImg2ImgPipeline for None"
```

## è¤‡æ•°ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹

ã„ãã¤ã‹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚„å¤šãã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’èª­ã¿è¾¼ã‚€å ´åˆã€ä¸è¦ãªãƒ¡ãƒ¢ãƒªã‚’ä½¿ã£ã¦ã—ã¾ã†å†èª­ã¿è¾¼ã¿ã‚’ã™ã‚‹ã‚ˆã‚Šã‚‚ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰åŒã˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å†åˆ©ç”¨ã™ã‚‹æ–¹ãŒãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„ã§ã™ã€‚ãŸã¨ãˆã°ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®å¤‰æ›ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ã„ã€ç”»åƒã‹ã‚‰ç”»åƒã¸ã®å¤‰æ›ã«ã¾ãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ã„ãŸã„å ´åˆã€[from_pipe()](https://huggingface.co/docs/diffusers/v0.25.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe) ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ä»¥å‰èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ã†ã“ã¨ã§è¿½åŠ ã®ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã™ã‚‹ã“ã¨ãªãã€æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚

[from_pipe()](https://huggingface.co/docs/diffusers/v0.25.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe) ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å…ƒã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã‚’æ¤œå‡ºã—ã€å®Ÿè¡Œã—ãŸã„ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®`"stable-diffusion"` ã‚¯ãƒ©ã‚¹ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’èª­ã¿è¾¼ã‚€å ´åˆï¼š

```py
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch

pipeline_text2img = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
print(type(pipeline_text2img))
"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>"
```

ãã—ã¦ã€[from_pipe()] (https://huggingface.co/docs/diffusers/v0.25.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)ã¯ã€ã‚‚ã¨ã®`"stable-diffusion"` ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¯ãƒ©ã‚¹ã§ã‚ã‚‹ [`StableDiffusionImg2ImgPipeline`] ã«ãƒãƒƒãƒ—ã—ã¾ã™:

```py
pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)
print(type(pipeline_img2img))
"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'>"
```
å…ƒã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦å¼•æ•°ï¼ˆã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒã‚§ãƒƒã‚«ãƒ¼ã®ç„¡åŠ¹åŒ–ãªã©ï¼‰ã‚’æ¸¡ã—ãŸå ´åˆã€ã“ã®å¼•æ•°ã‚‚æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«æ¸¡ã•ã‚Œã¾ã™:

```py
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch

pipeline_text2img = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True,
    requires_safety_checker=False,
).to("cuda")

pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)
print(pipeline_img2img.config.requires_safety_checker)
"False"
```

æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å‹•ä½œã‚’å¤‰æ›´ã—ãŸã„å ´åˆã¯ã€å…ƒã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å¼•æ•°ã‚„è¨­å®šã‚’ä¸Šæ›¸ãã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’ã‚ªãƒ³ã«æˆ»ã—ã€`strength` å¼•æ•°ã‚’è¿½åŠ ã—ã¾ã™:

```py
pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img, requires_safety_checker=True, strength=0.3)
print(pipeline_img2img.config.requires_safety_checker)
"True"
```
