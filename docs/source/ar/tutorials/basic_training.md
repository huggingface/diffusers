# ุชุฏุฑูุจ ูููุฐุฌ ุงูุงูุชุดุงุฑ

ุชุนุฏ ุงูุชูููุฏ ุบูุฑ ุงููุดุฑูุท ููุตูุฑ ุชุทุจูููุง ุดุงุฆุนูุง ูููุงุฐุฌ ุงูุงูุชุดุงุฑ ุงูุชู ุชููุฏ ุตูุฑูุง ุชุดุจู ุชูู ุงูููุฌูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ููุชุฏุฑูุจ. ูุนุงุฏุฉ ูุง ูุชู ุงูุญุตูู ุนูู ุฃูุถู ุงููุชุงุฆุฌ ูู ุฎูุงู ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ููุฏุฑุจ ูุณุจููุง ุนูู ูุฌููุนุฉ ุจูุงูุงุช ูุญุฏุฏุฉ. ููููู ุงูุนุซูุฑ ุนูู ุงูุนุฏูุฏ ูู ูุฐู ุงูููุงุท ุงููุฑุฌุนูุฉ ุนูู [Hub](https://huggingface.co/search/full-textุq=unconditional-image-generation&type=model)ุ ูููู ุฅุฐุง ูู ุชุชููู ูู ุงูุนุซูุฑ ุนูู ูุงุญุฏุฉ ุชูุงุณุจูุ ูููููู ุฏุงุฆููุง ุชุฏุฑูุจ ุงููููุฐุฌ ุงูุฎุงุต ุจู!

ุณููุถุญ ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนูููู ููููุฉ ุชุฏุฑูุจ [`UNet2DModel`] ูู ุงูุตูุฑ ุนูู ุฌุฒุก ูู ูุฌููุนุฉ ุจูุงูุงุช [Smithsonian Butterflies](https://huggingface.co/datasets/huggan/smithsonian_butterflies_subset) ูุชูููุฏ ุงููุฑุงุดุงุช ุงูุฎุงุตุฉ ุจู ๐ฆ.

<Tip>

๐ก ูุนุชูุฏ ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนูููู ููุชุฏุฑูุจ ุนูู ุฏูุชุฑ ุงูููุงุญุธุงุช [ุงูุชุฏุฑูุจ ูุน ๐งจ Diffusers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb). ููุญุตูู ุนูู ุชูุงุตูู ูุณูุงู ุฅุถุงูู ุญูู ููุงุฐุฌ ุงูุงูุชุดุงุฑ ูุซู ููููุฉ ุนูููุงุ ุฑุงุฌุน ุฏูุชุฑ ุงูููุงุญุธุงุช!

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ๐ค Datasets ูุชุญููู ูุฌููุนุงุช ุจูุงูุงุช ุงูุตูุฑ ููุนุงูุฌุชูุง ูุณุจููุงุ ู๐ค Accelerateุ ูุชุจุณูุท ุงูุชุฏุฑูุจ ุนูู ุฃู ุนุฏุฏ ูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU). ุณูููู ุงูุฃูุฑ ุงูุชุงูู ุฃูุถูุง ุจุชุซุจูุช [TensorBoard](https://www.tensorflow.org/tensorboard) ูุชุตูุฑ ููุงููุณ ุงูุชุฏุฑูุจ (ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู [Weights & Biases](https://docs.wandb.ai/) ูุชุชุจุน ุงูุชุฏุฑูุจ ุงูุฎุงุต ุจู).

```py
# ูู ุจุฅูุบุงุก ุงูุชุนููู ูุชุซุจูุช ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ ูู Colab
#! pip install diffusers [training]
```

ูุญู ูุดุฌุนู ุนูู ูุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุนุ ูููููุงู ุจุฐููุ ุณุชุญุชุงุฌ ุฅูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู (ูู ุจุฅูุดุงุก ูุงุญุฏ [ููุง](https://hf.co/join) ุฅุฐุง ูู ููู ูุฏูู ูุงุญุฏ ุจุงููุนู!). ููููู ุชุณุฌูู ุงูุฏุฎูู ูู ุฏูุชุฑ ุงูููุงุญุธุงุช ูุฅุฏุฎุงู ุฑูุฒู ุนูุฏ ุงููุทุงูุจุฉ. ุชุฃูุฏ ูู ุฃู ูุฏูู ุฏูุฑ ุงููุชุงุจุฉ.

```py copy
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

ุฃู ุชุณุฌูู ุงูุฏุฎูู ูู ุงููุญุทุฉ ุงูุทุฑููุฉ:

```bash copy
huggingface-cli login
```

ูุธุฑูุง ูุฃู ููุงุท ุงูุชุญูู ูู ุงููููุฐุฌ ูุจูุฑุฉ ุฌุฏูุงุ ููู ุจุชุซุจูุช [Git-LFS](https://git-lfs.com/) ูุฅุตุฏุงุฑ ูุฐู ุงููููุงุช ุงููุจูุฑุฉ:

```bash copy
! sudo apt -qq install git-lfs
! git config --global credential.helper store
```

## ุชูููู ุงูุชุฏุฑูุจ

ููุฑุงุญุฉุ ูู ุจุฅูุดุงุก ูุฆุฉ `TrainingConfig` ุชุญุชูู ุนูู ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ (ููููู ุถุจุทูุง ุญุณุจ ุฑุบุจุชู):

```py copy
>>> from dataclasses import dataclass

>>> @ dataclass
... class TrainingConfig:
... image_size = 128 # ุฏูุฉ ุงูุตูุฑุฉ ุงููููุฏุฉ
... train_batch_size = 16
... eval_batch_size = 16 # ุนุฏุฏ ุงูุตูุฑ ุงูุชู ุณูุชู ุฃุฎุฐ ุนููุงุช ูููุง ุฃุซูุงุก ุงูุชูููู
... num_epochs = 50
... gradient_accumulation_steps = 1
... learning_rate = 1e-4
... lr_warmup_steps = 500
... save_image_epochs = 10
... save_model_epochs = 30
... mixed_precision = "fp16" # `no` ูู float32ุ `fp16` ูู automatic mixed precision
... output_dir = "ddpm-butterflies-128" # ุงุณู ุงููููุฐุฌ ูุญูููุง ูุนูู HF Hub

... push_to_hub = True # ูุง ุฅุฐุง ูุงู ุณูุชู ุชุญููู ุงููููุฐุฌ ุงููุญููุธ ุฅูู HF Hub
... hub_model_id = "<your-username>/<my-awesome-model>" # ุงุณู ุงููุณุชูุฏุน ุงูุฐู ุณูุชู ุฅูุดุงุคู ุนูู HF Hub
... hub_private_repo = False
... overwrite_output_dir = True # ุงููุชุงุจุฉ ููู ุงููููุฐุฌ ุงููุฏูู ุนูุฏ ุฅุนุงุฏุฉ ุชุดุบูู ุฏูุชุฑ ุงูููุงุญุธุงุช
... seed = 0


>>> config = TrainingConfig()
```

## ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช

ููููู ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [Smithsonian Butterflies](https://huggingface.co/datasets/huggan/smithsonian_butterflies_subset) ุจุณูููุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค Datasets:

```py copy
>>> from datasets import load_dataset

>>> config.dataset_name = "huggan/smithsonian_butterflies_subset"
>>> dataset = load_dataset(config.dataset_name, split = "train")
```

<Tip>

๐ก ููููู ุงูุนุซูุฑ ุนูู ูุฌููุนุงุช ุจูุงูุงุช ุฅุถุงููุฉ ูู [ุญุฏุซ HugGan Community](https://huggingface.co/huggan) ุฃู ููููู ุงุณุชุฎุฏุงู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุนู ุทุฑูู ุฅูุดุงุก [`ImageFolder`](https://huggingface.co/docs/datasets/image_dataset#imagefolder)ูุญูู. ูู ุจุชุนููู `config.dataset_name` ุฅูู ูุนุฑู ุงููุณุชูุฏุน ููุฌููุนุฉ ุงูุจูุงูุงุช ุฅุฐุง ูุงูุช ูู ุญุฏุซ HugGan Communityุ ุฃู `imagefolder` ุฅุฐุง ููุช ุชุณุชุฎุฏู ุตูุฑู ุงูุฎุงุตุฉ.

</Tip>

ูุณุชุฎุฏู ๐ค Datasets ููุฒุฉ [`~ datasets.Image`] ููู ุชุฑููุฒ ุจูุงูุงุช ุงูุตูุฑุฉ ูุชุญููููุง ูู [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html) ูุงูุชู ูููููุง ุชุตูุฑูุง:

```py copy
>>> import matplotlib.pyplot as plt

>>> fig, axs = plt.subplots (1, 4, figsize = (16, 4))
>>> for i, image in enumerate(dataset [: 4]["image"]):
...     axs[i].imshow(image)
...     axs[i].set_axis_off()
>>> fig.show()
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/butterflies_ds.png"/>
</div>

ููุน ุฐููุ ูุฅู ุงูุตูุฑ ุจุฃุญุฌุงู ูุฎุชููุฉุ ูุฐูู ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌุชูุง ูุณุจููุง:

* `Resize` ูุบูุฑ ุญุฌู ุงูุตูุฑุฉ ุฅูู ุงูุญุฌู ุงููุญุฏุฏ ูู `config.image_size`.
* `RandomHorizontalFlip` ูุฒูุฏ ูู ุญุฌู ูุฌููุนุฉ ุงูุจูุงูุงุช ุนู ุทุฑูู ุนูุณ ุงูุตูุฑ ุจุดูู ุนุดูุงุฆู.
* `Normalize` ููู ูุฅุนุงุฏุฉ ุชุญุฌูู ููู ุงูุจูุณู ุฅูู ูุทุงู [-1ุ 1]ุ ููู ูุง ูุชููุนู ุงููููุฐุฌ.

```py copy
>>> from torchvision import transforms

>>> preprocess = transforms.Compose(
         [
         transforms.Resize((config.image_size, config.image_size)),
         transforms.RandomHorizontalFlip(),
         transforms.ToTensor(),
         transforms.Normalize([0.5], [0.5]),
         ]
     )
```

ุงุณุชุฎุฏู ุทุฑููุฉ [`~ datasets.Dataset.set_transform`] ูู ๐ค Datasets ูุชุทุจูู ูุธููุฉ `preprocess` ุฃุซูุงุก ุงูุชููู ุฃุซูุงุก ุงูุชุฏุฑูุจ:

```py copy
>>> def transform (examples):
... images = [preprocess (image.convert ("RGB")) for image in examples ["image"]]
... return {"images": images}


>>> dataset.set_transform (transform)
```

ูุง ุชุชุฑุฏุฏ ูู ุชุตูุฑ ุงูุตูุฑ ูุฑุฉ ุฃุฎุฑู ููุชุฃูุฏ ูู ุชุบููุฑ ุญุฌููุง. ุงูุขู ุฃูุช ูุณุชุนุฏ ูุชุบููู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู [DataLoader](https://pytorch.org/docs/stable/data#torch.utils.data.DataLoader) ููุชุฏุฑูุจ!

```py copy
>>> import torch

>>> train_dataloader = torch.utils.data.DataLoader (datasetุ batch_size = config.train_batch_sizeุ shuffle = True)
```

## ุฅูุดุงุก UNet2DModel

ูู ุงูุณูู ุฅูุดุงุก ููุงุฐุฌ ููุฏุฑุจุฉ ูุณุจููุง ูู ๐งจ Diffusers ูู ูุฆุฉ ุงููููุฐุฌ ุงูุฎุงุตุฉ ุจูุง ุจุงุณุชุฎุฏุงู ุงููุนููุงุช ุงูุชู ุชุฑูุฏูุง. ุนูู ุณุจูู ุงููุซุงูุ ูุฅูุดุงุก [`UNet2DModel`]:

```py copy
>>> from diffusers import UNet2DModel

>>> model = UNet2DModel (
... sample_size = config.image_sizeุ # ุฏูุฉ ุงูุตูุฑุฉ ุงููุณุชูุฏูุฉ
... in_channels = 3ุ # ุนุฏุฏ ูููุงุช ุงูุฅุฏุฎุงูุ 3 ููุตูุฑ RGB
... out_channels = 3ุ # ุนุฏุฏ ูููุงุช ุงูุฅุฎุฑุงุฌ
... layers_per_block = 2ุ # ุนุฏุฏ ุทุจูุงุช ResNet ุงููุณุชุฎุฏูุฉ ููู ูุชูุฉ UNet
... block_out_channels = (128ุ 128ุ 256ุ 256ุ 512ุ 512)ุ # ุนุฏุฏ ูููุงุช ุงูุฅุฎุฑุงุฌ ููู ูุชูุฉ UNet
... down_block_types = (
... "DownBlock2D"ุ # ูุชูุฉ ุงูุฎูุงุถ ResNet ุงูุนุงุฏูุฉ
... "DownBlock2D"ุ
... "DownBlock2D"ุ
... "DownBlock2D"ุ
... "AttnDownBlock2D"ุ # ูุชูุฉ ุงูุฎูุงุถ ResNet ูุน ุงูุงูุชุจุงู ุงูููุงูู ุงูุฐุงุชู
... "DownBlock2D"ุ
... )ุ
... up_block_types = (
... "UpBlock2D"ุ # ูุชูุฉ ResNet ุนุงุฏูุฉ
... "AttnUpBlock2D"ุ # ูุชูุฉ ResNet ูุน ุงูุงูุชุจุงู ุงูููุงูู ุงูุฐุงุชู
... "UpBlock2D"ุ
... "UpBlock2D"ุ
... "UpBlock2D"ุ
... "UpBlock2D"ุ
... )ุ
... )
```

ุบุงูุจูุง ูุง ูููู ูู ุงูุฌูุฏ ุงูุชุญูู ุจุณุฑุนุฉ ูู ุฃู ุดูู ุตูุฑุฉ ุงูุฅุฏุฎุงู ูุชุทุงุจู ูุน ุดูู ุฅุฎุฑุงุฌ ุงููููุฐุฌ:

```py copy
>>> sample_image = dataset [0] ["images"].unsqueeze (0)
>>> print ("input shape:"ุ sample_image.shape)
imnput shape: torch.Size ([1ุ 3ุ 128ุ 128])

>>> print ("output shape:"ุ model (sample_imageุ timestep = 0). sample.shape)
output shape: torch.Size ([1ุ 3ุ 128ุ 128])
```

ุฑุงุฆุน! ุจุนุฏ ุฐููุ ุณุชุญุชุงุฌ ุฅูู ุฌุฏูู ุฒููู ูุฅุถุงูุฉ ุจุนุถ ุงูุถูุถุงุก ุฅูู ุงูุตูุฑุฉ.

## ุฅูุดุงุก ุฌุฏูู ุฒููู

ูุชุตุฑู ุงูุฌุฏูู ุงูุฒููู ุจุดูู ูุฎุชูู ุงุนุชูุงุฏูุง ุนูู ูุง ุฅุฐุง ููุช ุชุณุชุฎุฏู ุงููููุฐุฌ ููุชุฏุฑูุจ ุฃู ุงูุงุณุชุฏูุงู. ุฃุซูุงุก ุงูุงุณุชุฏูุงูุ ูููู ุงูุฌุฏูู ุงูุฒููู ุจุชูููุฏ ุงูุตูุฑุฉ ูู ุงูุถูุถุงุก. ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูุฃุฎุฐ ุงูุฌุฏูู ุงูุฒููู ุฅุฎุฑุงุฌ ุงููููุฐุฌ - ุฃู ุนููุฉ - ูู ููุทุฉ ูุญุฏุฏุฉ ูู ุนูููุฉ ุงูุงูุชุดุงุฑ ููุถูู ุถูุถุงุก ุฅูู ุงูุตูุฑุฉ ููููุง ูู *ุฌุฏูู ุฒููู ููุถูุถุงุก* ู *ูุงุนุฏุฉ ุชุญุฏูุซ*.

ุฏุนููุง ูููู ูุธุฑุฉ ุนูู [`DDPMScheduler`] ูุงุณุชุฎุฏุงู ุทุฑููุฉ `add_noise` ูุฅุถุงูุฉ ุจุนุถ ุงูุถูุถุงุก ุงูุนุดูุงุฆูุฉ ุฅูู `sample_image` ูู ูุจู:

```py copy
>>> import torch
>>> from PIL import Image
>>> from diffusers import DDPMScheduler

>>> noise_scheduler = DDPMScheduler (num_train_timesteps = 1000)
>>> noise = torch.randn (sample_image.shape)
>>> timesteps = torch.LongTensor ([50])
>>> noisy_image = noise_scheduler.add_noise (sample_imageุ noiseุ timesteps)

>>> Image.fromarray (((noisy_image.permute (0ุ 2ุ 3ุ 1) + 1.0) * 127.5). type (torch.uint8). numpy () [0])
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/noisy_butterfly.png"/>
</div>

ุงููุฏู ูู ุงูุชุฏุฑูุจ ุนูู ุงููููุฐุฌ ูู ุงูุชูุจุค ุจุงูุถูุถุงุก ุงููุถุงูุฉ ุฅูู ุงูุตูุฑุฉ. ูููู ุญุณุงุจ ุงูุฎุณุงุฑุฉ ูู ูุฐู ุงูุฎุทูุฉ ุนูู ุงููุญู ุงูุชุงูู:

```py copy
>>> import torch.nn.functional as F

>>> noise_pred = model (noisy_imageุ timesteps). sample
>>> loss = F.mse_loss (noise_predุ noise)
```
## ุชุฏุฑูุจ ุงููููุฐุฌ

ุงูุขูุ ูุฏูู ูุนุธู ุงููุทุน ุงููุงุฒูุฉ ูุจุฏุก ุชุฏุฑูุจ ุงููููุฐุฌ ููู ูุง ุชุจูู ูู ุฌูุน ูู ุดูุก ูุนูุง.

ุฃููุงูุ ุณุชุญุชุงุฌ ุฅูู ูุญุณู ููุฎุทุท ููุนุฏู ุงูุชุนูู:

```py
>>> from diffusers.optimization import get_cosine_schedule_with_warmup

>>> optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)
>>> lr_scheduler = get_cosine_schedule_with_warmup(
...     optimizer=optimizer,
...     num_warmup_steps=config.lr_warmup_steps,
...     num_training_steps=(len(train_dataloader) * config.num_epochs),
... )
```


ุซูุ ุณุชุญุชุงุฌ ุฅูู ุทุฑููุฉ ูุชูููู ุงููููุฐุฌ. ููุชููููุ ููููู ุงุณุชุฎุฏุงู [`DDPMPipeline`] ูุชูููุฏ ุฏูุนุฉ ูู ุงูุตูุฑ ุงููููุฐุฌูุฉ ูุญูุธูุง ูุดุจูุฉ:

```py
>>> from diffusers import DDPMPipeline
>>> from diffusers.utils import make_image_grid
>>> import os

>>> def evaluate(config, epoch, pipeline):
...     # Sample some images from random noise (this is the backward diffusion process).
...     # The default pipeline output type is `List[PIL.Image]`
...     images = pipeline(
...         batch_size=config.eval_batch_size,
...         generator=torch.Generator(device='cpu').manual_seed(config.seed), # Use a separate torch generator to avoid rewinding the random state of the main training loop
...     ).images

...     # Make a grid out of the images
...     image_grid = make_image_grid(images, rows=4, cols=4)

...     # Save the images
...     test_dir = os.path.join(config.output_dir, "samples")
...     os.makedirs(test_dir, exist_ok=True)
...     image_grid.save(f"{test_dir}/{epoch:04d}.png")
```

ุงูุขู ููููู ูู ูู ูุฐู ุงูููููุงุช ูุนูุง ูู ุญููุฉ ุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ๐ค Accelerate ูุชุณุฌูู TensorBoard ุณููุ ูุชุฑุงูู ุงูุชุฏุฑุฌุงุชุ ูุงูุชุฏุฑูุจ ุนูู ุงูุฏูุฉ ุงููุฎุชูุทุฉ. ูุชุญููู ุงููููุฐุฌ ุฅูู Hubุ ูู ุจูุชุงุจุฉ ุฏุงูุฉ ููุญุตูู ุนูู ุงุณู ูุณุชูุฏุนู ููุนูููุงุชูุ ุซู ูู ุจุงูุฏูุน ุฅูู Hub.

<Tip>
๐ก ูุฏ ุชุจุฏู ุญููุฉ ุงูุชุฏุฑูุจ ุฃุฏูุงู ูุฎููุฉ ูุทูููุฉุ ูููููุง ุณุชููู ุฌุฏูุฑุฉ ุจุงูุงูุชูุงู ูุงุญููุง ุนูุฏูุง ุชุทูู ุงูุชุฏุฑูุจ ูู ุณุทุฑ ูุงุญุฏ ููุท ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ! ุฅุฐุง ูู ุชุชููู ูู ุงูุงูุชุธุงุฑ ูููุช ุชุฑูุฏ ุงูุจุฏุก ูู ุฅูุดุงุก ุงูุตูุฑุ ููุง ุชุชุฑุฏุฏ ูู ูุณุฎ ููุตู ูุชุดุบูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุฏูุงู. ููููู ุฏุงุฆููุง ุงูุนูุฏุฉ ููุญุต ุญููุฉ ุงูุชุฏุฑูุจ ุนู ูุซุจ ูุงุญููุงุ ูุซู ุนูุฏูุง ุชูุชุธุฑ ูููุฐุฌู ูุฅููุงุก ุงูุชุฏุฑูุจ. ๐ค
</Tip>

```py
>>> from accelerate import Accelerator
>>> from huggingface_hub import create_repo, upload_folder
>>> from tqdm.auto import tqdm
>>> from pathlib import Path
>>> import os

>>> def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler):
...     # Initialize accelerator and tensorboard logging
...     accelerator = Accelerator(
...         mixed_precision=config.mixed_precision,
...         gradient_accumulation_steps=config.gradient_accumulation_steps,
...         log_with="tensorboard",
...         project_dir=os.path.join(config.output_dir, "logs"),
...     )
...     if accelerator.is_main_process:
...         if config.output_dir is not None:
...             os.makedirs(config.output_dir, exist_ok=True)
...         if config.push_to_hub:
...             repo_id = create_repo(
...                 repo_id=config.hub_model_id or Path(config.output_dir).name, exist_ok=True
...             ).repo_id
...         accelerator.init_trackers("train_example")

...     # Prepare everything
...     # There is no specific order to remember, you just need to unpack the
...     # objects in the same order you gave them to the prepare method.
...     model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
...         model, optimizer, train_dataloader, lr_scheduler
...     )

...     global_step = 0

...     # Now you train the model
...     for epoch in range(config.num_epochs):
...         progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)
...         progress_bar.set_description(f"Epoch {epoch}")

...         for step, batch in enumerate(train_dataloader):
...             clean_images = batch["images"]
...             # Sample noise to add to the images
...             noise = torch.randn(clean_images.shape, device=clean_images.device)
...             bs = clean_images.shape[0]

...             # Sample a random timestep for each image
...             timesteps = torch.randint(
...                 0, noise_scheduler.config.num_train_timesteps, (bs,), device=clean_images.device,
...                 dtype=torch.int64
...             )

...             # Add noise to the clean images according to the noise magnitude at each timestep
...             # (this is the forward diffusion process)
...             noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)

...             with accelerator.accumulate(model):
...                 # Predict the noise residual
...                 noise_pred = model(noisy_images, timesteps, return_dict=False)[0]
...                 loss = F.mse_loss(noise_pred, noise)
...                 accelerator.backward(loss)

...                 accelerator.clip_grad_norm_(model.parameters(), 1.0)
...                 optimizer.step()
...                 lr_scheduler.step()
...                 optimizer.zero_grad()

...             progress_bar.update(1)
...             logs = {"loss": loss.detach().item(), "lr": lr_scheduler.get_last_lr()[0], "step": global_step}
...             progress_bar.set_postfix(**logs)
...             accelerator.log(logs, step=global_step)
...             global_step += 1

...         # After each epoch you optionally sample some demo images with evaluate() and save the model
...         if accelerator.is_main_process:
...             pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)

...             if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:
...                 evaluate(config, epoch, pipeline)

...             if (epoch + 1) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:
...                 if config.push_to_hub:
...                     upload_folder(
...                         repo_id=repo_id,
...                         folder_path=config.output_dir,
...                         commit_message=f"Epoch {epoch}",
...                         ignore_patterns=["step_*", "epoch_*"],
...                     )
...                 else:
...                     pipeline.save_pretrained(config.output_dir)
```


Phewุ ูุงู ูุฐุง ุงููุซูุฑ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ! ููููู ุฃุฎูุฑูุง ูุณุชุนุฏ ูุฅุทูุงู ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ูุธููุฉ [`~accelerate.notebook_launcher`] ูู ๐ค Accelerate. ูู ุจุชูุฑูุฑ ุงูุฏุงูุฉ ุญููุฉ ุงูุชุฏุฑูุจุ ูุฌููุน ุงูุญุฌุฌ ุงูุชุฏุฑูุจุ ูุนุฏุฏ ุงูุนูููุงุช (ููููู ุชุบููุฑ ูุฐู ุงููููุฉ ุฅูู ุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงููุชููุฑุฉ ูุฏูู) ูุงุณุชุฎุฏุงููุง ูู ุงูุชุฏุฑูุจ:

```py
>>> from accelerate import notebook_launcher

>>> args = (config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)

>>> notebook_launcher(train_loop, args, num_processes=1)
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุงูู ูุธุฑุฉ ุนูู ุงูุตูุฑ ุงูููุงุฆูุฉ ๐ฆ ุงูุชู ุชู ุฅูุดุงุคูุง ุจูุงุณุทุฉ ูููุฐุฌ ุงูุงูุชุดุงุฑ ุงูุฎุงุต ุจู!


```py
>>> import glob

>>> sample_images = sorted(glob.glob(f"{config.output_dir}/samples/*.png"))
>>> Image.open(sample_images[-1])
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/butterflies_final.png"/>
</div>

## ุงูุฎุทูุงุช ุงูุชุงููุฉ

ูุนุฏ ุฅูุดุงุก ุงูุตูุฑ ุบูุฑ ุงููุดุฑูุท ูุซุงููุง ูุงุญุฏูุง ุนูู ุงููููุฉ ุงูุชู ูููู ุชุฏุฑูุจูุง. ููููู ุงุณุชูุดุงู ููุงู ูุชูููุงุช ุชุฏุฑูุจ ุฃุฎุฑู ูู ุฎูุงู ุฒูุงุฑุฉ ุตูุญุฉ [๐งจ ุฃูุซูุฉ ุงูุชุฏุฑูุจ ุนูู Diffusers](../training/overview). ูููุง ููู ุจุนุถ ุงูุฃูุซูุฉ ุนูู ูุง ููููู ุชุนููู:

* [ุงูุนูุณ ุงููุตู](../training/text_inversion)ุ ููู ุฎูุงุฑุฒููุฉ ุชุนูู ุงููููุฐุฌ ููููููุง ุจุตุฑููุง ูุญุฏุฏูุง ูุชูุงููู ูู ุงูุตูุฑุฉ ุงููููุฏุฉ.
* [DreamBooth](../training/dreambooth)ุ ููู ุชูููุฉ ูุชูููุฏ ุตูุฑ ุดุฎุตูุฉ ูููุถูุน ูุนูู ุจูุงุกู ุนูู ุนุฏุฉ ุตูุฑ ุฅุฏุฎุงู ููููุถูุน.
* [ุฏููู](../training/text2image) ุฅูู ุถุจุท ูููุฐุฌ ุงูุงูุชุดุงุฑ ุงููุณุชูุฑ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู.
* [ุฏููู](../training/lora) ูุงุณุชุฎุฏุงู LoRAุ ููู ุชูููุฉ ูุนุงูุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ูุถุจุท ุงูููุงุฐุฌ ุงููุจูุฑุฉ ุฌุฏูุง ุจุดูู ุฃุณุฑุน.