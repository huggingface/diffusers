# ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ

[[open-in-colab]]

ØªØ¹Ø¯ Ù†Ù…Ø§Ø°Ø¬ ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§Øª. ÙŠØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ 2.0 Ù…Ø´ÙØ±ÙŠÙ† Ù†ØµÙŠÙŠÙ† Ù…ØªØ¹Ø¯Ø¯ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª ÙˆÙŠÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ ØªÙ„Ùƒ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù€ UNet.

ÙŠØºÙŠØ± [ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ 2.1] (../ api/pipelines/kandinsky) Ø§Ù„Ø¨Ù†ÙŠØ© Ù„ØªØ¶Ù…ÙŠÙ† Ù†Ù…ÙˆØ°Ø¬ ØµÙˆØ±Ø© Ø£ÙˆÙ„ÙŠØ© ([` CLIP `](https://huggingface.co/docs/transformers/model_doc/clip)) Ù„ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ ÙˆØªØ¶Ù…ÙŠÙ† Ø§Ù„ØµÙˆØ±. ØªÙˆÙØ± Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ù…Ø­Ø§Ø°Ø§Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© ÙˆÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù…Ø¹ ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†Øµ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ù…Ù…Ø§ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©. ÙˆØ£Ø®ÙŠØ±Ù‹Ø§ØŒ ÙŠØ³ØªØ®Ø¯Ù… ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ 2.1 [Ù…Ø´ÙØ±Ù‹Ø§ Ù„Ù€ Modulating Quantized Vectors (MoVQ)](https://huggingface.co/papers/2209.09002) - ÙˆØ§Ù„Ø°ÙŠ ÙŠØ¶ÙŠÙ Ø·Ø¨Ù‚Ø© ØªØ·Ø¨ÙŠØ¹ Ø´Ø±Ø·ÙŠ Ù…ÙƒØ§Ù†ÙŠ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ© - Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„ÙƒÙ…ÙˆÙ†Ø§Øª Ø¥Ù„Ù‰ ØµÙˆØ±.

ÙŠØ­Ø³Ù† [ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ 2.2] (../ api/pipelines/kandinsky_v22) Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù…Ø´ÙØ± Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¨Ù†Ù…ÙˆØ°Ø¬ CLIP-ViT-G Ø£ÙƒØ¨Ø± Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©. ÙƒÙ…Ø§ Ø£Ø¹ÙŠØ¯ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¹Ù„Ù‰ ØµÙˆØ± Ø¨Ø¯Ù‚Ø© ÙˆØ¬ÙˆØ§Ù†Ø¨ Ù…Ø®ØªÙ„ÙØ© Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚Ø© ÙˆØ£Ø­Ø¬Ø§Ù… ØµÙˆØ± Ù…Ø®ØªÙ„ÙØ©.

ÙŠØ¨Ø³Ø· [ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ 3] (../ api/pipelines/kandinsky3) Ø§Ù„Ø¨Ù†ÙŠØ© ÙˆÙŠÙ†ØªÙ‚Ù„ Ø¨Ø¹ÙŠØ¯Ù‹Ø§ Ø¹Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø°Ø§Øª Ø§Ù„Ù…Ø±Ø­Ù„ØªÙŠÙ† Ø§Ù„ØªÙŠ ØªØªØ¶Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙˆÙ†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙŠØ³ØªØ®Ø¯Ù… Kandinsky 3 [Flan-UL2](https://huggingface.co/google/flan-ul2) Ù„ØªØ´ÙÙŠØ± Ø§Ù„Ù†ØµØŒ Ùˆ UNet Ù…Ø¹ [BigGan-deep](https://hf.co/papers/1809.11096) blocksØŒ Ùˆ [Sber-MoVQGAN](https://github.com/ai-forever/MoVQGAN) Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„ÙƒÙ…ÙˆÙ†Ø§Øª Ø¥Ù„Ù‰ ØµÙˆØ±. ÙŠØªÙ… ØªØ­Ù‚ÙŠÙ‚ ÙÙ‡Ù… Ø§Ù„Ù†Øµ ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø´ÙØ± Ù†ØµÙŠ ÙˆØ´Ø¨ÙƒØ© UNet Ø£ÙƒØ¨Ø±.

Ø³ÙŠÙˆØ¶Ø­ Ù„Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ Ù„Ù„Ù…Ù‡Ø§Ù… Ù…Ø«Ù„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©ØŒ ÙˆØ§Ù„Ø·Ù„Ø§Ø¡ØŒ ÙˆØ§Ù„ØªÙ†Ù‚Ù„ØŒ ÙˆØ§Ù„Ù…Ø²ÙŠØ¯.

Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:

```py
# Ù‚Ù… Ø¨Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ© ÙÙŠ Colab
#! pip install -q diffusers transformers accelerate
```

<Tip warning={true}>

ÙŠØ¹Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Kandinsky 2.1 Ùˆ 2.2 Ù…ØªØ´Ø§Ø¨Ù‡Ù‹Ø§ Ø¬Ø¯Ù‹Ø§! Ø§Ù„ÙØ±Ù‚ Ø§Ù„ÙˆØ­ÙŠØ¯ Ù‡Ùˆ Ø£Ù† Kandinsky 2.2 Ù„Ø§ ÙŠÙ‚Ø¨Ù„ `prompt` ÙƒØ¥Ø¯Ø®Ø§Ù„ Ø¹Ù†Ø¯ ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ÙƒÙ…ÙˆÙ†Ø§Øª. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙŠÙ‚Ø¨Ù„ Kandinsky 2.2 ÙÙ‚Ø· `image_embeds` Ø£Ø«Ù†Ø§Ø¡ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±.

<br>

Ù„Ø¯Ù‰ Kandinsky 3 Ø¨Ù†ÙŠØ© Ø£ÙƒØ«Ø± Ø¥Ø­ÙƒØ§Ù…Ø§ ÙˆÙ„Ø§ ÙŠØªØ·Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ø£ÙˆÙ„ÙŠÙ‹Ø§. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ø§Ù„Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„ [Stable Diffusion XL] (sdxl).

</Tip>

## Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØ±Ø©

Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ ÙƒØ§Ù†Ø¯ÙŠÙ†Ø³ÙƒÙŠ Ù„Ø£ÙŠ Ù…Ù‡Ù…Ø©ØŒ Ø§Ø¨Ø¯Ø£ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„ØªØ´ÙÙŠØ± Ø§Ù„ÙÙƒØ±Ø© ÙˆØªÙˆÙ„ÙŠØ¯ ØªØ¶Ù…ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©. ÙƒÙ…Ø§ ÙŠÙ‚ÙˆÙ… Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨ØªÙˆÙ„ÙŠØ¯ `negative_image_embeds` Ø§Ù„ØªÙŠ ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø³Ù„Ø¨ÙŠØ© `""`. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± `negative_prompt` Ø§Ù„ÙØ¹Ù„ÙŠ Ø¥Ù„Ù‰ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØŒ ÙˆÙ„ÙƒÙ† Ù‡Ø°Ø§ Ø³ÙŠØ²ÙŠØ¯ Ù…Ù† Ø­Ø¬Ù… Ø¯ÙØ¹Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø§Ù„ÙØ¹Ø§Ù„Ø© Ø¨Ù…Ù‚Ø¯Ø§Ø± 2x.

<hfoptions id="text-to-image">
<hfoption id="Kandinsky 2.1">

```py
from diffusers import KandinskyPriorPipeline, KandinskyPipeline
import torch

prior_pipeline = KandinskyPriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16).to("cuda")
pipeline = KandinskyPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16).to("cuda")

prompt = "A alien cheeseburger creature eating itself, claymation, cinematic, moody lighting"
negative_prompt = "low quality, bad quality" # optional to include a negative prompt, but results are usually better
image_embeds, negative_image_embeds = prior_pipeline(prompt, negative_prompt, guidance_scale=1.0).to_tuple()
```

Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø¥Ù„Ù‰ [`KandinskyPipeline`] Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©:

```py
image = pipeline(prompt, image_embeds=image_embeds, negative_prompt=negative_prompt, negative_image_embeds=negative_image_embeds, height=768, width=768).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinsky-docs/cheeseburger.png"/>
</div>

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
from diffusers import KandinskyV22PriorPipeline, KandinskyV22Pipeline
import torch

prior_pipeline = KandinskyV22PriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16).to("cuda")
pipeline = KandinskyV22Pipeline.from_pretrained("kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16).to("cuda")

prompt = "A alien cheeseburger creature eating itself, claymation, cinematic, moody lighting"
negative_prompt = "low quality, bad quality" # optional to include a negative prompt, but results are usually better
image_embeds, negative_image_embeds = prior_pipeline(prompt, guidance_scale=1.0).to_tuple()
```

Ù…Ø±Ø± `image_embeds` Ùˆ` negative_image_embeds` Ø¥Ù„Ù‰ [`KandinskyV22Pipeline`] Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©:

```py
image = pipeline(image_embeds=image_embeds, negative_image_embeds=negative_image_embeds, height=768, width=768).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinsky-text-to-image.png"/>
</div>

</hfoption>
<hfoption id="Kandinsky 3">

Ù„Ø§ ÙŠØªØ·Ù„Ø¨ Kandinsky 3 Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ø£ÙˆÙ„ÙŠÙ‹Ø§ØŒ Ù„Ø°Ø§ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ [`Kandinsky3Pipeline`] Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆØªÙ…Ø±ÙŠØ± ÙÙƒØ±Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©:

```py
from diffusers import Kandinsky3Pipeline
import torch

pipeline = Kandinsky3Pipeline.from_pretrained("kandinsky-community/kandinsky-3", variant="fp16", torch_dtype=torch.float16)
pipeline.enable_model_cpu_offload()

prompt = "A alien cheeseburger creature eating itself, claymation, cinematic, moody lighting"
image = pipeline(prompt).images[0]
image
```

</hfoption>
</hfoptions>

ÙŠÙˆÙØ± ğŸ¤— Diffusers Ø£ÙŠØ¶Ù‹Ø§ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ [`KandinskyCombinedPipeline`] Ùˆ [`KandinskyV22CombinedPipeline`]ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ù„Ø§ ÙŠÙ„Ø²Ù… ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙˆØ®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„. ÙŠÙ‚ÙˆÙ… Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø¬Ù…Ø¹ Ø¨ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙˆÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§. Ù„Ø§ ÙŠØ²Ø§Ù„ Ø¨Ø¥Ù…ÙƒØ§Ù†Ùƒ ØªØ¹ÙŠÙŠÙ† Ù‚ÙŠÙ… Ù…Ø®ØªÙ„ÙØ© Ù„Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø§Øª `prior_guidance_scale` Ùˆ` prior_num_inference_steps` Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø°Ù„Ùƒ.

Ø§Ø³ØªØ®Ø¯Ù… [`AutoPipelineForText2Image`] Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§:

<hfoptions id="text-to-image">
<hfoption id="Kandinsky 2.1">

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16)
pipeline.enable_model_cpu_offload()

prompt = "A alien cheeseburger creature eating itself, claymation, cinematic, moody lighting"
negative_prompt = "low quality, bad quality"

image = pipeline(prompt=prompt, negative_prompt=negative_prompt, prior_guidance_scale=1.0, guidance_scale=4.0, height=768, width=768).images[0]
image
```

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16)
pipeline.enable_model_cpu_offload()

prompt = "A alien cheeseburger creature eating itself, claymation, cinematic, moody lighting"
negative_prompt = "low quality, bad quality"

image = pipeline(prompt=prompt, negative_prompt=negative_prompt, prior_guidance_scale=1.0, guidance_scale=4.0, height=768, width=768).images[0]
image
```

</hfoption>
</hfoptions>
Ù„Ù… ÙŠØªÙ… ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙƒÙˆØ§Ø¯ Ø¨Ø±Ù…Ø¬ÙŠØ© ÙˆØ±Ù…ÙˆØ² HTML ÙˆCSS Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø·Ù„Ø¨Ùƒ.

## Image-to-image

Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØ·Ù„Ø¨ Ø§Ù„Ù†Øµ Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨. Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø³Ø§Ø¨Ù‚:

<hfoptions id="image-to-image">

<hfoption id="Kandinsky 2.1">

```py
import torch
from diffusers import KandinskyImg2ImgPipeline, KandinskyPriorPipeline

prior_pipeline = KandinskyPriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = KandinskyImg2ImgPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
```

</hfoption>

<hfoption id="Kandinsky 2.2">

```py
import torch
from diffusers import KandinskyV22Img2ImgPipeline, KandinskyPriorPipeline

prior_pipeline = KandinskyPriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = KandinskyV22Img2ImgPipeline.from_pretrained("kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
```

</hfoption>

<hfoption id="Kandinsky 3">

Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Kandinsky 3 Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„ÙŠØŒ Ù„Ø°Ù„Ùƒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¨Ø§Ø´Ø±Ø©:

```py
from diffusers import Kandinsky3Img2ImgPipeline
from diffusers.utils import load_image
import torch

pipeline = Kandinsky3Img2ImgPipeline.from_pretrained("kandinsky-community/kandinsky-3", variant="fp16", torch_dtype=torch.float16)
pipeline.enable_model_cpu_offload()
```
</hfoption>

</hfoptions>

Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ ØµÙˆØ±Ø© Ù„Ù„ØªÙ‡ÙŠØ¦Ø©:

```py
from diffusers.utils import load_image

# download image
url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
original_image = load_image(url)
original_image = original_image.resize((768, 512))
```

<div class="flex justify-center">
    <img class="rounded-xl" src="https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"/>
</div>


![ØµÙˆØ±Ø© Ù„Ø¬Ø¨Ø§Ù„ Ù…Ø±Ø³ÙˆÙ…Ø© Ø¨Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø¹Ø±ÙŠØ¶Ø©](https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg)

Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ `image_embeds` Ùˆ `negative_image_embeds` Ù…Ø¹ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:

```py
prompt = "A fantasy landscape, Cinematic lighting"
negative_prompt = "low quality, bad quality"

image_embeds, negative_image_embeds = prior_pipeline(prompt, negative_prompt).to_tuple()
```

Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©ØŒ ÙˆØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª ÙˆØ§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø©:

<hfoptions id="image-to-image">

<hfoption id="Kandinsky 2.1">


```py
from diffusers.utils import make_image_grid

image = pipeline(prompt, negative_prompt=negative_prompt, image=original_image, image_embeds=image_embeds, negative_image_embeds=negative_image_embeds, height=768, width=768, strength=0.3).images[0]
make_image_grid([original_image.resize((512, 512)), image.resize((512, 512))], rows=1, cols=2)
```
<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinsky-docs/img2img_fantasyland.png"/>
</div>

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
from diffusers.utils import make_image_grid

image = pipeline(image=original_image, image_embeds=image_embeds, negative_image_embeds=negative_image_embeds, height=768, width=768, strength=0.3).images[0]
make_image_grid([original_image.resize((512, 512)), image.resize((512, 512))], rows=1, cols=2)
```

<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinsky-image-to-image.png"/>
</div>

</hfoption>
<hfoption id="Kandinsky 3">

```py
image = pipeline(prompt, negative_prompt=negative_prompt, image=image, strength=0.75, num_inference_steps=25).images[0]
image
```

</hfoption>
</hfoptions>

ÙŠÙˆÙØ± ğŸ¤— Diffusers Ø£ÙŠØ¶Ù‹Ø§ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ [`KandinskyImg2ImgCombinedPipeline`] Ùˆ [`KandinskyV22Img2ImgCombinedPipeline`]ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ù„Ø§ ÙŠÙ„Ø²Ù… ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØ®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„. ÙŠÙ‚ÙˆÙ… Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø´ØªØ±Ùƒ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙˆØ§Ù„Ù…Ø­Ù„Ù„. Ù„Ø§ ÙŠØ²Ø§Ù„ Ø¨Ø¥Ù…ÙƒØ§Ù†Ùƒ ØªØ¹ÙŠÙŠÙ† Ù‚ÙŠÙ… Ù…Ø®ØªÙ„ÙØ© Ù„Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø§Øª `prior_guidance_scale` Ùˆ `prior_num_inference_steps` Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø°Ù„Ùƒ.

Ø§Ø³ØªØ®Ø¯Ù… [`AutoPipelineForImage2Image`] Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§:

<hfoptions id="image-to-image">

<hfoption id="Kandinsky 2.1">


```py
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16, use_safetensors=True)
pipeline.enable_model_cpu_offload()

prompt = "A fantasy landscape, Cinematic lighting"
negative_prompt = "low quality, bad quality"

url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
original_image = load_image(url)

original_image.thumbnail((768, 768))

image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=original_image, strength=0.3).images[0]
make_image_grid([original_image.resize((512, 512)), image.resize((512, 512))], rows=1, cols=2)
```


</hfoption>

<hfoption id="Kandinsky 2.2">


```py
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained("kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16)
pipeline.enable_model_cpu_offload()

prompt = "A fantasy landscape, Cinematic lighting"
negative_prompt = "low quality, bad quality"

url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
original_image = load_image(url)

original_image.thumbnail((768, 768))

image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=original_image, strength=0.3).images[0]
make_image_grid([original_image.resize((512, 512)), image.resize((512, 512))], rows=1, cols=2)
```


</hfoption>

</hfoptions>


## Inpainting

<Tip warning={true}>

âš ï¸ ØªØ³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ Kandinsky Ø§Ù„Ø¢Ù† â¬œï¸ **pixels Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡** Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… [`KandinskyInpaintPipeline`] ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØºÙŠÙŠØ± Ø§Ù„Ù‚Ù†Ø§Ø¹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡:

```py
# For PIL input
import PIL.ImageOps
mask = PIL.ImageOps.invert(mask)

# For PyTorch and NumPy input
mask = 1 - mask
```

</Tip>

Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø±Ø³Ù…ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©ØŒ ÙˆÙ‚Ù†Ø§Ø¹ Ù„Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©ØŒ ÙˆØ·Ù„Ø¨ Ù†Øµ Ù„Ù…Ø§ Ø³ÙŠØªÙ… Ø·Ù„Ø§Ø¤Ù‡. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:

<hfoptions id="inpaint">

<hfoption id="Kandinsky 2.1">

```py
from diffusers import KandinskyInpaintPipeline, KandinskyPriorPipeline
from diffusers.utils import load_image, make_image_grid
import torch
import numpy as np
from PIL import Image

prior_pipeline = KandinskyPriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = KandinskyInpaintPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-inpaint", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
```

</hfoption>

<hfoption id="Kandinsky 2.2">


```py
from diffusers import KandinskyV22InpaintPipeline, KandinskyV22PriorPipeline
from diffusers.utils import load_image, make_image_grid
import torch
import numpy as np
from PIL import Image

prior_pipeline = KandinskyV22PriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = KandinskyV22InpaintPipeline.from_pretrained("kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
```

</hfoption>

</hfoptions>

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£ÙˆÙ„ÙŠØ© ÙˆØ¥Ù†Ø´Ø§Ø¡ Ù‚Ù†Ø§Ø¹:


```py
init_image = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png")
mask = np.zeros((768, 768), dtype=np.float32)
# mask area above cat's head
mask[:250, 250:-250] = 1
```

Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:

```py
prompt = "a hat"
prior_output = prior_pipeline(prompt)
```

Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØ§Ù„Ù‚Ù†Ø§Ø¹ ÙˆØ§Ù„Ø·Ù„Ø¨ ÙˆØ§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø©:

<hfoptions id="inpaint">

<hfoption id="Kandinsky 2.1">

```py
output_image = pipeline(prompt, image=init_image, mask_image=mask, **prior_output, height=768, width=768, num_inference_steps=150).images[0]
mask = Image.fromarray((mask*255).astype('uint8'), 'L')
make_image_grid([init_image, mask, output_image], rows=1, cols=3)
```


<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinsky-docs/inpaint_cat_hat.png"/>
</div>

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
output_image = pipeline(image=init_image, mask_image=mask, **prior_output, height=768, width=768, num_inference_steps=150).images[0]
mask = Image.fromarray((mask*255).astype('uint8'), 'L')
make_image_grid([init_image, mask, output_image], rows=1, cols=3)
```

<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinskyv22-inpaint.png"/>
</div>

</hfoption>

</hfoptions>

ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`KandinskyInpaintCombinedPipeline`] Ø§Ù„Ø´Ø§Ù…Ù„ Ùˆ [`KandinskyV22InpaintCombinedPipeline`] Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø·ÙˆØ· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØ§Ù„Ù…Ø­Ù„Ù„ Ù…Ø¹Ù‹Ø§ ØªØ­Øª ØºØ·Ø§Ø¡ Ø§Ù„Ù…Ø­Ø±Ùƒ. Ø§Ø³ØªØ®Ø¯Ù… [`AutoPipelineForInpainting`] Ù„Ù‡Ø°Ø§ Ø§Ù„ØºØ±Ø¶:

<hfoptions id="inpaint">

<hfoption id="Kandinsky 2.1">


```py
import torch
import numpy as np
from PIL import Image
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipe = AutoPipelineForInpainting.from_pretrained("kandinsky-community/kandinsky-2-1-inpaint", torch_dtype=torch.float16)
pipe.enable_model_cpu_offload()

init_image = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png")
mask = np.zeros((768, 768), dtype=np.float32)
# mask area above cat's head
mask[:250, 250:-250] = 1
prompt = "a hat"

output_image = pipe(prompt=prompt, image=init_image, mask_image=mask).images[0]
mask = Image.fromarray((mask*255).astype('uint8'), 'L')
make_image_grid([init_image, mask, output_image], rows=1, cols=3)
```

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
import torch
import numpy as np
from PIL import Image
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipe = AutoPipelineForInpainting.from_pretrained("kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16)
pipe.enable_model_cpu_offload()

init_image = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png")
mask = np.zeros((768, 768), dtype=np.float32)
# mask area above cat's head
mask[:250, 250:-250] = 1
prompt = "a hat"

output_image = pipe(prompt=prompt, image=original_image, mask_image=mask).images[0]
mask = Image.fromarray((mask*255).astype('uint8'), 'L')
make_image_grid([init_image, mask, output_image], rows=1, cols=3)
```

</hfoption>

</hfoptions>

## Ø§Ù„Ø§Ø³ØªÙŠÙØ§Ø¡

ÙŠØªÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠÙØ§Ø¡ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„ÙØ±Ø§Øº Ø§Ù„ÙƒØ§Ù…Ù† Ø¨ÙŠÙ† ØªØ¶Ù…ÙŠÙ† Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµØŒ ÙˆÙ‡ÙŠ Ø·Ø±ÙŠÙ‚Ø© Ø±Ø§Ø¦Ø¹Ø© Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„ÙˆØ³ÙŠØ·Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø¨Ù‚. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙˆØµÙˆØ±ØªÙŠÙ† ØªØ±ÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙŠÙØ§Ø¡ Ø¨ÙŠÙ†Ù‡Ù…Ø§:
```py
from diffusers import KandinskyPriorPipeline, KandinskyPipeline
from diffusers.utils import load_image, make_image_grid
import torch

prior_pipeline = KandinskyPriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
img_1 = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png")
img_2 = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/starry_night.jpeg")
make_image_grid([img_1.resize((512,512)), img_2.resize((512,512))], rows=1, cols=2)
```

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
from diffusers import KandinskyV22PriorPipeline, KandinskyV22Pipeline
from diffusers.utils import load_image, make_image_grid
import torch

prior_pipeline = KandinskyV22PriorPipeline.from_pretrained("kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
img_1 = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png")
img_2 = load_image("https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/starry_night.jpeg")
make_image_grid([img_1.resize((512,512)), img_2.resize((512,512))], rows=1, cols=2)
```

</hfoption>
</hfoptions>

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">a cat</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/starry_night.jpeg"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">Van Gogh's Starry Night painting</figcaption>
  </div>
</div>

Ø­Ø¯Ø¯ Ø§Ù„Ù†ØµÙˆØµ Ø£Ùˆ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙŠÙØ§Ø¡ Ø¨ÙŠÙ†Ù‡Ø§ØŒ ÙˆÙ‚Ù… Ø¨Ø¶Ø¨Ø· Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ù„ÙƒÙ„ Ù†Øµ Ø£Ùˆ ØµÙˆØ±Ø©. Ø¬Ø±Ø¨ Ù…Ø¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„ØªØ±Ù‰ ÙƒÙŠÙ ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙŠÙØ§Ø¡!

```py
images_texts = ["a cat", img_1, img_2]
weights = [0.3, 0.3, 0.4]
```

Ù‚Ù… Ø¨Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¹Ù„Ù‰ Ø¯Ø§Ù„Ø© `interpolate` Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§ØªØŒ Ø«Ù… Ù…Ø±Ø±Ù‡Ø§ Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©:


```py
# prompt can be left empty
prompt = ""
prior_out = prior_pipeline.interpolate(images_texts, weights)

pipeline = KandinskyPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16, use_safetensors=True).to("cuda")

image = pipeline(prompt, **prior_out, height=768, width=768).images[0]
image
```

<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinsky-docs/starry_cat.png"/>
</div>

</hfoption>
<hfoption id="Kandinsky 2.2">

```py
# prompt can be left empty
prompt = ""
prior_out = prior_pipeline.interpolate(images_texts, weights)

pipeline = KandinskyV22Pipeline.from_pretrained("kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True).to("cuda")

image = pipeline(prompt, **prior_out, height=768, width=768).images[0]
image
```

<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/kandinskyv22-interpolate.png"/>
</div>

</hfoption>
</hfoptions>

## ControlNet

<Tip warning={true}>
âš ï¸ ControlNet Ù…Ø¯Ø¹ÙˆÙ… ÙÙ‚Ø· Ù„Ù€ Kandinsky 2.2!
</Tip>

ØªÙ…ÙƒÙ‘Ù† ControlNet Ù…Ù† ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹ Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø«Ù„ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¹Ù…Ù‚ Ø£Ùˆ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‡ÙŠØ¦Ø© Kandinsky 2.2 Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¹Ù…Ù‚ Ø¨Ø­ÙŠØ« ÙŠÙÙ‡Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© ØµÙˆØ±Ø© Ø§Ù„Ø¹Ù…Ù‚.

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§:

```py
from diffusers.utils import load_image

img = load_image(
"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinskyv22/cat.png"
).resize((768, 768))
img
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinskyv22/cat.png"/>
</div>

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ `depth-estimation` Ù…Ù† ğŸ¤— Transformers Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø³ØªØ±Ø¯Ø§Ø¯ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¹Ù…Ù‚:

```py
import torch
import numpy as np

from transformers import pipeline

def make_hint(image, depth_estimator):
	image = depth_estimator(image)["depth"]
	image = np.array(image)
	image = image[:, :, None]
	image = np.concatenate([image, image, image], axis=2)
	detected_map = torch.from_numpy(image).float() / 255.0
	hint = detected_map.permute(2, 0, 1)
	return hint

depth_estimator = pipeline("depth-estimation")
hint = make_hint(img, depth_estimator).unsqueeze(0).half().to("cuda")
```

### Ù…Ù† Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© [[controlnet-text-to-image]]

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø³Ø§Ø¨Ù‚ ÙˆØ®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ [`KandinskyV22ControlnetPipeline`]:

```py
from diffusers import KandinskyV22PriorPipeline, KandinskyV22ControlnetPipeline

prior_pipeline = KandinskyV22PriorPipeline.from_pretrained(
"kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

pipeline = KandinskyV22ControlnetPipeline.from_pretrained(
"kandinsky-community/kandinsky-2-2-controlnet-depth", torch_dtype=torch.float16
).to("cuda")
```

Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ù…Ø­Ø« ÙˆÙ…Ø­Ø« Ø³Ø§Ø¨Ù‚:

```py
prompt = "A robot, 4k photo"
negative_prior_prompt = "lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature"

generator = torch.Generator(device="cuda").manual_seed(43)

image_emb, zero_image_emb = prior_pipeline(
prompt=prompt, negative_prompt=negative_prior_prompt, generator=generator
).to_tuple()
```

Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ù…Ø±Ø± ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø© ÙˆØµÙˆØ±Ø© Ø§Ù„Ø¹Ù…Ù‚ Ø¥Ù„Ù‰ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ [`KandinskyV22ControlnetPipeline`] Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©:

```py
image = pipeline(image_embeds=image_emb, negative_image_embeds=zero_image_emb, hint=hint, num_inference_steps=50, generator=generator, height=768, width=768).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinskyv22/robot_cat_text2img.png"/>
</div>

### Ù…Ù† ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© [[controlnet-image-to-image]]

Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù† ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ControlNetØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù…:

- [`KandinskyV22PriorEmb2EmbPipeline`] Ù„ØªÙˆÙ„ÙŠØ¯ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ù…Ø­Ø« Ù†ØµÙŠ ÙˆØµÙˆØ±Ø©
- [`KandinskyV22ControlnetImg2ImgPipeline`] Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø©

Ù‚Ù… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø© Ø£ÙˆÙ„ÙŠØ© Ù„Ù‚Ø·Ø© Ù…Ø³ØªØ®Ø¯Ù…Ø§Ù‹ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ `depth-estimation` Ù…Ù† ğŸ¤— Transformers ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¹Ù…Ù‚:

```py
import torch
import numpy as np

from diffusers import KandinskyV22PriorEmb2EmbPipeline, KandinskyV22ControlnetImg2ImgPipeline
from diffusers.utils import load_image
from transformers import pipeline

img = load_image(
"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinskyv22/cat.png"
).resize((768, 768))

def make_hint(image, depth_estimator):
image = depth_estimator(image)["depth"]
image = np.array(image)
image = image[:, :, None]
image = np.concatenate([image, image, image], axis=2)
detected_map = torch.from_numpy(image).float() / 255.0
hint = detected_map.permute(2, 0, 1)
return hint

depth_estimator = pipeline("depth-estimation")
hint = make_hint(img, depth_estimator).unsqueeze(0).half().to("cuda")
```

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙˆØ®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ [`KandinskyV22ControlnetImg2ImgPipeline`]:

```py
prior_pipeline = KandinskyV22PriorEmb2EmbPipeline.from_pretrained(
"kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

pipeline = KandinskyV22ControlnetImg2ImgPipeline.from_pretrained(
"kandinsky-community/kandinsky-2-2-controlnet-depth", torch_dtype=torch.float16
).to("cuda")
```

Ù…Ø±Ø± Ù…Ø­Ø« Ù†ØµÙŠ ÙˆØµÙˆØ±Ø© Ø£ÙˆÙ„ÙŠØ© Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„ØªÙˆÙ„ÙŠØ¯ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø©:

```py
prompt = "A robot, 4k photo"
negative_prior_prompt = "lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature"

generator = torch.Generator(device="cuda").manual_seed(43)

img_emb = prior_pipeline(prompt=prompt, image=img, strength=0.85, generator=generator)
negative_emb = prior_pipeline(prompt=negative_prior_prompt, image=img, strength=1, generator=generator)
```

Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ´ØºÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ [`KandinskyV22ControlnetImg2ImgPipeline`] Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø©:

```py
image = pipeline(image=img, strength=0.5, image_embeds=img_emb.image_embeds, negative_image_embeds=negative_emb.image_embeds, hint=hint, num_inference_steps=50, generator=generator, height=768, width=768).images[0]
make_image_grid([img.resize((512, 512)), image.resize((512, 512))], rows=1, cols=2)
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinskyv22/robot_cat.png"/>
</div>

## Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª

ÙŠØªÙ…ÙŠØ² Kandinsky Ø¨ÙƒÙˆÙ†Ù‡ ÙØ±ÙŠØ¯Ø§Ù‹ Ù…Ù† Ù†ÙˆØ¹Ù‡ Ù„Ø£Ù†Ù‡ ÙŠØªØ·Ù„Ø¨ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø³Ø§Ø¨Ù‚ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§ØªØŒ ÙˆØ®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø«Ø§Ù†Ù Ù„ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ÙƒÙ…ÙˆÙ†Ø§Øª Ø¥Ù„Ù‰ ØµÙˆØ±Ø©. ÙŠØ¬Ø¨ Ø£Ù† ØªØ±ÙƒØ² Ø¬Ù‡ÙˆØ¯ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø¹Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù„Ø£Ù† Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ÙŠØªÙ… ÙÙŠÙ‡ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨. ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„ØªØ­Ø³ÙŠÙ† Kandinsky Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„.

1. Ù‚Ù… Ø¨ØªÙ…ÙƒÙŠÙ† [xFormers](../optimization/xformers) Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… PyTorch < 2.0:

```diff
from diffusers import DiffusionPipeline
import torch

pipe = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16)
+ pipe.enable_xformers_memory_efficient_attention()
```

2. Ù‚Ù… Ø¨ØªÙ…ÙƒÙŠÙ† `torch.compile` Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… PyTorch >= 2.0 Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ (SDPA) ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§:

```diff
pipe.unet.to(memory_format=torch.channels_last)
+ pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)
```

ÙˆÙ‡Ø°Ø§ Ù…Ù…Ø§Ø«Ù„ Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~models.attention_processor.AttnAddedKVProcessor2_0`] Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­:

```py
from diffusers.models.attention_processor import AttnAddedKVProcessor2_0

pipe.unet.set_attn_processor(AttnAddedKVProcessor2_0())
```

3. Ù‚Ù… Ø¨ØªÙØ±ÙŠØº Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~KandinskyPriorPipeline.enable_model_cpu_offload`] Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ù†ÙØ§Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©:

```diff
from diffusers import DiffusionPipeline
import torch

pipe = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16)
+ pipe.enable_model_cpu_offload()
```

4. ÙŠØ³ØªØ®Ø¯Ù… Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…Ù† Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØ±Ø©ØŒ Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ø¬Ø¯ÙˆÙ„ DDIMSchedulerØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ø¬Ø¯ÙˆÙ„ Ø¢Ø®Ø± Ù…Ø«Ù„ [`DDPMScheduler`] Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© ØªØ£Ø«ÙŠØ± Ø°Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§ÙŠØ¶Ø© Ø¨ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©:

```py
from diffusers import DDPMScheduler
from diffusers import DiffusionPipeline

scheduler = DDPMScheduler.from_pretrained("kandinsky-community/kandinsky-2-1", subfolder="ddpm_scheduler")
pipe = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", scheduler=scheduler, torch_dtype=torch.float16, use_safetensors=True).to("cuda")
```