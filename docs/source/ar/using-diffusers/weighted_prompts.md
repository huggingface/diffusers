# ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø­ÙØ²Ø§Øª

[[open-in-colab]]

Ø§Ù„Ù…Ø­ÙØ²Ø§Øª Ù…Ù‡Ù…Ø© Ù„Ø£Ù†Ù‡Ø§ ØªØµÙ Ù…Ø§ ØªØ±ÙŠØ¯ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± ØªÙˆÙ„ÙŠØ¯Ù‡. Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø­ÙØ²Ø§Øª ØªÙƒÙˆÙ† Ù…ÙØµÙ„Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø© ÙˆØ¬ÙŠØ¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ØªØ­Ù‚ÙŠÙ‚ Ø±Ø¤ÙŠØªÙƒ. ÙˆÙ„ÙƒÙ† ØµÙŠØ§ØºØ© Ù…Ø­ÙØ² Ø±Ø§Ø¦Ø¹ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ ÙˆØ¬Ù‡Ø¯Ù‹Ø§ØŒ ÙˆÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø­ÙŠØ§Ù† Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø°Ù„Ùƒ ÙƒØ§ÙÙŠÙ‹Ø§ Ù„Ø£Ù† Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø¯Ù‚ÙŠÙ‚Ø©. Ù‡Ù†Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ¹Ø²ÙŠØ² Ù…Ø­ÙØ²Ùƒ Ø¨ØªÙ‚Ù†ÙŠØ§Øª Ø£Ø®Ø±Ù‰ØŒ Ù…Ø«Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ÙØ²Ø§Øª ÙˆÙˆØ²Ù† Ø§Ù„Ù…Ø­ÙØ²Ø§ØªØŒ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯Ù‡Ø§.

Ø³ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø­ÙØ²Ø§Øª Ù‡Ø°Ù‡ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ø¨Ù…Ø¬Ù‡ÙˆØ¯ Ø£Ù‚Ù„ ÙˆØªØ¹Ø¯ÙŠÙ„ ÙˆØ²Ù† ÙƒÙ„Ù…Ø§Øª Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ø¹ÙŠÙ†Ø© ÙÙŠ Ù…Ø­ÙØ².

## Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø­ÙØ²Ø§Øª

> [!TIP]
> Ù‡Ø°Ø§ Ù„ÙŠØ³ Ø¯Ù„ÙŠÙ„Ù‹Ø§ Ø´Ø§Ù…Ù„Ø§Ù‹ Ø¹Ù† Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø­ÙØ²Ø§ØªØŒ ÙˆÙ„ÙƒÙ†Ù‡ Ø³ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ© Ù„Ù…Ø­ÙØ² Ø¬ÙŠØ¯. Ù†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± ÙÙŠ ØªØ¬Ø±Ø¨Ø© Ù…Ø­ÙØ²Ø§Øª Ù…Ø®ØªÙ„ÙØ© ÙˆØ¯Ù…Ø¬Ù‡Ø§ Ø¨Ø·Ø±Ù‚ Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ. ÙƒÙ„Ù…Ø§ ÙƒØªØ¨Øª Ù…Ø­ÙØ²Ø§Øª Ø£ÙƒØ«Ø±ØŒ Ø³ØªØ·ÙˆØ± Ø­Ø¯Ø³Ù‹Ø§ Ù„Ù…Ø§ ÙŠÙ†Ø¬Ø­ ÙˆÙ…Ø§ Ù„Ø§ ÙŠÙ†Ø¬Ø­!

ØªØ¤Ø¯ÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø§Ù†ØªØ´Ø§Ø± ÙˆØ¸ÙŠÙØ© Ø¬ÙŠØ¯Ø© ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…Ù† Ù…Ø­ÙØ² Ø£Ø³Ø§Ø³ÙŠØŒ ÙˆÙ„ÙƒÙ† Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ÙØ² Ø¬ÙŠØ¯ Ø§Ù„ØµÙŠØ§ØºØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬. ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„ÙƒØªØ§Ø¨Ø© Ù…Ø­ÙØ² Ø¬ÙŠØ¯:

1. Ù…Ø§ Ù‡ÙŠ ØµÙŠØºØ© Ø§Ù„ØµÙˆØ±Ø©ØŸ Ù‡Ù„ Ù‡ÙŠ ØµÙˆØ±Ø© ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ© Ø£Ù… Ù„ÙˆØ­Ø© Ø²ÙŠØªÙŠØ© Ø£Ù… ØªÙˆØ¶ÙŠØ­ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø£Ù… Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŸ
2. Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©ØŸ Ù‡Ù„ Ù‡Ùˆ Ø´Ø®Øµ Ø£Ùˆ Ø­ÙŠÙˆØ§Ù† Ø£Ùˆ ÙƒØ§Ø¦Ù† Ø£Ùˆ Ù…Ø´Ù‡Ø¯ØŸ
3. Ù…Ø§ Ù‡ÙŠ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø±Ø¤ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©ØŸ Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø¨Ø¯Ø¹Ù‹Ø§ Ø­Ù‚Ù‹Ø§ ÙˆØ§Ù„Ø§Ø³ØªÙ…ØªØ§Ø¹ Ø¨ØªØ¬Ø±Ø¨Ø© ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ù„Ø¥Ø¶ÙØ§Ø¡ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù„Ù‰ ØµÙˆØ±ØªÙƒ. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø©ØŸ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ø¬ÙŠØ© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ©ØŸ Ù…Ø§ Ù‡Ùˆ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙÙ† Ø£Ùˆ Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø°ÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡ØŸ ÙƒÙ„Ù…Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ù‹Ø§ ÙˆØ¯Ù‚Ø©ØŒ ÙƒØ§Ù† ÙÙ‡Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù…Ø§ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯Ù‡ Ø£ÙØ¶Ù„.

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/plain-prompt.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">"ØµÙˆØ±Ø© ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ© Ù„Ø£Ø±ÙŠÙƒØ© Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ù…ÙˆØ²Ø© ÙÙŠ ØºØ±ÙØ© Ø§Ù„Ù…Ø¹ÙŠØ´Ø©"</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/detail-prompt.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">"Ø£Ø±ÙŠÙƒØ© Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ù…ÙˆØ²Ø© ØµÙØ±Ø§Ø¡ Ø²Ø§Ù‡ÙŠØ© ØªØ¬Ù„Ø³ ÙÙŠ ØºØ±ÙØ© Ù…Ø¹ÙŠØ´Ø© Ù…Ø±ÙŠØ­Ø©ØŒ ÙˆØªÙ„ØªÙ Ù…Ù†Ø­Ù†ÙŠØªÙ‡Ø§ Ø­ÙˆÙ„ ÙƒÙˆÙ…Ø© Ù…Ù† Ø§Ù„ÙˆØ³Ø§Ø¦Ø¯ Ø§Ù„Ù…Ù„ÙˆÙ†Ø©. ÙˆØ¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ Ø§Ù„Ø®Ø´Ø¨ÙŠØ©ØŒ ØªØ¶ÙŠÙ Ø³Ø¬Ø§Ø¯Ø© Ø°Ø§Øª Ù†Ù‚ÙˆØ´ Ù„Ù…Ø³Ø© Ù…Ù† Ø§Ù„Ø³Ø­Ø± ØºÙŠØ± Ø§Ù„Ù…ØªÙƒÙ„ÙØŒ ÙˆØªÙ‚Ù Ù†Ø¨ØªØ© ÙÙŠ Ø§Ù„Ø²Ø§ÙˆÙŠØ©ØŒ Ù…Ù…ØªØ¯Ø© Ù†Ø­Ùˆ Ø£Ø´Ø¹Ø© Ø§Ù„Ø´Ù…Ø³ Ø§Ù„ØªÙŠ ØªØªØ³Ù„Ù„ Ù…Ù† Ø§Ù„Ù†ÙˆØ§ÙØ°"</figcaption>
</div>
</div>

## ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ÙØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT2

ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ÙØ²Ø§Øª Ù‡ÙŠ ØªÙ‚Ù†ÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø­ÙØ² Ø¨Ø³Ø±Ø¹Ø© Ø¯ÙˆÙ† Ø¨Ø°Ù„ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø¬Ù‡Ø¯ ÙÙŠ Ø¨Ù†Ø§Ø¦Ù‡. ØªØ³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ù…Ø«Ù„ GPT2 Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ø­ÙØ²Ø§Øª Ù†Øµ Stable Diffusion Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø­ÙØ² ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨ÙƒÙ„Ù…Ø§Øª Ø±Ø¦ÙŠØ³ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù‡Ù…Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©.

ØªØ¹Ù…Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ¬Ù…ÙŠØ¹ Ù‚Ø§Ø¦Ù…Ø© Ø¨ÙƒÙ„Ù…Ø§Øª Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© ÙˆØ¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ØªÙˆÙ„ÙŠØ¯ ØªÙ„Ùƒ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ø­ÙØ² Ø§Ù„Ø£ØµÙ„ÙŠ. Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©ØŒ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø­ÙØ²Ùƒ "Ù‚Ø·Ø©"ØŒ ÙˆÙŠÙ…ÙƒÙ† Ù„Ù€ GPT2 ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ø­ÙØ² Ø¥Ù„Ù‰ "Ù„Ù‚Ø·Ø© Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ© Ù„ÙÙŠÙ„Ù… Ù„Ù‚Ø·Ø© Ù„Ù‚Ø·Ø© Ù„Ù‚Ø·Ø© ÙÙŠ Ø§Ù„Ø´Ù…Ø³ Ø¹Ù„Ù‰ Ø³Ø·Ø­ ÙÙŠ ØªØ±ÙƒÙŠØ§ØŒ Ù…ÙØµÙ„Ø© Ù„Ù„ØºØ§ÙŠØ©ØŒ ÙˆÙ…ÙŠØ²Ø§Ù†ÙŠØ© Ø¶Ø®Ù…Ø© Ù„ÙÙŠÙ„Ù… Ù‡ÙˆÙ„ÙŠÙˆÙˆØ¯ØŒ Ø³ÙŠÙ†Ù…Ø§Ø³ÙƒÙˆØ¨ØŒ Ù…Ø²Ø§Ø¬ÙŠØŒ Ù…Ù„Ø­Ù…ÙŠØŒ Ø¬Ù…ÙŠÙ„ØŒ Ø­Ø¨ÙŠØ¨Ø§Øª Ø§Ù„ÙÙŠÙ„Ù… Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø­Ø§Ø¯ Ø¬Ù…ÙŠÙ„Ø© Ù…ÙØµÙ„Ø© Ù…Ø¹Ù‚Ø¯Ø© Ù…Ø°Ù‡Ù„Ø© Ù…Ù„Ø­Ù…ÙŠØ©".

> [!TIP]
> ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… [Ø¶Ø¬ÙŠØ¬ Ø§Ù„ØªØ¹ÙˆÙŠØ¶](https://www.crosslabs.org//blog/diffusion-with-offset-noise) LoRA Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙÙŠ Ø§Ù„ØµÙˆØ± Ø§Ù„ÙØ§ØªØ­Ø© ÙˆØ§Ù„Ø¯Ø§ÙƒÙ†Ø© ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø¥Ø¶Ø§Ø¡Ø© Ø£ÙØ¶Ù„ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…. Ù…ØªØ§Ø­ Ù‡Ø°Ø§ [LoRA](https://hf.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_offset_example-lora_1.0.safetensors) Ù…Ù† [stabilityai/stable-diffusion-xl-base-1.0](https://hf.co/stabilityai/stable-diffusion-xl-base-1.0).

Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ø¯ÙŠØ¯ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ ÙˆÙ‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø£ÙƒØ«Ø± Ø´Ù…ÙˆÙ„Ø§Ù‹ Ù…Ù† [Ø§Ù„ÙƒÙ„Ù…Ø§Øª](https://hf.co/LykosAI/GPT-Prompt-Expansion-Fooocus-v2/blob/main/positive.txt) Ùˆ [Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨](https://github.com/lllyasviel/Fooocus/tree/main/sdxl_styles) Ø§Ù„ØªÙŠ ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ Fooocus) Ù„ØªØ¹Ø²ÙŠØ² Ù…Ø­ÙØ² Ø¨Ù‡Ø§.

```py
import torch
from transformers import GenerationConfig, GPT2LMHeadModel, GPT2Tokenizer, LogitsProcessor, LogitsProcessorList
from diffusers import StableDiffusionXLPipeline

styles = {
"cinematic": "cinematic film still of {prompt}, highly detailed, high budget hollywood movie, cinemascope, moody, epic, gorgeous, film grain",
"anime": "anime artwork of {prompt}, anime style, key visual, vibrant, studio anime, highly detailed",
"photographic": "cinematic photo of {prompt}, 35mm photograph, film, professional, 4k, highly detailed",
"comic": "comic of {prompt}, graphic illustration, comic art, graphic novel art, vibrant, highly detailed",
"lineart": "line art drawing {prompt}, professional, sleek, modern, minimalist, graphic, line art, vector graphics",
"pixelart": " pixel-art {prompt}, low-res, blocky, pixel art style, 8-bit graphics",
}

words = [
"aesthetic", "astonishing", "beautiful", "breathtaking", "composition", "contrasted", "epic", "moody", "enhanced",
"exceptional", "fascinating", "flawless", "glamorous", "glorious", "illumination", "impressive", "improved",
"inspirational", "magnificent", "majestic", "hyperrealistic", "smooth", "sharp", "focus", "stunning", "detailed",
"intricate", "dramatic", "high", "quality", "perfect", "light", "ultra", "highly", "radiant", "satisfying",
"soothing", "sophisticated", "stylish", "sublime", "terrific", "touching", "timeless", "wonderful", "unbelievable",
"elegant", "awesome", "amazing", "dynamic", "trendy",
]
```

Ù‚Ø¯ ØªÙƒÙˆÙ† Ù„Ø§Ø­Ø¸Øª ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© `words`ØŒ Ø£Ù† Ù‡Ù†Ø§Ùƒ ÙƒÙ„Ù…Ø§Øª Ù…Ø¹ÙŠÙ†Ø© ÙŠÙ…ÙƒÙ† Ø§Ù‚ØªØ±Ø§Ù†Ù‡Ø§ Ù„Ø®Ù„Ù‚ Ø´ÙŠØ¡ Ø£ÙƒØ«Ø± Ù…Ø¹Ù†Ù‰. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠÙ…ÙƒÙ† Ø¯Ù…Ø¬ ÙƒÙ„Ù…ØªÙŠ "high" Ùˆ "quality" Ù„ØªØµØ¨Ø­ "high quality". Ø¯Ø¹Ù†Ø§ Ù†Ù‚Ø±Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ø¹Ù‹Ø§ ÙˆÙ†Ø²ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù‚ØªØ±Ø§Ù†Ù‡Ø§.

```py
word_pairs = ["highly detailed", "high quality", "enhanced quality", "perfect composition", "dynamic light"]

def find_and_order_pairs(s, pairs):
words = s.split()
found_pairs = []
for pair in pairs:
pair_words = pair.split()
if pair_words[0] in words and pair_words[1] in words:
found_pairs.append(pair)
words.remove(pair_words[0])
words.remove(pair_words[1])

for word in words[:]:
for pair in pairs:
if word in pair.split():
words.remove(word)
break
ordered_pairs = ", ".join(found_pairs)
remaining_s = ", ".join(words)
return ordered_pairs, remaining_s
```

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° ÙØ¦Ø© [`~transformers.LogitsProcessor` Ù…Ø®ØµØµØ©](https://huggingface.co/transformers/main_classes/logits_processor.html) ØªÙ‚ÙˆÙ… Ø¨ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø±Ù…ÙˆØ² ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© `words` Ø¨Ù‚ÙŠÙ…Ø© 0 ÙˆØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© `words` Ø¨Ù‚ÙŠÙ…Ø© Ø³Ø§Ù„Ø¨Ø© Ø­ØªÙ‰ Ù„Ø§ ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡Ø§ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙˆÙ„ÙŠØ¯. Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©ØŒ ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ­ÙŠØ²Ù‹Ø§ Ù†Ø­Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© `words`. Ø¨Ø¹Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ ÙŠØªÙ… Ø£ÙŠØ¶Ù‹Ø§ ØªØ¹ÙŠÙŠÙ†Ù‡Ø§ Ø¨Ù‚ÙŠÙ…Ø© Ø³Ø§Ù„Ø¨Ø© Ø­ØªÙ‰ Ù„Ø§ ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡Ø§ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.

```py
class CustomLogitsProcessor(LogitsProcessor):
def __init__(self, bias):
super().__init__()
self.bias = bias

def __call__(self, input_ids, scores):
if len(input_ids.shape) == 2:
last_token_id = input_ids[0, -1]
self.bias[last_token_id] = -1e10
return scores + self.bias

word_ids = [tokenizer.encode(word, add_prefix_space=True)[0] for word in words]
bias = torch.full((tokenizer.vocab_size,), -float("Inf")).to("cuda")
bias[word_ids] = 0
processor = CustomLogitsProcessor(bias)
processor_list = LogitsProcessorList([processor])
```

Ù‚Ù… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø­ÙØ² ÙˆÙ…Ø­ÙØ² `cinematic` Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙŠ Ù‚Ø§Ù…ÙˆØ³ `styles` Ø³Ø§Ø¨Ù‚Ù‹Ø§.

```py
prompt = "a cat basking in the sun on a roof in Turkey"
style = "cinematic"

prompt = styles[style].format(prompt=prompt)
prompt
"cinematic film still of a cat basking in the sun on a roof in Turkey, highly detailed, high budget hollywood movie, cinemascope, moody, epic, gorgeous, film grain"
```

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªØ¹Ù„ÙŠÙ… GPT2 ÙˆÙ†Ù…ÙˆØ°Ø¬ Ù…Ù† Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚ [Gustavosta/MagicPrompt-Stable-Diffusion](https://huggingface.co/Gustavosta/MagicPrompt-Stable-Diffusion) (ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù‡Ø°Ù‡ Ø®ØµÙŠØµÙ‹Ø§ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ÙØ²Ø§Øª) Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ø­ÙØ².

```py
tokenizer = GPT2Tokenizer.from_pretrained("Gustavosta/MagicPrompt-Stable-Diffusion")
model = GPT2LMHeadModel.from_pretrained("Gustavosta/MagicPrompt-Stable-Diffusion", torch_dtype=torch.float16).to(
"cuda"
)
model.eval()

inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
token_count = inputs["input_ids"].shape[1]
max_new_tokens = 50 - token_count

generation_config = GenerationConfig(
penalty_alpha=0.7,
top_k=50,
eos_token_id=model.config.eos_token_id,
pad_token_id=model.config.eos_token_id,
pad_token=model.config.pad_token_id,
do_sample=True,
)

with torch.no_grad():
generated_ids = model.generate(
input_ids=inputs["input_ids"],
attention_mask=inputs["attention_mask"],
max_new_tokens=max_new_tokens,
generation_config=generation_config,
logits_processor=proccesor_list,
)
```

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø­ÙØ² Ø§Ù„Ù…Ø¯Ø®Ù„ ÙˆØ§Ù„Ù…Ø­ÙØ² Ø§Ù„Ù…ÙˆÙ„Ø¯. Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø¥Ù„Ù‚Ø§Ø¡ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ÙØ² Ø§Ù„Ù…ÙˆÙ„Ø¯ (`generated_part`)ØŒ ÙˆØ£Ø²ÙˆØ§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ (`pairs`)ØŒ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© (`words`). ÙƒÙ„ Ù‡Ø°Ø§ Ù…Ø¶Ù…Ù† ÙÙŠ `enhanced_prompt`.

```py
output_tokens = [tokenizer.decode(generated_id, skip_special_tokens=True) for generated_id in generated_ids]
input_part, generated_part = output_tokens[0][: len(prompt)], output_tokens[0][len(prompt) :]
pairs, words = find_and_order_pairs(generated_part, word_pairs)
formatted_generated_part = pairs + ", " + words
enhanced_prompt = input_part + ", " + formatted_generated_part
enhanced_prompt
["cinematic film still of a cat basking in the sun on a roof in Turkey, highly detailed, high budget hollywood movie, cinemascope, moody, epic, gorgeous, film grain quality sharp focus beautiful detailed intricate stunning amazing epic"]
```

Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙˆÙˆØ²Ù† LoRA Ù„Ø¶Ø¬ÙŠØ¬ Ø§Ù„ØªØ¹ÙˆÙŠØ¶ Ø¨ÙˆØ²Ù† *Ù…Ù†Ø®ÙØ¶* Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­ÙØ² Ø§Ù„Ù…Ø¹Ø²Ø².

```py
pipeline = StableDiffusionXLPipeline.from_pretrained(
"RunDiffusion/Juggernaut-XL-v9", torch_dtype=torch.float16, variant="fp16"
).to("cuda")

pipeline.load_lora_weights(
"stabilityai/stable-diffusion-xl-base-1.0",
weight_name="sd_xl_offset_example-lora_1.0.safetensors",
adapter_name="offset",
)
pipeline.set_adapters(["offset"], adapter_weights=[0.2])

image = pipeline(
enhanced_prompt,
width=1152,
height=896,
guidance_scale=7.5,
num_inference_steps=25,
).images[0]
image
```

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/non-enhanced-prompt.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">"Ù‚Ø·Ø© ØªØ³ØªÙ„Ù‚ÙŠ ÙÙŠ Ø§Ù„Ø´Ù…Ø³ Ø¹Ù„Ù‰ Ø³Ø·Ø­ ÙÙŠ ØªØ±ÙƒÙŠØ§"</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/enhanced-prompt.png"/>
<figcaption class="mt-â‚‚ text-center text-sm text-gray-500">"Ù„Ù‚Ø·Ø© Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ© Ù„ÙÙŠÙ„Ù… Ù„Ù‚Ø·Ø© Ù„Ù‚Ø·Ø© Ù„Ù‚Ø·Ø© ÙÙŠ Ø§Ù„Ø´Ù…Ø³ Ø¹Ù„Ù‰ Ø³Ø·Ø­ ÙÙŠ ØªØ±ÙƒÙŠØ§ØŒ Ù…ÙØµÙ„Ø© Ù„Ù„ØºØ§ÙŠØ©ØŒ ÙˆÙ…ÙŠØ²Ø§Ù†ÙŠØ© Ø¶Ø®Ù…Ø© Ù„ÙÙŠÙ„Ù… Ù‡ÙˆÙ„ÙŠÙˆÙˆØ¯ØŒ Ø³ÙŠÙ†Ù…Ø§Ø³ÙƒÙˆØ¨ØŒ Ù…Ø²Ø§Ø¬ÙŠØŒ Ù…Ù„Ø­Ù…ÙŠØŒ Ø¬Ù…ÙŠÙ„ØŒ Ø­Ø¨ÙŠØ¨Ø§Øª Ø§Ù„ÙÙŠÙ„Ù… Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø­Ø§Ø¯ Ø¬Ù…ÙŠÙ„Ø© Ù…ÙØµÙ„Ø© Ù…Ø¹Ù‚Ø¯Ø© Ù…Ø°Ù‡Ù„Ø© Ù…Ù„Ø­Ù…ÙŠØ©"</figcaption>
</div>
</div>
## ÙˆØ²Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©

ÙŠÙˆÙØ± ÙˆØ²Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø·Ø±ÙŠÙ‚Ø© Ù„ØªØ£ÙƒÙŠØ¯ Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Ù…Ø·Ø§Ù„Ø¨Ø© Ù…Ø§ØŒ Ù…Ù…Ø§ ÙŠØªÙŠØ­ Ù…Ø²ÙŠØ¯Ù‹Ø§ Ù…Ù† Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©. ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØªØ¶Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø¹Ø¯Ø© Ù…ÙØ§Ù‡ÙŠÙ…ØŒ ÙˆØ§Ù„ØªÙŠ ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ù†ØµÙŠØ© Ø³ÙŠØ§Ù‚ÙŠØ©. ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ù„ØªÙ‡ÙŠØ¦Ø© Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø§Ø·Ø¹ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© (Ø§Ù‚Ø±Ø£ Ù…Ù†Ø´ÙˆØ± Ø§Ù„Ù…Ø¯ÙˆÙ†Ø© Stable Diffusion [1] Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¹Ù…Ù„Ù‡Ø§).

ÙŠØ¹Ù…Ù„ ÙˆØ²Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø²ÙŠØ§Ø¯Ø© Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ Ù…ØªØ¬Ù‡ Ø§Ù„ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†ØµÙŠ Ø§Ù„Ø°ÙŠ ÙŠÙ‚Ø§Ø¨Ù„Ù‡ ÙÙŠ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©. Ù‚Ø¯ Ù„Ø§ ØªØ±ØºØ¨ ÙÙŠ Ø£Ù† ÙŠØ±ÙƒØ² Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø¨Ø§Ù„ØªØ³Ø§ÙˆÙŠ. ÙˆØ£Ø¨Ø³Ø· Ø·Ø±ÙŠÙ‚Ø© Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø°Ø§Øª Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ© Ù‡ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… [Compel] [2]ØŒ ÙˆÙ‡Ùˆ Ù…ÙƒØªØ¨Ø© Ù„ÙˆØ²Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø§Ù„Ù†ØµÙŠØ© ÙˆØ¯Ù…Ø¬Ù‡Ø§. Ø¨Ù…Ø¬Ø±Ø¯ Ø­ØµÙˆÙ„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø°Ø§Øª Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø£ÙŠ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙˆØ³ÙŠØ· [`prompt_embeds`] [3] (ÙˆØ§Ø®ØªÙŠØ§Ø±ÙŠÙ‹Ø§ [`negative_prompt_embeds`] [4])ØŒ Ù…Ø«Ù„ [`StableDiffusionPipeline`] [5]ØŒ Ùˆ [`StableDiffusionControlNetPipeline`] [6]ØŒ Ùˆ [`StableDiffusionXLPipeline`] [7].

<Tip>

Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…ÙØ¶Ù„ Ù„Ø¯ÙŠÙƒ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙˆØ³ÙŠØ· `prompt_embeds`ØŒ ÙÙŠØ±Ø¬Ù‰ ÙØªØ­ [Ù‚Ø¶ÙŠØ©] [8] Ø­ØªÙ‰ Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø¥Ø¶Ø§ÙØªÙ‡!

</Tip>

Ø³ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ© ÙˆØ²Ù† ÙˆØ¯Ù…Ø¬ Ù…Ø·Ø§Ù„Ø¨Ø§ØªÙƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Compel ÙÙŠ ğŸ¤— Diffusers.

Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŒ ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙƒ Ø£Ø­Ø¯Ø« Ø¥ØµØ¯Ø§Ø± Ù…Ù† Compel Ù…Ø«Ø¨ØªÙ‹Ø§:

```py
# Ù‚Ù… Ø¨Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ù„ØªØ«Ø¨ÙŠØªÙ‡ ÙÙŠ Colab
#! pip install compel --upgrade
```

Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ù‚ÙˆÙ… Ø¨ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© "Ù‚Ø·Ø© Ø­Ù…Ø±Ø§Ø¡ ØªÙ„Ø¹Ø¨ Ø¨ÙƒØ±Ø©" Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`StableDiffusionPipeline`] :

```py
from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler
import torch

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", use_safetensors=True)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.to("cuda")

prompt = "a red cat playing with a ball"

generator = torch.Generator(device="cpu").manual_seed(33)

image = pipe(prompt, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/compel/forest_0.png"/>
</div>

### Ø§Ù„ÙˆØ²Ù†

Ø³ØªÙ„Ø§Ø­Ø¸ Ø£Ù†Ù‡ Ù„Ø§ ØªÙˆØ¬Ø¯ "ÙƒØ±Ø©" ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©! Ø¯Ø¹Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… Compel Ù„Ø²ÙŠØ§Ø¯Ø© ÙˆØ²Ù† Ù…ÙÙ‡ÙˆÙ… "ÙƒØ±Ø©" ÙÙŠ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† [`Compel`] [9]ØŒ ÙˆÙ…Ø±Ø± Ù…Ø­Ø¯Ø¯ Ù…ÙˆØ§Ù‚Ø¹ ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ù†ØµÙŠ Ù„Ù‡:

```py
from compel import Compel

compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)
```

ÙŠØ³ØªØ®Ø¯Ù… Compel `+` Ø£Ùˆ `-` Ù„Ø²ÙŠØ§Ø¯Ø© Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ ÙˆØ²Ù† ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©. Ù„Ø²ÙŠØ§Ø¯Ø© ÙˆØ²Ù† "ÙƒØ±Ø©":

<Tip>

`+` ÙŠÙ‚Ø§Ø¨Ù„Ù‡ Ø§Ù„Ù‚ÙŠÙ…Ø© `1.1`ØŒ `++` ÙŠÙ‚Ø§Ø¨Ù„Ù‡ `1.1^2`ØŒ ÙˆÙ‡ÙƒØ°Ø§. ÙˆØ¨Ø§Ù„Ù…Ø«Ù„ØŒ ÙŠÙ‚Ø§Ø¨Ù„ `-` Ø§Ù„Ù‚ÙŠÙ…Ø© `0.9` ÙˆÙŠÙ‚Ø§Ø¨Ù„ `--` Ø§Ù„Ù‚ÙŠÙ…Ø© `0.9^2`. Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† `+` Ø£Ùˆ `-` ÙÙŠ Ù…Ø·Ø§Ù„Ø¨ØªÙƒ!

</Tip>

```py
prompt = "a red cat playing with a ball++"
```

Ù…Ø±Ø± Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø¥Ù„Ù‰ `compel_proc` Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ØªØªÙ…ØªØ¹ Ø¨Ø£Ù‡Ù…ÙŠØ© Ù†Ø³Ø¨ÙŠØ© ÙˆØ§Ù„ØªÙŠ ÙŠØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨:

```py
prompt_embeds = compel_proc(prompt)
generator = torch.manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/compel/forest_1.png"/>
</div>

Ù„ØªØ®ÙÙŠØ¶ ÙˆØ²Ù† Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„Ø§Ø­Ù‚Ø© `-`:

```py
prompt = "a red------- cat playing with a ball"
prompt_embeds = compel_proc(prompt)

generator = torch.manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-neg.png"/>
</div>

ÙŠÙ…ÙƒÙ†Ùƒ Ø­ØªÙ‰ Ø²ÙŠØ§Ø¯Ø© Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ ÙˆØ²Ù† Ù…ÙØ§Ù‡ÙŠÙ… Ù…ØªØ¹Ø¯Ø¯Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©:

```py
prompt = "a red cat++ playing with a ball----"
prompt_embeds = compel_proc(prompt)

generator = torch.manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-pos-neg.png"/>
</div>

### Ø§Ù„Ù…Ø²Ø¬

ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø²ÙŠØ¬ Ù…Ø±Ø¬Ø­ Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© `.blend()` Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª ÙˆØªÙ…Ø±ÙŠØ± Ø¨Ø¹Ø¶ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ù„Ù‡Ø§. Ù‚Ø¯ Ù„Ø§ ÙŠÙ†ØªØ¬ Ù…Ø²ÙŠØ¬Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙŠ ØªØªÙˆÙ‚Ø¹Ù‡Ø§ Ù„Ø£Ù†Ù‡ ÙŠÙƒØ³Ø± Ø¨Ø¹Ø¶ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¹Ù…Ù„ Ø§Ù„Ù…Ø´ÙØ± Ø§Ù„Ù†ØµÙŠØŒ Ù„Ø°Ø§ Ù‚Ù… Ø¨Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙˆØ§Ù„Ø§Ø³ØªÙ…ØªØ§Ø¹ Ø¨Ù‡!

```py
prompt_embeds = compel_proc('("a red cat playing with a ball", "jungle").blend(0.7, 0.8)')
generator = torch.Generator(device="cuda").manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-blend.png"/>
</div>

### Ø§Ù„Ø¹Ø·Ù

ÙŠØ¤Ø¯ÙŠ Ø§Ù„Ø¹Ø·Ù Ø¥Ù„Ù‰ Ù†Ø´Ø± ÙƒÙ„ Ù…Ø·Ø§Ù„Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ‚Ù„ ÙˆÙŠÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø¬Ù…ÙˆØ¹Ù‡Ø§ Ø§Ù„Ù…Ø±Ø¬Ø­. Ø£Ø¶Ù `.and()` ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø·Ù:

```py
prompt_embeds = compel_proc('["a red cat", "playing with a", "ball"].and()')
generator = torch.Generator(device="cuda").manual_seed(55)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-conj.png"/>
</div>

### Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§Ù„Ù†ØµÙŠ

[Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§Ù„Ù†ØµÙŠ] [10] Ù‡Ùˆ ØªÙ‚Ù†ÙŠØ© Ù„ØªØ¹Ù„Ù… Ù…ÙÙ‡ÙˆÙ… Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø°Ù„Ùƒ Ø§Ù„Ù…ÙÙ‡ÙˆÙ….

Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ù„Ø© [`~loaders.TextualInversionLoaderMixin.load_textual_inversion`] [11] Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠØ© Ø§Ù„Ù†ØµÙŠØ© (Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ ØªØµÙØ­ [Stable Diffusion Conceptualizer] [12] Ù„Ø£ÙƒØ«Ø± Ù…Ù† 100 Ù…ÙÙ‡ÙˆÙ… Ù…Ø¯Ø±Ø¨):

```py
import torch
from diffusers import StableDiffusionPipeline
from compel import Compel, DiffusersTextualInversionManager

pipe = StableDiffusionPipeline.from_pretrained(
"runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16,
use_safetensors=True, variant="fp16").to("cuda")
pipe.load_textual_inversion("sd-concepts-library/midjourney-style")
```

ÙŠÙˆÙØ± Compel ÙØ¦Ø© `DiffusersTextualInversionManager` Ù„ØªØ¨Ø³ÙŠØ· ÙˆØ²Ù† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§Ù„Ù†ØµÙŠ. Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° `DiffusersTextualInversionManager` ÙˆÙ…Ø±Ø±Ù‡ Ø¥Ù„Ù‰ ÙØ¦Ø© `Compel`:

```py
textual_inversion_manager = DiffusersTextualInversionManager(pipe)
compel_proc = Compel(
tokenizer=pipe.tokenizer,
text_encoder=pipe.text_encoder,
textual_inversion_manager=textual_inversion_manager)
```

Ù‚Ù… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ù„ØªÙ‡ÙŠØ¦Ø© Ù…Ø·Ø§Ù„Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø© `<concept>`:

```py
prompt_embeds = compel_proc('("A red cat++ playing with a ball <midjourney-style>")')

image = pipe(prompt_embeds=prompt_embeds).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-text-inversion.png"/>
</div>

### DreamBooth

[DreamBooth] [13] Ù‡ÙŠ ØªÙ‚Ù†ÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø³ÙŠØ§Ù‚ÙŠØ© Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ù‚Ù„ÙŠÙ„ ÙÙ‚Ø· Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„ÙŠÙ‡Ø§. Ø¥Ù†Ù‡ Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§Ù„Ù†ØµÙŠØŒ ÙˆÙ„ÙƒÙ† DreamBooth ÙŠÙ‚ÙˆÙ… Ø¨ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ Ø­ÙŠÙ† Ø£Ù† Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§Ù„Ù†ØµÙŠ ÙŠÙ‚ÙˆÙ… ÙÙ‚Ø· Ø¨ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ù†ØµÙŠØ©. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~DiffusionPipeline.from_pretrained`] [14] Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ DreamBooth (Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ ØªØµÙØ­ [Stable Diffusion Dreambooth Concepts Library] [15] Ù„Ø£ÙƒØ«Ø± Ù…Ù† 100 Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ø±Ø¨):

```py
import torch
from diffusers import DiffusionPipeline, UniPCMultistepScheduler
from compel import Compel

pipe = DiffusionPipeline.from_pretrained("sd-dreambooth-library/dndcoverart-v1", torch_dtype=torch.float16).to("cuda")
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
```

Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ÙØ¦Ø© `Compel` Ù…Ø¹ Ù…Ø­Ø¯Ø¯ Ù…ÙˆØ§Ù‚Ø¹ ÙˆÙ…Ø´ÙØ± Ù†ØµÙŠØŒ ÙˆÙ…Ø±Ø± Ù…Ø·Ø§Ù„Ø¨ØªÙƒ Ø¥Ù„ÙŠÙ‡Ø§. Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ÙØ±ÙŠØ¯ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ø·Ø§Ù„Ø¨ØªÙƒ. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ `dndcoverart-v1` Ø§Ù„Ù…Ø¹Ø±Ù `dndcoverart`:

```py
compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)
prompt_embeds = compel_proc('("magazine cover of a dndcoverart dragon, high quality, intricate details, larry elmore art style").and()')
image = pipe(prompt_embeds=prompt_embeds).images[0]
image
```

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-dreambooth.png"/>
</div>

### Stable Diffusion XL

ÙŠØ­ØªÙˆÙŠ Stable Diffusion XL (SDXL) Ø¹Ù„Ù‰ Ù…Ø­Ø¯Ø¯ÙŠ Ù…ÙˆØ§Ù‚Ø¹ ÙˆÙ…Ø´ÙØ±ÙŠÙ† Ù†ØµÙŠÙŠÙ†ØŒ Ù„Ø°Ø§ ÙØ¥Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø®ØªÙ„Ù Ø¨Ø¹Ø¶ Ø§Ù„Ø´ÙŠØ¡. Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø°Ù„ÙƒØŒ ÙŠØ¬Ø¨ ØªÙ…Ø±ÙŠØ± ÙƒÙ„Ø§ Ø§Ù„Ù…Ø­Ø¯Ø¯ÙŠÙ† ÙˆØ§Ù„Ù…Ø´ÙØ±ÙŠÙ† Ø¥Ù„Ù‰ ÙØ¦Ø© `Compel`:

```py
from compel import Compel, ReturnedEmbeddingsType
from diffusers import DiffusionPipeline
from diffusers.utils import make_image_grid
import torch

pipeline = DiffusionPipeline.from_pretrained(
"stabilityai/stable-diffusion-xl-base-1.0",
variant="fp16",
use_safetensors=True,
torch_dtype=torch.float16
).to("cuda")

compel = Compel(
tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2],
text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2],
returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,
requires_pooled=[False, True]
)
```

Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø©ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø²ÙŠØ¯ ÙˆØ²Ù† "ÙƒØ±Ø©" Ø¨Ù…Ø¹Ø§Ù…Ù„ 1.5 Ù„Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ØŒ ÙˆÙ†Ù‚Ù„Ù„ ÙˆØ²Ù† "ÙƒØ±Ø©" Ø¥Ù„Ù‰ 0.6 Ù„Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©. ÙŠØªØ·Ù„Ø¨ [`StableDiffusionXLPipeline`] [16] Ø£ÙŠØ¶Ù‹Ø§ [`pooled_prompt_embeds`] [17] (ÙˆØ§Ø®ØªÙŠØ§Ø±ÙŠÙ‹Ø§ [`negative_pooled_prompt_embeds`] [18])ØŒ Ù„Ø°Ø§ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ø§Ù„ØªÙˆØªÙ†Ø§Øª Ø§Ù„Ø´Ø±Ø·ÙŠØ©:

```py
# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
prompt = ["a red cat playing with a (ball)1.5", "a red cat playing with a (ball)0.6"]
conditioning, pooled = compel(prompt)

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
generator = [torch.Generator().manual_seed(33) for _ in range(len(prompt))]
images = pipeline(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, generator=generator, num_inference_steps=30).images
make_image_grid(images, rows=1, cols=2)
```

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/compel/sdxl_ball1.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">"a red cat playing with a (ball)1.5"</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/compel/sdxl_ball2.png"/>
<figcaption class="mt-Û² text-center text-sm text-gray-500">"a red cat playing with a (ball)0.6"</figcaption>
</div>
</div>