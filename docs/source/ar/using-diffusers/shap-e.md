# Shap-E

[[open-in-colab]]

Shap-E ูู ูููุฐุฌ ุดุฑุทู ูุชูููุฏ ุฃุตูู ุซูุงุซูุฉ ุงูุฃุจุนุงุฏ ูููู ุงุณุชุฎุฏุงููุง ูู ุชุทููุฑ ุฃูุนุงุจ ุงูููุฏูู ูุชุตููู ุงูุฏูููุฑ ุงูุฏุงุฎูู ูุงูููุฏุณุฉ ุงููุนูุงุฑูุฉ. ุชู ุชุฏุฑูุจู ุนูู ูุฌููุนุฉ ุจูุงูุงุช ูุจูุฑุฉ ูู ุงูุฃุตูู ุซูุงุซูุฉ ุงูุฃุจุนุงุฏุ ูุชูุช ูุนุงูุฌุชูุง ุจุนุฏ ุฐูู ูุฅูุดุงุก ุงููุฒูุฏ ูู ูุฌูุงุช ุงููุธุฑ ููู ูุงุฆู ูุฅูุชุงุฌ ุณุญุจ ููุงุท 16K ุจุฏูุงู ูู 4K. ูุชู ุชุฏุฑูุจ ูููุฐุฌ Shap-E ูู ุฎุทูุชูู:

1. ููุจู ูุดูุฑ ุณุญุจ ุงูููุงุท ูุงูุตูุฑ ุงูุชู ุชู ุนุฑุถูุง ูุฃุตู ุซูุงุซู ุงูุฃุจุนุงุฏ ููุฎุฑุฌ ูุนููุงุช ุงูุฏูุงู ุงูุถูููุฉ ุงูุชู ุชูุซู ุงูุฃุตู.
2. ูุชู ุชุฏุฑูุจ ูููุฐุฌ ุงูุงูุชุดุงุฑ ุนูู ุงููุฎููุงุช ุงูุชู ููุชุฌูุง ุงููุดูุฑ ูุชูููุฏ ุญููู ุงูุฅุดุนุงุน ุงูุนุตุจูุฉ (NeRFs) ุฃู ุดุจูุฉ ุซูุงุซูุฉ ุงูุฃุจุนุงุฏ ุฐุงุช ูุณูุฌุ ููุง ูุฌุนู ูู ุงูุณูู ุชุตููุฑ ุงูุฃุตู ุซูุงุซู ุงูุฃุจุนุงุฏ ูุงุณุชุฎุฏุงูู ูู ุงูุชุทุจููุงุช ุงููุงุญูุฉ.

ุณููุถุญ ูุฐุง ุงูุฏููู ููููุฉ ุงุณุชุฎุฏุงู Shap-E ูุจุฏุก ุฅูุดุงุก ุฃุตูู ุซูุงุซูุฉ ุงูุฃุจุนุงุฏ ุงูุฎุงุตุฉ ุจู!

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุงูููุชุจุงุช ุงูุชุงููุฉ:

```py
# ูู ุจุฅูุบุงุก ุงูุชุนููู ูุชุซุจูุช ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ ูู Colab
#! pip install -q diffusers transformers accelerate trimesh
```

## ูุต ุฅูู 3D

ูุฅูุดุงุก ุตูุฑุฉ ูุชุญุฑูุฉ ููุงุฆู ุซูุงุซู ุงูุฃุจุนุงุฏุ ูู ุจุชูุฑูุฑ ููุฌู ูุตู ุฅูู [`ShapEPipeline`]. ูููู ุงูุฃูุจูุจ ุจุชูููุฏ ูุงุฆูุฉ ูู ุฅุทุงุฑุงุช ุงูุตูุฑ ุงูุชู ุชุณุชุฎุฏู ูุฅูุดุงุก ุงููุงุฆู ุซูุงุซู ุงูุฃุจุนุงุฏ.

```py
import torch
from diffusers import ShapEPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16, variant="fp16")
pipe = pipe.to(device)

guidance_scale = 15.0
prompt = ["A firecracker", "A birthday cupcake"]

images = pipe(
    prompt,
    guidance_scale=guidance_scale,
    num_inference_steps=64,
    frame_size=256,
).images
```

ุงูุขู ุงุณุชุฎุฏู ูุธููุฉ [`~utils.export_to_gif`] ูุชุญููู ูุงุฆูุฉ ุฅุทุงุฑุงุช ุงูุตูุฑ ุฅูู ุตูุฑุฉ GIF ูููุงุฆู ุซูุงุซู ุงูุฃุจุนุงุฏ.

```py
from diffusers.utils import export_to_gif

export_to_gif(images[0], "firecracker_3d.gif")
export_to_gif(images[1], "cake_3d.gif")
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/firecracker_out.gif"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">prompt = "A firecracker"</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/cake_out.gif"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">prompt = "A birthday cupcake"</figcaption>
  </div>
</div>


## ุตูุฑุฉ ุฅูู 3D

ูุฅูุดุงุก ูุงุฆู ุซูุงุซู ุงูุฃุจุนุงุฏ ูู ุตูุฑุฉ ุฃุฎุฑูุ ุงุณุชุฎุฏู [`ShapEImg2ImgPipeline`]. ููููู ุงุณุชุฎุฏุงู ุตูุฑุฉ ููุฌูุฏุฉ ุฃู ุฅูุดุงุก ุตูุฑุฉ ุฌุฏูุฏุฉ ุชูุงููุง. ุฏุนูุง ูุณุชุฎุฏู ูููุฐุฌ [Kandinsky 2.1](../api/pipelines/kandinsky) ูุฅูุดุงุก ุตูุฑุฉ ุฌุฏูุฏุฉ.

```py
from diffusers import DiffusionPipeline
import torch

prior_pipeline = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16, use_safetensors=True).to("cuda")

prompt = "A cheeseburger, white background"

image_embeds, negative_image_embeds = prior_pipeline(prompt, guidance_scale=1.0).to_tuple()
image = pipeline(
    prompt,
    image_embeds=image_embeds,
    negative_image_embeds=negative_image_embeds,
).images[0]

image.save("burger.png")
```

ูุฑุฑ ุชุดูุฒ ุจุฑุฌุฑ ุฅูู [`ShapEImg2ImgPipeline`] ูุฅูุดุงุก ุชูุซูู ุซูุงุซู ุงูุฃุจุนุงุฏ ูู.

```py
from PIL import Image
from diffusers import ShapEImg2ImgPipeline
from diffusers.utils import export_to_gif

pipe = ShapEImg2ImgPipeline.from_pretrained("openai/shap-e-img2img", torch_dtype=torch.float16, variant="fp16").to("cuda")

guidance_scale = 3.0
image = Image.open("burger.png").resize((256, 256))

images = pipe(
    image,
    guidance_scale=guidance_scale,
    num_inference_steps=64,
    frame_size=256,
).images

gif_path = export_to_gif(images[0], "burger_3d.gif")
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/burger_in.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">cheeseburger</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/burger_out.gif"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">3D cheeseburger</figcaption>
  </div>
</div>


## ุฅูุดุงุก ุดุจูุฉ

Shap-E ูู ูููุฐุฌ ูุฑู ููููู ุฃูุถูุง ุฅูุดุงุก ูุฎุฑุฌุงุช ุดุจูุฉ ููุณูุฌุฉ ููุชู ุชุตููุฑูุง ููุชุทุจููุงุช ุงููุงุญูุฉ. ูู ูุฐุง ุงููุซุงูุ ุณุชููู ุจุชุญููู ุงูุฅุฎุฑุงุฌ ุฅูู ููู `glb` ูุฃู ููุชุจุฉ ูุฌููุนุงุช ุงูุจูุงูุงุช ๐ค ุชุฏุนู ุนุฑุถ ุดุจูุฉ ูููุงุช `glb` ุงูุชู ูููู ุนุฑุถูุง ุจูุงุณุทุฉ [ุนุงุฑุถ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/docs/hub/datasets-viewer#dataset-preview).

ููููู ุฅูุดุงุก ูุฎุฑุฌุงุช ุดุจูุฉ ููู ูู [`ShapEPipeline`] ู [`ShapEImg2ImgPipeline`] ุนู ุทุฑูู ุชุญุฏูุฏ `output_type` ุงููุนููุฉ ููุง `"mesh"`:

```py
import torch
from diffusers import ShapEPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16, variant="fp16")
pipe = pipe.to(device)

guidance_scale = 15.0
prompt = "A birthday cupcake"

images = pipe(prompt, guidance_scale=guidance_scale, num_inference_steps=64, frame_size=256, output_type="mesh").images
```

ุงุณุชุฎุฏู ูุธููุฉ [`~utils.export_to_ply`] ูุญูุธ ุฅุฎุฑุงุฌ ุงูุดุจูุฉ ูููู `ply`:

<Tip>
ููููู ุฃูุถูุง ุญูุธ ุฅุฎุฑุงุฌ ุงูุดุจูุฉ ูููู `obj` ุจุงุณุชุฎุฏุงู ูุธููุฉ [`~utils.export_to_obj`]. ุฅู ุงููุฏุฑุฉ ุนูู ุญูุธ ุฅุฎุฑุงุฌ ุงูุดุจูุฉ ูู ูุฌููุนุฉ ูุชููุนุฉ ูู ุงูุชูุณููุงุช ุชุฌุนููุง ุฃูุซุฑ ูุฑููุฉ ููุงุณุชุฎุฏุงู ุงููุงุญู!
</Tip>

```py
from diffusers.utils import export_to_ply

ply_path = export_to_ply(images[0], "3d_cake.ply")
print(f"Saved to folder: {ply_path}")
```

ุจุนุฏ ุฐููุ ููููู ุชุญููู ููู `ply` ุฅูู ููู `glb` ุจุงุณุชุฎุฏุงู ููุชุจุฉ trimesh:

```py
import trimesh

mesh = trimesh.load("3d_cake.ply")
mesh_export = mesh.export("3d_cake.glb", file_type="glb")
```

ุงูุชุฑุงุถููุงุ ูุชู ุชุฑููุฒ ุฅุฎุฑุงุฌ ุงูุดุจูุฉ ูู ููุธูุฑ ุงูุฑุคูุฉ ุงูุณูููุ ูููู ููููู ุชุบููุฑ ููุธูุฑ ุงูุฑุคูุฉ ุงูุงูุชุฑุงุถู ุนู ุทุฑูู ุชุทุจูู ุชุญููู ุงูุฏูุฑุงู:

```py
import trimesh
import numpy as np

mesh = trimesh.load("3d_cake.ply")
rot = trimesh.transformations.rotation_matrix(-np.pi / 2, [1, 0, 0])
mesh = mesh.apply_transform(rot)
mesh_export = mesh.export("3d_cake.glb", file_type="glb")
```

ูู ุจุชุญููู ููู ุงูุดุจูุฉ ุฅูู ูุณุชูุฏุน ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูุนุฑุถู ุจุงุณุชุฎุฏุงู ุนุงุฑุถ ูุฌููุนุฉ ุงูุจูุงูุงุช!

<div class="flex justify-center">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/3D-cake.gif"/>
</div>