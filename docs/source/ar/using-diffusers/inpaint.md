
# Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±

ØªØ¹Ø¯ ØªÙ‚Ù†ÙŠØ© Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ± (Inpainting) Ø£Ø¯Ø§Ø© Ù…ÙÙŠØ¯Ø© Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØµÙˆØ± Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ù…Ù†Ø§Ø·Ù‚ Ù…Ø­Ø¯Ø¯Ø© Ù…Ù†Ù‡Ø§. ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¹ÙŠÙˆØ¨ ÙˆØ§Ù„ØªØ´ÙˆÙŠØ´ØŒ Ø£Ùˆ Ø­ØªÙ‰ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù…Ù†Ø·Ù‚Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙŠØ¡ Ø¬Ø¯ÙŠØ¯ ØªÙ…Ø§Ù…Ù‹Ø§. ØªØ¹ØªÙ…Ø¯ Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¹Ù„Ù‰ Ù‚Ù†Ø§Ø¹ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ø±Ø§Ø¯ Ù…Ù„Ø¤Ù‡Ø§ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©Ø› Ø­ÙŠØ« ØªÙ…Ø«Ù„ Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ØŒ Ø¨ÙŠÙ†Ù…Ø§ ØªÙ…Ø«Ù„ Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡Ø§ Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±. ÙŠØªÙ… Ù…Ù„Ø¡ Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ÙˆØµÙÙŠ.

Ù…Ø¹ Ù…ÙƒØªØ¨Ø© ğŸ¤— DiffusersØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø­Ùˆ Ø§Ù„ØªØ§Ù„ÙŠ:

1. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ (Checkpoint) Ø®Ø§ØµØ© Ø¨Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¦Ø© [`AutoPipelineForInpainting`]. Ø³ÙŠØªÙ… Ø§Ù„ÙƒØ´Ù ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù† ÙØ¦Ø© Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´:

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
"kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# Ø§Ø­Ø°Ù Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† xFormers Ù…Ø«Ø¨ØªÙ‹Ø§ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ PyTorch 2.0 Ø£Ùˆ Ø£Ø¹Ù„Ù‰ Ù…Ø«Ø¨ØªÙ‹Ø§
pipeline.enable_xformers_memory_efficient_attention()
```

<Tip>
Ø³ØªÙ„Ø§Ø­Ø¸ Ø®Ù„Ø§Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø£Ù†Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… [`~DiffusionPipeline.enable_model_cpu_offload`] Ùˆ [`~DiffusionPipeline.enable_xformers_memory_efficient_attention`]ØŒ Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ²ÙŠØ§Ø¯Ø© Ø³Ø±Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… PyTorch 2.0ØŒ ÙÙ„Ø§ ÙŠÙ„Ø²Ù… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [`~DiffusionPipeline.enable_xformers_memory_efficient_attention`] Ø¹Ù„Ù‰ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨Ùƒ Ù„Ø£Ù†Ù‡Ø§ Ø³ØªØ³ØªØ®Ø¯Ù… Ø¨Ø§Ù„ÙØ¹Ù„ Ø§Ù†ØªØ¨Ø§Ù‡ [scaled-dot product](../optimization/torch2.0#scaled-dot-product-attention) Ø§Ù„Ø£ØµÙ„ÙŠ ÙÙŠ PyTorch 2.0.
</Tip>

2. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹:

```py
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")
```

3. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù†Øµ ÙˆØµÙÙŠ Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø«Ù… Ù…Ø±Ø±Ù‡ Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹:

```py
prompt = "a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k"
negative_prompt = "bad anatomy, deformed, ugly, disfigured"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">base image</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">mask image</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-cat.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">generated image</figcaption>
  </div>
</div>


## Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹

Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† ØªÙˆÙÙŠØ± ØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ØŒ Ø¥Ù„Ø§ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŒ ÙˆÙ„ÙƒÙ† Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù‚Ù†Ø§Ø¹ Ù„Ù‡Ø§. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø£Ø¯Ù†Ø§Ù‡ Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù‚Ù†Ø§Ø¹ Ø¨Ø³Ù‡ÙˆÙ„Ø©.

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø¥ÙƒÙ…Ø§Ù„Ù‡Ø§ØŒ Ø«Ù… Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ø§Ø© Ø§Ù„Ø±Ø³Ù… Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù‚Ù†Ø§Ø¹. Ø¨Ù…Ø¬Ø±Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ØŒ Ø§Ù†Ù‚Ø± ÙÙˆÙ‚ "Run" Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹ ÙˆØªØ­Ù…ÙŠÙ„Ù‡Ø§.

<iframe
  src="https://stevhliu-inpaint-mask-maker.hf.space"
  frameborder="0"
  width="850"
  height="450"
></iframe>

## Ø¯Ø±Ø¬Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ© Ø§Ù„Ù‚Ù†Ø§Ø¹

ØªÙˆÙØ± Ø·Ø±ÙŠÙ‚Ø© [`~VaeImageProcessor.blur`] Ø®ÙŠØ§Ø±Ù‹Ø§ Ù„Ø·Ø±ÙŠÙ‚Ø© Ù…Ø²Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆÙ…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥ÙƒÙ…Ø§Ù„. ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø¹Ø§Ù…Ù„ `blur_factor`. ÙŠØ¤Ø¯ÙŠ Ø²ÙŠØ§Ø¯Ø© `blur_factor` Ø¥Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ© Ø§Ù„Ù…Ø·Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ø­ÙˆØ§Ù Ø§Ù„Ù‚Ù†Ø§Ø¹ØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆÙ…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø£ÙƒØ«Ø± Ù†Ø¹ÙˆÙ…Ø©. Ø¨ÙŠÙ†Ù…Ø§ ÙŠØ­Ø§ÙØ¸ Ù…Ø¹Ø§Ù…Ù„ `blur_factor` Ø§Ù„Ù…Ù†Ø®ÙØ¶ Ø£Ùˆ Ø§Ù„ØµÙØ±ÙŠ Ø¹Ù„Ù‰ Ø­ÙˆØ§Ù Ø§Ù„Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø­Ø§Ø¯Ø©.

Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø©ØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ù†Ø§Ø¹ Ø¶Ø¨Ø§Ø¨ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ±:

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
from PIL import Image

pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to('cuda')

mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png")
blurred_mask = pipeline.mask_processor.blur(mask, blur_factor=33)
blurred_mask
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">mask with no blur</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/mask_blurred.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">mask with blur applied</figcaption>
  </div>
</div>

## Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

Ù…Ù† Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø´Ø¹Ø¨ÙŠØ© Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±: [Stable Diffusion Inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)ØŒ Ùˆ [Stable Diffusion XL (SDXL) Inpainting](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1)ØŒ Ùˆ [Kandinsky 2.2 Inpainting](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint). Ø¹Ø§Ø¯Ø© Ù…Ø§ ÙŠÙ†ØªØ¬ Ù†Ù…ÙˆØ°Ø¬ SDXL ØµÙˆØ±Ù‹Ø§ Ø°Ø§Øª Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù…Ù† Stable Diffusion v1.5ØŒ ÙƒÙ…Ø§ Ø£Ù† Kandinsky 2.2 Ù‚Ø§Ø¯Ø± Ø£ÙŠØ¶Ù‹Ø§ Ø¹Ù„Ù‰ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©.

### Stable Diffusion Inpainting

Stable Diffusion Inpainting Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†ØªØ´Ø§Ø± Ù„Ø§ØªÙŠÙ†ÙŠ ØªÙ…Øª Ù…Ø¹Ø§ÙŠØ±ØªÙ‡ Ø¹Ù„Ù‰ ØµÙˆØ± Ø¨Ø­Ø¬Ù… 512x512 Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±. Ø¥Ù†Ù‡ Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø¬ÙŠØ¯Ø© Ù„Ø£Ù†Ù‡ Ø³Ø±ÙŠØ¹ Ù†Ø³Ø¨ÙŠÙ‹Ø§ ÙˆÙŠÙ†ØªØ¬ ØµÙˆØ±Ù‹Ø§ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©. Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙ…Ø±ÙŠØ± Ù†Øµ ÙˆØµÙÙŠ ÙˆØµÙˆØ±Ø© Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØµÙˆØ±Ø© Ù‚Ù†Ø§Ø¹ Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨:

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
"runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# Ø§Ø­Ø°Ù Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† xFormers Ù…Ø«Ø¨ØªÙ‹Ø§ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ PyTorch 2.0 Ø£Ùˆ Ø£Ø¹Ù„Ù‰ Ù…Ø«Ø¨ØªÙ‹Ø§
pipeline.enable_xformers_memory_efficient_attention()

# Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### Stable Diffusion XL (SDXL) Inpainting

SDXL Ù‡Ùˆ Ø¥ØµØ¯Ø§Ø± Ø£ÙƒØ¨Ø± ÙˆØ£ÙƒØ«Ø± Ù‚ÙˆØ© Ù…Ù† Stable Diffusion v1.5. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØªØ¨Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù…Ù„ÙŠØ© Ù…ÙƒÙˆÙ†Ø© Ù…Ù† Ù…Ø±Ø­Ù„ØªÙŠÙ† (Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù…ÙØ±Ø¯Ù‡)Ø› Ø­ÙŠØ« ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø¨ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©ØŒ Ø«Ù… ÙŠÙ‚ÙˆÙ… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø¨Ø£Ø®Ø° ØªÙ„Ùƒ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­Ø³ÙŠÙ† ØªÙØ§ØµÙŠÙ„Ù‡Ø§ ÙˆØ¬ÙˆØ¯ØªÙ‡Ø§. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø¯Ù„ÙŠÙ„ [SDXL](sdxl) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ù„ÙŠÙ„ Ø£ÙƒØ«Ø± Ø´Ù…ÙˆÙ„Ø§Ù‹ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… SDXL ÙˆØªÙƒÙˆÙŠÙ† Ù…Ø¹Ø§Ù„Ù…Ù‡.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
"diffusers/stable-diffusion-xl-1.0-inpainting-0.1", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# Ø§Ø­Ø°Ù Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† xFormers Ù…Ø«Ø¨ØªÙ‹Ø§ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ PyTorch 2.0 Ø£Ùˆ Ø£Ø¹Ù„Ù‰ Ù…Ø«Ø¨ØªÙ‹Ø§
pipeline.enable_xformers_memory_efficient_attention()

# Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_Intersecting image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### Kandinsky 2.2 Inpainting

ØªØªØ´Ø§Ø¨Ù‡ Ø¹Ø§Ø¦Ù„Ø© Ù†Ù…Ø§Ø°Ø¬ Kandinsky Ù…Ø¹ SDXL Ù„Ø£Ù†Ù‡Ø§ ØªØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ø£ÙŠØ¶Ù‹Ø§Ø› Ø­ÙŠØ« ÙŠÙ‚ÙˆÙ… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¨Ø¥Ù†Ø´Ø§Ø¡ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø©ØŒ ÙˆÙŠÙ†Ø´Ø¦ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ø§Ù„ØµÙˆØ± Ù…Ù†Ù‡Ø§. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£ÙˆÙ„ÙŠØ© ÙˆÙ†Ù…ÙˆØ°Ø¬ Ø§Ù†ØªØ´Ø§Ø± Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„ØŒ ÙˆÙ„ÙƒÙ† Ø£Ø³Ù‡Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Kandinsky 2.2 Ù‡ÙŠ ØªØ­Ù…ÙŠÙ„Ù‡ ÙÙŠ ÙØ¦Ø© [`AutoPipelineForInpainting`] Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… [`KandinskyV22InpaintCombinedPipeline`] ØªØ­Øª Ø§Ù„ØºØ·Ø§Ø¡.

ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ø£Ø¯Ù†Ø§Ù‡. Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ ÙŠØ³ØªØ®Ø¯Ù… Ù…ÙƒØªØ¨Ø© xFormersØŒ Ù„Ø°Ø§ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØªÙ‡Ø§ Ù‚Ø¨Ù„ ØªØ´ØºÙŠÙ„Ù‡.

ØªÙØ¸Ù‡Ø± Ø§Ù„ØµÙˆØ± Ø£Ø¯Ù†Ø§Ù‡ Ù†ØªØ§Ø¦Ø¬ Ø§Ø³ØªØ®Ø¯Ø§Ù… Kandinsky 2.2 Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©. Ù„Ø§Ø­Ø¸ ÙƒÙŠÙ Ø£Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ ÙˆÙˆØ¶ÙˆØ­Ù‹Ø§ Ù…Ù† SD ÙˆSDXL.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdv1.5.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Stable Diffusion Inpainting</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdxl.png"/>
<figcaption class="mt-turut text-center text-sm text-gray-500">Stable Diffusion XL Inpainting</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-kandinsky.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Kandinsky 2.2 Inpainting</figcaption>
</div>
</div>


## Ù†Ù‚Ø§Ø· ØªÙØªÙŠØ´ ØºÙŠØ± Ø®Ø§ØµØ© Ø¨Ù€ Inpaint

Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· ØªÙØªÙŠØ´ Ø®Ø§ØµØ© Ø¨Ù€ Inpaint Ù…Ø«Ù„ [runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting). ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù‚Ø§Ø· ØªÙØªÙŠØ´ Ø¹Ø§Ø¯ÙŠØ© Ù…Ø«Ù„ [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5). Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ù‚Ø§Ø±Ù† Ù†ØªØ§Ø¦Ø¬ Ù†Ù‚Ø·ØªÙŠ Ø§Ù„ØªÙØªÙŠØ´.

Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø± Ù…ÙÙˆÙ„Ø¯Ø© Ù…Ù† Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ø¹Ø§Ø¯ÙŠØ©ØŒ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ† Ù…Ù† Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Inpaint. Ø³ØªÙ„Ø§Ø­Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ± Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø± Ù„ÙŠØ³Øª Ø¨Ù†ÙØ³ Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ ÙˆÙŠÙ…ÙƒÙ†Ùƒ Ø±Ø¤ÙŠØ© Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªÙŠ ÙŠÙÙØªØ±Ø¶ Ø£Ù† ØªÙ‚ÙˆÙ… Ø¨Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Inpaint. Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ† Ø£Ù†Ø¸Ù Ø¨ÙƒØ«ÙŠØ±ØŒ ÙˆØªØ¸Ù‡Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø¥ØµÙ„Ø§Ø­Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ø£ÙƒØ«Ø± Ø·Ø¨ÙŠØ¹ÙŠØ©.

<hfoptions id="regular-specific">
<hfoption id="runwayml/stable-diffusion-v1-5">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
<hfoption id="runwayml/stable-diffusion-inpainting">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
</hfoptions>

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/non-inpaint-specific.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-v1-5</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-specific.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-inpainting</figcaption>
  </div>
</div>


Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø°Ù„ÙƒØŒ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø«Ù„ Ø¥Ø²Ø§Ù„Ø© ÙƒØ§Ø¦Ù† Ù…Ù† ØµÙˆØ±Ø© (Ù…Ø«Ù„ Ø§Ù„ØµØ®ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„)ØŒ ÙØ¥Ù† Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ø¹Ø§Ø¯ÙŠØ© ØªØ¹Ø·ÙŠ Ù†ØªØ§Ø¦Ø¬ Ø¬ÙŠØ¯Ø© Ø¬Ø¯Ù‹Ø§. Ù„ÙŠØ³ Ù‡Ù†Ø§Ùƒ ÙØ±Ù‚ Ù…Ù„Ø­ÙˆØ¸ Ø¨ÙŠÙ† Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© ÙˆÙ†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Inpaint.

<hfoptions id="inpaint">
<hfoption id="runwayml/stable-diffusion-v1-5">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png")

image = pipeline(prompt="road", image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
<hfoption id="runwayml/stable-diffusion-inpaint">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png")

image = pipeline(prompt="road", image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
</hfoptions>

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/regular-inpaint-basic.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-v1-5</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/specific-inpaint-basic.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-inpainting</figcaption>
  </div>
</div>


Ø§Ù„Ù…Ù‚Ø§ÙŠØ¶Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ ØºÙŠØ± Ø®Ø§ØµØ© Ø¨Ù€ Inpaint Ù‡ÙŠ Ø£Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© Ù‚Ø¯ ØªÙƒÙˆÙ† Ø£Ù‚Ù„ØŒ ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªÙ…ÙŠÙ„ Ø¹Ù…ÙˆÙ…Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹ (ÙˆÙ‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø³Ø¨Ø¨ ÙÙŠ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø±Ø¤ÙŠØ© Ù…Ø®Ø·Ø· Ø§Ù„Ù‚Ù†Ø§Ø¹). ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù‚Ø§Ø· ØªÙØªÙŠØ´ Inpaint Ø§Ù„Ø®Ø§ØµØ© Ø¹Ù† Ù‚ØµØ¯ Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ± Ø°Ø§Øª Ø¬ÙˆØ¯Ø© Ø£Ø¹Ù„Ù‰ØŒ ÙˆØ§Ù„ØªÙŠ ØªØªØ¶Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù†ØªÙ‚Ø§Ù„ Ø£ÙƒØ«Ø± Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© ÙˆØºÙŠØ± Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©. ÙˆÙ†ØªÙŠØ¬Ø© Ù„Ø°Ù„ÙƒØŒ Ù…Ù† Ø§Ù„Ù…Ø±Ø¬Ø­ Ø£Ù† ØªØºÙŠØ± Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø§Ø· Ù…Ù†Ø·Ù‚Ø© ØºÙŠØ± Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©.

Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© ØºÙŠØ± Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ø£Ù…Ø±Ù‹Ø§ Ù…Ù‡Ù…Ù‹Ø§ Ù„Ù…Ù‡Ù…ØªÙƒØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`VaeImageProcessor.apply_overlay`] Ù„Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© ØºÙŠØ± Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ù„Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù‚Ø§Ø¡ ÙƒÙ…Ø§ Ù‡ÙŠ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© ÙˆØºÙŠØ± Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©.


```py
import PIL
import numpy as np
import torch

from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

device = "cuda"
pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    torch_dtype=torch.float16,
)
pipeline = pipeline.to(device)

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
repainted_image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]
repainted_image.save("repainted_image.png")

unmasked_unchanged_image = pipeline.image_processor.apply_overlay(mask_image, init_image, repainted_image)
unmasked_unchanged_image.save("force_unmasked_unchanged.png")
make_image_grid([init_image, mask_image, repainted_image, unmasked_unchanged_image], rows=2, cols=2)
```



## ØªÙƒÙˆÙŠÙ† Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨

ØªØ¹ØªÙ…Ø¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ±Ø© - Ù…Ø«Ù„ Ø§Ù„Ø¬ÙˆØ¯Ø© Ùˆ"Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹" - Ø¹Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨. Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ù…Ø¹Ø±ÙØ© Ù…Ø§ ØªÙØ¹Ù„Ù‡ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø±Ø¬ÙˆØ©. Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ù„Ù‚ÙŠ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø£Ù‡Ù… Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª ÙˆÙ†Ø±Ù‰ ÙƒÙŠÙ ÙŠØ¤Ø«Ø± ØªØºÙŠÙŠØ±Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.

### Ø§Ù„Ù‚ÙˆØ©

`strength` Ù‡ÙŠ Ù…Ù‚ÙŠØ§Ø³ Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ù…Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.

- ğŸ“ˆ Ù‚ÙŠÙ…Ø© Ø¹Ø§Ù„ÙŠØ© Ù„Ù€ `strength` ØªØ¹Ù†ÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ³ØªØºØ±Ù‚ Ø¹Ù…Ù„ÙŠØ© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙˆÙŠØ´ ÙˆÙ‚ØªÙ‹Ø§ Ø£Ø·ÙˆÙ„ØŒ ÙˆÙ„ÙƒÙ†Ùƒ Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© ØªØ®ØªÙ„Ù Ø£ÙƒØ«Ø± Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

- ğŸ“‰ Ù‚ÙŠÙ…Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù€ `strength` ØªØ¹Ù†ÙŠ Ø¥Ø¶Ø§ÙØ© Ù‚Ø¯Ø± Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªÙƒÙˆÙ† Ø¹Ù…Ù„ÙŠØ© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙˆÙŠØ´ Ø£Ø³Ø±Ø¹ØŒ ÙˆÙ„ÙƒÙ† Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¬ÙŠØ¯Ø© ÙˆÙ‚Ø¯ ØªØ´Ø¨Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£ÙƒØ«Ø±


```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.6).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.6.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.6</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.8.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.8</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-1.0.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 1.0</figcaption>
  </div>
</div>


### Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡

`guidance_scale` ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ ØªÙˆØ§ÙÙ‚ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©.

- ğŸ“ˆ Ù‚ÙŠÙ…Ø© Ø¹Ø§Ù„ÙŠØ© Ù„Ù€ `guidance_scale` ØªØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù…ÙˆØ¬Ù‡ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù…ØªÙˆØ§ÙÙ‚Ø§Ù† Ø¨Ø´ÙƒÙ„ ÙˆØ«ÙŠÙ‚ØŒ Ù„Ø°Ø§ ÙØ¥Ù† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù‡Ùˆ ØªÙØ³ÙŠØ± Ø£ÙƒØ«Ø± ØµØ±Ø§Ù…Ø© Ù„Ù„Ù…ÙˆØ¬Ù‡

- ğŸ“‰ Ù‚ÙŠÙ…Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù€ `guidance_scale` ØªØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù…ÙˆØ¬Ù‡ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù…ØªÙˆØ§ÙÙ‚Ø§Ù† Ø¨Ø´ÙƒÙ„ ÙØ¶ÙØ§Ø¶ØŒ Ù„Ø°Ø§ ÙÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø£ÙƒØ«Ø± ØªÙ†ÙˆØ¹Ù‹Ø§ Ø¹Ù† Ø§Ù„Ù…ÙˆØ¬Ù‡

ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… `strength` Ùˆ`guidance_scale` Ù…Ø¹Ù‹Ø§ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ù…Ø¯Ù‰ ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠÙ…Ù†Ø­ Ù…Ø²ÙŠØ¬ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ù„Ù€ `strength` Ùˆ`guidance_scale` Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ¨Ø± Ù‚Ø¯Ø± Ù…Ù† Ø§Ù„Ø­Ø±ÙŠØ© Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, guidance_scale=2.5).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-2.5.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 2.5</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-7.5.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 7.5</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-12.5.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 12.5</figcaption>
  </div>
</div>


### Ù…ÙˆØ¬Ù‡ Ø³Ù„Ø¨ÙŠ

ÙŠÙØªØ±Ø¶ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø§Ù„Ø³Ù„Ø¨ÙŠ Ø§Ù„Ø¯ÙˆØ± Ø§Ù„Ù…Ø¹Ø§ÙƒØ³ Ù„Ù„Ù…ÙˆØ¬Ù‡Ø› ÙÙ‡Ùˆ ÙŠÙˆØ¬Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹ÙŠØ¯Ù‹Ø§ Ø¹Ù† ØªÙˆÙ„ÙŠØ¯ Ø£Ø´ÙŠØ§Ø¡ Ù…Ø¹ÙŠÙ†Ø© ÙÙŠ ØµÙˆØ±Ø©. ÙˆÙ‡Ø°Ø§ Ù…ÙÙŠØ¯ Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø³Ø±Ø¹Ø© ÙˆÙ…Ù†Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø£Ø´ÙŠØ§Ø¡ Ù„Ø§ ØªØ±ÙŠØ¯Ù‡Ø§.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
negative_prompt = "bad architecture, unstable, poor details, blurry"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex justify-center">
  <figure>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-negative.png" />
    <figcaption class="text-center">negative_prompt = "bad architecture, unstable, poor details, blurry"</figcaption>
  </figure>
</div>


### Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ù…Ø­ØµÙˆÙ„

ØªØªÙ…Ø«Ù„ Ø¥Ø­Ø¯Ù‰ Ø·Ø±Ù‚ Ø²ÙŠØ§Ø¯Ø© Ø¬ÙˆØ¯Ø© ØµÙˆØ±Ø© Ø§Ù„Ø­Ø´Ùˆ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø© [`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop). Ø¹Ù†Ø¯Ù…Ø§ ÙŠØªÙ… ØªÙ…ÙƒÙŠÙ† Ù‡Ø°Ø§ Ø§Ù„Ø®ÙŠØ§Ø±ØŒ ÙØ¥Ù†Ù‡ ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù‚ØªØµØ§Øµ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ø¨Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø°ÙŠ ÙŠØ­Ø¯Ø¯Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙƒÙ…Ø§ Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù‚ØªØµØ§Øµ Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©. ÙŠØªÙ… ØªÙƒØ¨ÙŠØ± ÙƒÙ„ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ù‚Ù†Ø§Ø¹ Ø¥Ù„Ù‰ Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù„Ù„Ø­Ø´ÙˆØŒ Ø«Ù… ÙŠØªÙ… ÙˆØ¶Ø¹Ù‡Ù…Ø§ ÙÙˆÙ‚ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©. Ù‡Ø°Ù‡ Ø·Ø±ÙŠÙ‚Ø© Ø³Ø±ÙŠØ¹Ø© ÙˆØ³Ù‡Ù„Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…Ù†ÙØµÙ„ Ù…Ø«Ù„ [`StableDiffusionUpscalePipeline`].

Ø£Ø¶Ù Ù…Ø¹Ù„Ù…Ø© `padding_mask_crop` Ø¥Ù„Ù‰ Ù…ÙƒØ§Ù„Ù…Ø© Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙˆÙ‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ†Ù‡Ø§ Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©.
```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
from PIL import Image

generator = torch.Generator(device='cuda').manual_seed(0)
pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to('cuda')

base = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore.png")
mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png")

image = pipeline("boat", image=base, mask_image=mask, strength=0.75, generator=generator, padding_mask_crop=32).images[0]
image
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/baseline_inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">default inpaint image</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/padding_mask_crop_inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint image with `padding_mask_crop` enabled</figcaption>
  </div>
</div>


### Ø®Ø·ÙˆØ· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø©

ÙŠÙ…ÙƒÙ† ØªØ³Ù„Ø³Ù„ [`AutoPipelineForInpainting`] Ù…Ø¹ Ø®Ø·ÙˆØ· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø£Ø®Ø±Ù‰ Ù…Ù† ğŸ¤— Diffusers Ù„ØªØ­Ø±ÙŠØ± Ø¥Ø®Ø±Ø§Ø¬Ù‡Ø§. ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù…ÙÙŠØ¯Ù‹Ø§ Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù…Ù† Ø®Ø·ÙˆØ· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ ÙˆØ¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ø®Ø·ÙˆØ· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…ØªØ¹Ø¯Ø¯Ø©ØŒ ÙÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ØªØ³Ù„Ø³Ù„Ù‡Ø§ Ù…Ø¹Ù‹Ø§ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙÙŠ Ù…Ø³Ø§Ø­Ø© Ø®ÙÙŠØ© ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ù…ÙƒÙˆÙ†Ø§Øª Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨.

### Ø±Ø¨Ø· Ø§Ù„Ù†Øµ Ø¨Ø§Ù„ØµÙˆØ±Ø© Ø«Ù… Ø¥ØµÙ„Ø§Ø­Ù‡Ø§

ÙŠØªÙŠØ­ Ø±Ø¨Ø· Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…Ù† Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©ØŒ ÙˆÙ„Ø§ ÙŠÙ„Ø²Ù…Ùƒ ØªÙˆÙÙŠØ± ØµÙˆØ±Ø© Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡. ÙŠØ¬Ø¹Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ù…Ø±ÙŠØ­Ù‹Ø§ Ù„ØªØ­Ø±ÙŠØ± Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù„Ø¯ÙŠÙƒ Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© ØªÙ…Ø§Ù…Ù‹Ø§.

Ø§Ø¨Ø¯Ø£ Ø¨Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…Ù† Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ù„Ø¹Ø©:


```py
import torch
from diffusers import AutoPipelineForText2Image, AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k").images[0]
```


Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹ Ù…Ù† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø£Ø¹Ù„Ø§Ù‡:
```py
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_text-chain-mask.png")
```

ÙˆØ§Ù„Ø¢Ù† Ø¯Ø¹ÙˆÙ†Ø§ Ù†ØµÙ„Ø­ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ø¨Ø´Ù„Ø§Ù„:

```py
pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "digital painting of a fantasy waterfall, cloudy"
image = pipeline(prompt=prompt, image=text2image, mask_image=mask_image).images[0]
make_image_grid([text2image, mask_image, image], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">text-to-image</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain-out.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint</figcaption>
  </div>
</div>

### Ø¥ØµÙ„Ø§Ø­ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø©

ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø±Ø¨Ø· Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ù‚Ø¨Ù„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¢Ø®Ø± Ù…Ø«Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø£Ùˆ Ø£Ø¯Ø§Ø© ØªÙƒØ¨ÙŠØ± Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©.

Ø§Ø¨Ø¯Ø£ Ø¨Ø¥ØµÙ„Ø§Ø­ ØµÙˆØ±Ø©:

```py
import torch
from diffusers import AutoPipelineForInpainting, AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image_inpainting = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]

# resize image to 1024x1024 for SDXL
image_inpainting = image_inpainting.resize((1024, 1024))
```

Ø§Ù„Ø¢Ù† Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ù…Ø±Ø± Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¥ØµÙ„Ø§Ø­ Ø¢Ø®Ø± Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ SDXL refiner Ù„ØªØ­Ø³ÙŠÙ† ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©:

```py
pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image_inpainting, mask_image=mask_image, output_type="latent").images[0]
```

<Tip>
Ù…Ù† Ø§Ù„Ù…Ù‡Ù… ØªØ­Ø¯ÙŠØ¯ output_type="latent" ÙÙŠ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙÙŠ Ù…Ø³Ø§Ø­Ø© Ø§Ù„ÙƒØ§Ù…Ù†Ø© Ù„ØªØ¬Ù†Ø¨ Ø®Ø·ÙˆØ© Ø§Ù„ØªØ±Ù…ÙŠØ² ÙÙƒ Ø§Ù„ØªØ±Ù…ÙŠØ² ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©. ÙŠØ¹Ù…Ù„ Ù‡Ø°Ø§ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø© ØªØ³ØªØ®Ø¯Ù… Ù†ÙØ³ VAE. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙÙŠ Ù‚Ø³Ù… [Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¥ØµÙ„Ø§Ø­](#text-to-image-to-inpaint)ØŒ ÙŠØ³ØªØ®Ø¯Ù… Kandinsky 2.2 ÙØ¦Ø© VAE Ù…Ø®ØªÙ„ÙØ© Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬ Stable Diffusion Ù„Ø°Ù„Ùƒ Ù„Ù† ÙŠØ¹Ù…Ù„. ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Øª Stable Diffusion v1.5 Ù„ÙƒÙ„ Ù…Ù† Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙƒÙ„ Ø´ÙŠØ¡ ÙÙŠ Ù…Ø³Ø§Ø­Ø© Ø§Ù„ÙƒØ§Ù…Ù†Ø© Ù„Ø£Ù†Ù‡Ø§ ØªØ³ØªØ®Ø¯Ù… Ø¬Ù…ÙŠØ¹Ù‡Ø§ [`AutoencoderKL`].
</Tip>

Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù„Ù…Ø³Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø¹Ù„ÙŠÙ‡Ø§. Ù…Ù† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`~AutoPipelineForImage2Image.from_pipe`] Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒÙˆÙ†Ø§Øª Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ ÙˆØªØ¬Ù†Ø¨ ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙˆÙ†Ø§Øª Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¯ÙˆÙ† Ø¯Ø§Ø¹.

```py
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline)
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image_inpainting, image], rows=2, cols=2)
```

<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-chain.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Ø¥ØµÙ„Ø§Ø­</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-final.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©</figcaption>
</div>
</div>

ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ØŒ Ø§Ù„Ø¥ØµÙ„Ø§Ø­ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù‡Ø§Ù… Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ø¬Ø¯Ù‹Ø§. ØªÙ‚ÙˆÙ… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø¨ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© ØªØ´Ø¨Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©. ÙŠÙØ¹Ù„ Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø´ÙŠØ¡ Ù†ÙØ³Ù‡ØŒ ÙˆÙ„ÙƒÙ†Ù‡ ÙŠØ­ÙˆÙ„ ÙÙ‚Ø· Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ Ø­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ù‚Ù†Ø§Ø¹ ÙˆÙŠØ¸Ù„ Ø¨Ø§Ù‚ÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ø¥ØµÙ„Ø§Ø­ ÙƒØ£Ø¯Ø§Ø© Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ù„Ø¥Ø¬Ø±Ø§Ø¡ ØªØºÙŠÙŠØ±Ø§Øª Ù…Ø­Ø¯Ø¯Ø© ÙˆÙ„Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù†Ø·Ø§Ù‚ Ø£ÙˆØ³Ø¹ Ù„Ø¥Ø¬Ø±Ø§Ø¡ ØªØºÙŠÙŠØ±Ø§Øª ÙˆØ§Ø³Ø¹Ø© Ø§Ù„Ù†Ø·Ø§Ù‚.


## Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±

Ù…Ù† Ø§Ù„ØµØ¹Ø¨ Ø¬Ø¹Ù„ Ø§Ù„ØµÙˆØ±Ø© ØªØ¨Ø¯Ùˆ Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ ØªØ±ÙŠØ¯ Ù„Ø£Ù† Ø¹Ù…Ù„ÙŠØ© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙˆÙŠØ´ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©. ÙÙŠ Ø­ÙŠÙ† Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø¬ÙˆØ§Ù†Ø¨ Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙƒÙˆÙŠÙ† Ù…Ø¹Ù„Ù…Ø§Øª Ù…Ø«Ù„ "negative_prompt"ØŒ Ù‡Ù†Ø§Ùƒ Ø·Ø±Ù‚ Ø£ÙØ¶Ù„ ÙˆØ£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±.

### ÙˆØ²Ù† Ø§Ù„ÙØ­Øµ

ÙŠÙˆÙØ± ÙˆØ²Ù† Ø§Ù„ÙØ­Øµ Ø·Ø±ÙŠÙ‚Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„ÙƒÙ…ÙŠ Ù„Ù‚ÙŠØ§Ø³ Ø­Ø¬Ù… ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… ÙÙŠ ÙØ­Øµ. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ø²ÙŠØ§Ø¯Ø© Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ù…ØªØ¬Ù‡ ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†Øµ Ù„ÙƒÙ„ Ù…ÙÙ‡ÙˆÙ… ÙÙŠ Ø§Ù„ÙØ­ØµØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØ­Ø¯Ø¯ Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ Ù…Ù‚Ø¯Ø§Ø± ÙƒÙ„ Ù…ÙÙ‡ÙˆÙ… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡. ØªÙˆÙØ± Ù…ÙƒØªØ¨Ø© [Compel](https://github.com/damian0815/compel) Ø¨Ù†Ø§Ø¡ Ø¬Ù…Ù„Ø© Ø¨Ø¯ÙŠÙ‡ÙŠ Ù„Ù‚ÙŠØ§Ø³ Ø£ÙˆØ²Ø§Ù† Ø§Ù„ÙØ­Øµ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª. ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª ÙÙŠ Ø¯Ù„ÙŠÙ„ [ÙˆØ²Ù† Ø§Ù„ÙØ­Øµ](../using-diffusers/weighted_prompts).

Ø¨Ù…Ø¬Ø±Ø¯ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§ØªØŒ Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© "prompt_embeds" (Ùˆ"negative_prompt_embeds" Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… ÙØ­ØµÙ‹Ø§ Ø³Ù„Ø¨ÙŠÙ‹Ø§) ÙÙŠ ["AutoPipelineForInpainting"]. ØªØ­Ù„ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ù…Ø­Ù„ Ù…Ø¹Ù„Ù…Ø© "Ø§Ù„ÙØ­Øµ":

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, # generated from Compel
    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel
    image=init_image,
    mask_image=mask_image
).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```



### ControlNet

ØªÙØ³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ ControlNet Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ø§Ù„Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„ Stable DiffusionØŒ ÙˆØªÙˆÙØ± Ø·Ø±ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© ÙˆØ¯Ù‚Ø© Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ ÙƒÙŠÙÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©. ØªÙ‚Ø¨Ù„ ControlNet Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØ±Ø© ØªÙƒÙŠÙŠÙ Ø¥Ø¶Ø§ÙÙŠØ© ØªÙˆØ¬Ù‡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠÙ‡Ø§.

Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¯Ø¹Ù†Ø§ Ù†ÙÙƒÙŠÙ‘Ù ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ControlNet Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ ØµÙˆØ± Inpaint:

```py
import torch
import numpy as np
from diffusers import ControlNetModel, StableDiffusionControlNetInpaintPipeline
from diffusers.utils import load_image, make_image_grid

# load ControlNet
controlnet = ControlNetModel.from_pretrained("lllyasviel/control_v11p_sd15_inpaint", torch_dtype=torch.float16, variant="fp16")

# pass ControlNet to the pipeline
pipeline = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

# prepare control image
def make_inpaint_condition(init_image, mask_image):
    init_image = np.array(init_image.convert("RGB")).astype(np.float32) / 255.0
    mask_image = np.array(mask_image.convert("L")).astype(np.float32) / 255.0

    assert init_image.shape[0:1] == mask_image.shape[0:1], "image and image_mask must have the same image size"
    init_image[mask_image > 0.5] = -1.0  # set as masked pixel
    init_image = np.expand_dims(init_image, 0).transpose(0, 3, 1, 2)
    init_image = torch.from_numpy(init_image)
    return init_image

control_image = make_inpaint_condition(init_image, mask_image)
```

Ø§Ù„Ø¢Ù†ØŒ Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØµÙˆØ±Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹ ÙˆØµÙˆØ±Ø© Ø§Ù„ØªØ­ÙƒÙ…. Ø³ØªÙ„Ø§Ø­Ø¸ Ø£Ù† Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø´Ø¯Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©.

```py
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, control_image=control_image).images[0]
make_image_grid([init_image, mask_image, PIL.Image.fromarray(np.uint8(control_image[0][0])).convert('RGB'), image], rows=2, cols=2)
```

ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ù…Ø¶ÙŠ Ù‚Ø¯Ù…Ù‹Ø§ Ø®Ø·ÙˆØ© Ø£Ø®Ø±Ù‰ ÙˆØ³Ù„Ø³Ù„Ø© Ù…Ø¹ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø£Ø³Ù„ÙˆØ¨ Ø¬Ø¯ÙŠØ¯:
```py
from diffusers import AutoPipelineForImage2Image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style castle" # include the token "elden ring style" in the prompt
negative_prompt = "bad architecture, deformed, disfigured, poor details"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image, image_elden_ring], rows=2, cols=2)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">initial image</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-controlnet.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">ControlNet inpaint</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-img2img.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">image-to-image</figcaption>
  </div>
</div>

## Ø§Ù„ØªØ­Ø³ÙŠÙ†

Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„ØµØ¹Ø¨ ÙˆØ§Ù„Ø¨Ø·ÙŠØ¡ ØªØ´ØºÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ù‚ÙŠÙˆØ¯ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø¹Ø¶ Ø§Ù„Ø­ÙŠÙ„ Ø§Ù„ØªØ­Ø³ÙŠÙ†ÙŠØ©. Ø£Ø­Ø¯ Ø£ÙƒØ¨Ø± Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª (ÙˆØ£Ø³Ù‡Ù„Ù‡Ø§) Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…ÙƒÙŠÙ†Ù‡Ø§ Ù‡Ùˆ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„ÙƒÙØ¡ Ù„Ù„Ø°Ø§ÙƒØ±Ø©. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… PyTorch 2.0ØŒ ÙŠØªÙ… ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù…ÙÙ…ÙÙŠØ² ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ØŒ ÙˆÙ„Ø§ ÙŠÙ„Ø²Ù… Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ PyTorch ØºÙŠØ± 2.0ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ«Ø¨ÙŠØª ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ†ÙÙŠØ° xFormers Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø§Ù„ÙƒÙØ¡ Ù„Ù„Ø°Ø§ÙƒØ±Ø©. ÙƒÙ„Ø§ Ø§Ù„Ø®ÙŠØ§Ø±ÙŠÙ† ÙŠÙ‚Ù„Ù„Ø§Ù† Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆÙŠÙØ³Ø±Ø¹Ø§Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„.

ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©:

```diff
+ pipeline.enable_xformers_memory_efficient_attention()
+ pipeline.enable_model_cpu_offload()
```


Ù„Ø²ÙŠØ§Ø¯Ø© ØªØ³Ø±ÙŠØ¹ Ø±Ù…Ø² Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ Ø§Ø³ØªØ®Ø¯Ù… [torch_compile](../optimization/torch2.0#torchcompile). ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ù„Ù [torch.compile](https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile) Ø­ÙˆÙ„ Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒØ«Ø§ÙØ© ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙˆØ§Ù„Ø°ÙŠ ÙŠÙƒÙˆÙ† Ø¹Ø§Ø¯Ø©Ù‹ UNet:

```py
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```

ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ ÙÙŠ Ø£Ø¯Ù„Ø© [ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©](../optimization/memory) Ùˆ [Torch 2.0](../optimization/torch2.0).