## ØªÙ‚ÙŠÙŠÙ… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± 

ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ© Ù…Ø«Ù„ [Stable Diffusion](https://huggingface.co/docs/diffusers/stable_diffusion) Ù‡Ùˆ Ø£Ù…Ø± Ø°Ø§ØªÙŠ Ø¨Ø·Ø¨ÙŠØ¹ØªÙ‡. ÙˆÙ„ÙƒÙ† ÙƒÙ…Ù…Ø§Ø±Ø³ÙŠÙ† ÙˆØ¨Ø§Ø­Ø«ÙŠÙ†ØŒ ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ÙŠØªØ¹ÙŠÙ† Ø¹Ù„ÙŠÙ†Ø§ Ø§ØªØ®Ø§Ø° Ø®ÙŠØ§Ø±Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ù† Ø¨ÙŠÙ† Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©. Ù„Ø°Ù„ÙƒØŒ Ø¹Ù†Ø¯ Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ÙŠØ© Ù…Ø®ØªÙ„ÙØ© (Ù…Ø«Ù„ GANs Ùˆ DiffusionØŒ Ø¥Ù„Ø®)ØŒ ÙƒÙŠÙ Ù†Ø®ØªØ§Ø± Ø£Ø­Ø¯Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø¢Ø®Ø±ØŸ

ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ÙˆØ¹ÙŠ Ù„Ù…Ø«Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø±Ø¶Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆÙ‚Ø¯ ÙŠØ¤Ø«Ø± Ø¨Ø´ÙƒÙ„ ØºÙŠØ± ØµØ­ÙŠØ­ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Ø§Ø±. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ÙØ¥Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙƒÙ…ÙŠØ© Ù„Ø§ ØªØªÙˆØ§ÙÙ‚ Ø¨Ø§Ù„Ø¶Ø±ÙˆØ±Ø© Ù…Ø¹ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©. Ù„Ø°Ù„ÙƒØŒ Ø¹Ø§Ø¯Ø© Ù…Ø§ ÙŠÙˆÙØ± Ù…Ø²ÙŠØ¬ Ù…Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ù†ÙˆØ¹ÙŠØ© ÙˆØ§Ù„ÙƒÙ…ÙŠØ© Ø¥Ø´Ø§Ø±Ø© Ø£Ù‚ÙˆÙ‰ Ø¹Ù†Ø¯ Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¢Ø®Ø±.

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©ØŒ Ù†Ù‚Ø¯Ù… Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© ØºÙŠØ± Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ù†ÙˆØ¹ÙŠØ© ÙˆØ§Ù„ÙƒÙ…ÙŠØ© Ù„ØªÙ‚ÙŠÙŠÙ… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±. ÙˆØ¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„ÙƒÙ…ÙŠØ©ØŒ Ù†Ø±ÙƒØ² Ø¨Ø´ÙƒÙ„ Ø®Ø§Øµ Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© ØªÙ†ÙÙŠØ°Ù‡Ø§ Ø¥Ù„Ù‰ Ø¬Ø§Ù†Ø¨ `diffusers`.

ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¶Ø­Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù…Ø¹ ØªØ«Ø¨ÙŠØª Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.

## Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª

Ù†ØºØ·ÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ù…Ø¹ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ØªØ§Ù„ÙŠØ©:

- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© Ø¨Ø§Ù„Ù†Øµ (Ù…Ø«Ù„ [`StableDiffusionPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/text2img)).
- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© Ø¨Ø§Ù„Ù†ØµØŒ Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø£ÙŠØ¶Ù‹Ø§ Ø¨ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ù…Ø«Ù„ [`StableDiffusionImg2ImgPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/img2img) Ùˆ [`StableDiffusionInstructPix2PixPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/pix2pix)).
- Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø§Ù„ÙØµÙ„ (Ù…Ø«Ù„ [`DiTPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/dit)).

## Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ÙˆØ¹ÙŠ

ÙŠÙ†Ø·ÙˆÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ÙˆØ¹ÙŠ Ø¹Ø§Ø¯Ø© Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ… Ø¨Ø´Ø±ÙŠ Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©. ÙˆØªÙÙ‚Ø§Ø³ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø¹Ø¨Ø± Ø¬ÙˆØ§Ù†Ø¨ Ù…Ø«Ù„ Ø§Ù„ØªÙƒÙˆÙŠÙ†ØŒ ÙˆØ§Ù„Ù…Ø­Ø§Ø°Ø§Ø© Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ù†ØµØŒ ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©. ØªÙˆÙØ± Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø¯Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ØªÙˆØ­ÙŠØ¯ Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø°Ø§ØªÙŠØ©.

DrawBench Ùˆ PartiPrompts Ù‡ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ø§Ù„Ù†ÙˆØ¹ÙŠØ©. ØªÙ… ØªÙ‚Ø¯ÙŠÙ… DrawBench Ùˆ PartiPrompts Ø¨ÙˆØ§Ø³Ø·Ø© [Imagen](https://imagen.research.google/) Ùˆ [Parti](https://parti.research.google/) Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ§Ù„ÙŠ.

Ù…Ù† [Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ Ù„Ù€ Parti](https://parti.research.google/):

> PartiPrompts (P2) Ù‡ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© ØºÙ†ÙŠØ© ØªØ¶Ù… Ø£ÙƒØ«Ø± Ù…Ù† 1600 Ù…Ø·Ø§Ù„Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù†Ù‚ÙˆÙ… Ø¨Ø¥ØµØ¯Ø§Ø±Ù‡Ø§ ÙƒØ¬Ø²Ø¡ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…Ù„. ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… P2 Ù„Ù‚ÙŠØ§Ø³ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø¨Ø± Ù…Ø®ØªÙ„Ù Ø§Ù„ÙØ¦Ø§Øª ÙˆØªØ­Ø¯ÙŠØ§Øª Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨.

![parti-prompts](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/parti-prompts.png)

ÙŠØ­ØªÙˆÙŠ PartiPrompts Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:

- Ù…Ø·Ø§Ù„Ø¨Ø©
- ÙØ¦Ø© Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© (Ù…Ø«Ù„ "Ù…Ø¬Ø±Ø¯Ø©"ØŒ "Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ø§Ù„Ù…"ØŒ Ø¥Ù„Ø®)
- Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ¹ÙƒØ³ Ø§Ù„ØµØ¹ÙˆØ¨Ø© (Ù…Ø«Ù„ "Ø£Ø³Ø§Ø³ÙŠ"ØŒ "Ù…Ø¹Ù‚Ø¯"ØŒ "Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙˆØ§Ù„Ø±Ù…ÙˆØ²"ØŒ Ø¥Ù„Ø®)

ØªØ³Ù…Ø­ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ø¨Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.

Ù„Ù‡Ø°Ø§ØŒ Ù‚Ø§Ù… ÙØ±ÙŠÙ‚ ğŸ§¨ Diffusers Ø¨Ø¨Ù†Ø§Ø¡ **Open Parti Prompts**ØŒ ÙˆÙ‡Ùˆ Ù…Ø¹ÙŠØ§Ø± Ù…Ø±Ø¬Ø¹ÙŠ Ù†ÙˆØ¹ÙŠ Ù…Ø¯ÙÙˆØ¹ Ø¨Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Parti Prompts Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø­Ø¯Ø« Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø±:

- [Open Parti Prompts Game](https://huggingface.co/spaces/OpenGenAI/open-parti-prompts): Ù„Ø¹Ø´Ø±Ø© Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù…Ù† PartiØŒ ÙŠØªÙ… Ø¹Ø±Ø¶ Ø£Ø±Ø¨Ø¹ ØµÙˆØ±ØŒ ÙˆÙŠØ®ØªØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„.
- [Open Parti Prompts Leaderboard](https://huggingface.co/spaces/OpenGenAI/parti-prompts-leaderboard): Ù„ÙˆØ­Ø© Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙŠ ØªÙ‚Ø§Ø±Ù† Ø£ÙØ¶Ù„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ø¨Ø¹Ø¶Ù‡Ø§ Ø§Ù„Ø¨Ø¹Ø¶.

Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØ± ÙŠØ¯ÙˆÙŠÙ‹Ø§ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø±Ù‰ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… `diffusers` Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ PartiPrompts.

ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ù…Ù†Ù‡Ø§ Ø¹Ø¨Ø± ØªØ­Ø¯ÙŠØ§Øª Ù…Ø®ØªÙ„ÙØ©: Basic Ùˆ Complex Ùˆ Linguistic Structures Ùˆ Imagination Ùˆ Writing & Symbols. Ù‡Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… PartiPrompts ÙƒÙ€ [Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª](https://huggingface.co/datasets/nateraw/parti-prompts).

```python
from datasets import load_dataset

# prompts = load_dataset("nateraw/parti-prompts", split="train")
# prompts = prompts.shuffle()
# sample_prompts = [prompts[i]["Prompt"] for i in range(5)]

# ØªØ«Ø¨ÙŠØª Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ù„ØµØ§Ù„Ø­ Ø§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„ØªÙƒØ±Ø§Ø±.
sample_prompts = [
"a corgi",
"a hot air balloon with a yin-yang symbol, with the moon visible in the daytime sky",
"a car with no windows",
"a cube made of porcupine",
'The saying "BE EXCELLENT TO EACH OTHER" written on a red brick wall with a graffiti image of a green alien wearing a tuxedo. A yellow fire hydrant is on a sidewalk in the foreground.',
]
```

Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Stable Diffusion ([v1-4 checkpoint](https://huggingface.co/CompVis/stable-diffusion-v1-4)):

```python
import torch

seed = 0
generator = torch.manual_seed(seed)

images = sd_pipeline(sample_prompts, num_images_per_prompt=1, generator=generator).images
```

![parti-prompts-14](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/parti-prompts-14.png)

ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø£ÙŠØ¶Ù‹Ø§ ØªØ¹ÙŠÙŠÙ† `num_images_per_prompt` ÙˆÙÙ‚Ù‹Ø§ Ù„Ø°Ù„Ùƒ Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ØµÙˆØ± Ù…Ø®ØªÙ„ÙØ© Ù„Ù†ÙØ³ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©. ÙŠØ¤Ø¯ÙŠ ØªØ´ØºÙŠÙ„ Ù†ÙØ³ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙˆÙ„ÙƒÙ† Ù…Ø¹ Ù†Ù‚Ø·Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© Ù…Ø®ØªÙ„ÙØ© ([v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)) Ø¥Ù„Ù‰ Ù…Ø§ ÙŠÙ„ÙŠ:

![parti-prompts-15](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/parti-prompts-15.png)

Ø¨Ù…Ø¬Ø±Ø¯ ØªÙˆÙ„ÙŠØ¯ Ø¹Ø¯Ø© ØµÙˆØ± Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø© (Ù‚ÙŠØ¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…)ØŒ ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ Ù…Ù‚ÙŠÙ…ÙŠÙ† Ø¨Ø´Ø±ÙŠÙŠÙ† Ù„Ù„ØªØµÙ†ÙŠÙ. Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ Ù…Ø¹Ø§ÙŠÙŠØ± DrawBench Ùˆ PartiPrompts Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ Ø£ÙˆØ±Ø§Ù‚Ù‡Ù… Ø§Ù„Ø¨Ø­Ø«ÙŠØ©.

<Tip>
Ù…Ù† Ø§Ù„Ù…ÙÙŠØ¯ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ø¨Ø¹Ø¶ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø£Ø«Ù†Ø§Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø­Ø±Ø² ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. ÙÙŠ [Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨](https://github.com/huggingface/diffusers/tree/main/examples/) Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù†Ø§ØŒ Ù†Ø¯Ø¹Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ© Ù…Ø¹ Ø¯Ø¹Ù… Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ TensorBoard Ùˆ Weights & Biases.
</Tip>

## Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙƒÙ…ÙŠ

ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù…ØŒ Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ø±Ø´Ø§Ø¯Ùƒ Ø®Ù„Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© ØªÙ‚ÙŠÙŠÙ… Ø«Ù„Ø§Ø« Ø®Ø·ÙˆØ· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù†ØªØ´Ø§Ø± Ù…Ø®ØªÙ„ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:

- Ù†ØªÙŠØ¬Ø© CLIP
- Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠ CLIP
- FID

### ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© Ø¨Ø§Ù„Ù†Øµ

[Ù†ØªÙŠØ¬Ø© CLIP](https://arxiv.org/abs/2104.08718) ØªÙ‚ÙŠØ³ ØªÙˆØ§ÙÙ‚ Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©. ØªØ´ÙŠØ± Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù„Ù†ØªÙŠØ¬Ø© CLIP Ø¥Ù„Ù‰ ØªÙˆØ§ÙÙ‚ Ø£Ø¹Ù„Ù‰ ğŸ”¼. Ù†ØªÙŠØ¬Ø© CLIP Ù‡ÙŠ Ù‚ÙŠØ§Ø³ ÙƒÙ…ÙŠ Ù„Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ù†ÙˆØ¹ÙŠ "Ø§Ù„ØªÙˆØ§ÙÙ‚". ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø¹ØªØ¨Ø§Ø± ØªÙˆØ§ÙÙ‚ Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¹Ù„Ù‰ Ø£Ù†Ù‡ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ. ÙˆÙ‚Ø¯ ÙˆØ¬Ø¯ Ø£Ù† Ù†ØªÙŠØ¬Ø© CLIP Ù„Ù‡Ø§ Ø¹Ù„Ø§Ù‚Ø© Ù‚ÙˆÙŠØ© Ø¨Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø¨Ø´Ø±ÙŠ.

Ù‚Ù… Ø£ÙˆÙ„Ø§Ù‹ Ø¨ØªØ­Ù…ÙŠÙ„ [`StableDiffusionPipeline`]:

```python
from diffusers import StableDiffusionPipeline
import torch

model_ckpt = "CompVis/stable-diffusion-v1-4"
sd_pipeline = StableDiffusionPipeline.from_pretrained(model_ckpt, torch_dtype=torch.float16).to("cuda")
```

Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©:

```python
prompts = [
"a photo of an astronaut riding a horse on mars",
"A high tech solarpunk utopia in the Amazon rainforest",
"A pikachu fine dining with a view to the Eiffel Tower",
"A mecha robot in a favela in expressionist style",
"an insect robot preparing a delicious meal",
"A small cabin on top of a snowy mountain in the style of Disney, artstation",
]

images = sd_pipeline(prompts, num_images_per_prompt=1, output_type="np").images

print(images.shape)
# (6, 512, 512, 3)
```

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø­Ø³Ø§Ø¨ Ù†ØªÙŠØ¬Ø© CLIP.

```python
from torchmetrics.functional.multimodal import clip_score
from functools import partial

clip_score_fn = partial(clip_score, model_name_or_path="openai/clip-vit-base-patch16")

def calculate_clip_score(images, prompts):
images_int = (images * 255).astype("uint8")
clip_score = clip_score_fn(torch.from_numpy(images_int).permute(0, 3, 1, 2), prompts).detach()
return round(float(clip_score), 4)

sd_clip_score = calculate_clip_score(images, prompts)
print(f"CLIP score: {sd_clip_score}")
# Ù†ØªÙŠØ¬Ø© CLIP: 35.7038
```

ÙÙŠ Ø§Ù„Ù…Ø«Ø§Ù„ Ø£Ø¹Ù„Ø§Ù‡ØŒ Ù‚Ù…Ù†Ø§ Ø¨ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ÙƒÙ„ Ù…Ø·Ø§Ù„Ø¨Ø©. Ø¥Ø°Ø§ Ù‚Ù…Ù†Ø§ Ø¨ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ù…ØªØ¹Ø¯Ø¯Ø© Ù„ÙƒÙ„ Ù…Ø·Ø§Ù„Ø¨Ø©ØŒ ÙØ³ÙˆÙ Ù†Ø¶Ø·Ø± Ø¥Ù„Ù‰ Ø£Ø®Ø° Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù„ÙƒÙ„ Ù…Ø·Ø§Ù„Ø¨Ø©.

Ø§Ù„Ø¢Ù†ØŒ Ø¥Ø°Ø§ Ø£Ø±Ø¯Ù†Ø§ Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù‚Ø·ØªÙŠ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…ØªÙˆØ§ÙÙ‚ØªÙŠÙ† Ù…Ø¹ [`StableDiffusionPipeline`]ØŒ ÙÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙ†Ø§ ØªÙ…Ø±ÙŠØ± Ù…ÙˆÙ„Ø¯ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨. Ø£ÙˆÙ„Ø§Ù‹ØŒ Ù†Ù‚ÙˆÙ… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø°Ø±Ø© Ø«Ø§Ø¨ØªØ© Ù…Ø¹ [Ù†Ù‚Ø·Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© Ù…Ø³ØªÙ‚Ø±Ø© Ù„Ù„Ø§Ù†ØªØ´Ø§Ø± v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4):

```python
seed = 0
generator = torch.manual_seed(seed)

images = sd_pipeline(prompts, num_images_per_prompt=1, generator=generator, output_type="np").images
```

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù‚Ø·Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© [v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±:

```python
model_ckpt_1_5 = "runwayml/stable-diffusion-v1-5"
sd_pipeline_1_5 = StableDiffusionPipeline.from_pretrained(model_ckpt_1_5, torch_dtype=weight_dtype).to(device)

images_1_5 = sd_pipeline_1_5(prompts, num_images_per_prompt=1, generator=generator, output_type="np").images
```

ÙˆØ£Ø®ÙŠØ±Ù‹Ø§ØŒ Ù†Ù‚Ø§Ø±Ù† Ù†ØªØ§Ø¦Ø¬ CLIP Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ù…:

```python
sd_clip_score_1_4 = calculate_clip_score(images, prompts)
print(f"Ù†ØªÙŠØ¬Ø© CLIP Ù…Ø¹ v-1-4: {sd_clip_score_1_4}")
# Ù†ØªÙŠØ¬Ø© CLIP Ù…Ø¹ v-1-4: 34.9102

sd_clip_score_1_5 = calculate_clip_score(images_1_5, prompts)
print(f"Ù†ØªÙŠØ¬Ø© CLIP Ù…Ø¹ v-1-5: {sd_clip_score_1_5}")
# Ù†ØªÙŠØ¬Ø© CLIP Ù…Ø¹ v-1-5: 36.2137
```

ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù†Ù‚Ø·Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© [v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) ØªØ¤Ø¯ÙŠ Ø£Ø¯Ø§Ø¡Ù‹ Ø£ÙØ¶Ù„ Ù…Ù† Ø³Ø§Ø¨Ù‚ØªÙ‡Ø§. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ù„Ø§Ø­Ø¸ Ø£Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø§Ù„ØªÙŠ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§Ù‡Ø§ Ù„Ø­Ø³Ø§Ø¨ Ù†ØªØ§Ø¦Ø¬ CLIP Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ù‹Ø§. Ù…Ù† Ø£Ø¬Ù„ ØªÙ‚ÙŠÙŠÙ… Ø£ÙƒØ«Ø± Ø¹Ù…Ù„ÙŠØ©ØŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø§Ù„Ø±Ù‚Ù… Ø£Ø¹Ù„Ù‰ Ø¨ÙƒØ«ÙŠØ±ØŒ ÙˆÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø©.

<Tip warning={true}>
Ø¨Ø­ÙƒÙ… Ø§Ù„Ø¨Ù†Ø§Ø¡ØŒ Ù‡Ù†Ø§Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„Ù‚ÙŠÙˆØ¯ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªÙŠØ¬Ø©. ÙƒØ§Ù†Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„ÙŠÙ‡Ø§ Ù…Ù† Ø§Ù„ÙˆÙŠØ¨ ÙˆØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡Ø§ Ù…Ù† Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª `alt` ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ù…Ø§Ø«Ù„Ø© Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª.
Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ù…Ù…Ø«Ù„Ø© Ø¨Ø§Ù„Ø¶Ø±ÙˆØ±Ø© Ù„Ù…Ø§ Ù‚Ø¯ ÙŠØ³ØªØ®Ø¯Ù…Ù‡ Ø§Ù„Ø¥Ù†Ø³Ø§Ù† Ù„ÙˆØµÙ ØµÙˆØ±Ø©. ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠØŒ ÙƒØ§Ù† Ø¹Ù„ÙŠÙ†Ø§ "Ù‡Ù†Ø¯Ø³Ø©" Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù‡Ù†Ø§.
</Tip>
### ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø¶Ø¨Ø· Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ±Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù…ÙˆØ¬Ù‡ Ù†ØµÙŠ. Ø¯Ø¹Ù†Ø§ Ù†Ø£Ø®Ø° [`StableDiffusionInstructPix2PixPipeline`] ÙƒÙ…Ø«Ø§Ù„. ÙÙ‡Ùˆ ÙŠØ£Ø®Ø° ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªØ¹Ø¯ÙŠÙ„ ÙƒØ¥Ø¯Ø®Ø§Ù„ Ù…ÙˆØ¬Ù‡ ÙˆØµÙˆØ±Ø© Ø¥Ø¯Ø®Ø§Ù„ Ù„ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§.

Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø°Ù„Ùƒ:

![ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-instruction.png)

ØªØªÙ…Ø«Ù„ Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ø«Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù‚ÙŠØ§Ø³ Ø§ØªØ³Ø§Ù‚ Ø§Ù„ØªØºÙŠÙŠØ± Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±ØªÙŠÙ† (ÙÙŠ Ù…Ø³Ø§Ø­Ø© CLIP) Ù…Ø¹ Ø§Ù„ØªØºÙŠÙŠØ± Ø¨ÙŠÙ† ØªØ¹Ù„ÙŠÙ‚ÙŠ Ø§Ù„ØµÙˆØ±ØªÙŠÙ† (ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ ÙÙŠ "ØªÙƒÙŠÙŠÙ Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ù€ CLIP Ù„Ù…ÙˆÙ„Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±"). ÙŠØ´Ø§Ø± Ø¥Ù„Ù‰ Ø°Ù„Ùƒ Ø¨Ø§Ø³Ù… "**ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ CLIP**".

- ÙŠØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØ±Ø¹ÙŠ 1 Ù…Ø¹ ØµÙˆØ±Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (Ø§Ù„ØµÙˆØ±Ø© 1) Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§.
- ÙŠØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØ±Ø¹ÙŠ 2 Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© (Ø§Ù„ØµÙˆØ±Ø© 2). ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¹ÙƒØ³ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„.

ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ©:

![Ø§ØªØ³Ø§Ù‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-consistency.png)

Ù„Ù‚Ø¯ Ø£Ø¹Ø¯Ø¯Ù†Ø§ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØµØºØ±Ø© Ù„ØªÙ†ÙÙŠØ° Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³. Ø¯Ø¹Ù†Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

```python
from datasets import load_dataset

dataset = load_dataset("sayakpaul/instructpix2pix-demo", split="train")
dataset.features
```

```bash
{'input': Value(dtype='string', id=None),
'edit': Value(dtype='string', id=None),
'output': Value(dtype='string', id=None),
'image': Image(decode=True, id=None)}
```

Ù‡Ù†Ø§ Ù„Ø¯ÙŠÙ†Ø§:

- `input` Ù‡Ùˆ Ø¹Ù†ÙˆØ§Ù† ÙØ±Ø¹ÙŠ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù€ `image`.
- ÙŠØ´ÙŠØ± `edit` Ø¥Ù„Ù‰ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„.
- ÙŠØ´ÙŠØ± `output` Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØ±Ø¹ÙŠ Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø°ÙŠ ÙŠØ¹ÙƒØ³ ØªØ¹Ù„ÙŠÙ…Ø§Øª `edit`.

Ø¯Ø¹Ù†Ø§ Ù†Ù„Ù‚ÙŠ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø©.

```python
idx = 0
print(f"Original caption: {dataset[idx]['input']}")
print(f"Edit instruction: {dataset[idx]['edit']}")
print(f"Modified caption: {dataset[idx]['output']}")
```

```bash
Original caption: 2. FAROE ISLANDS: An archipelago of 18 mountainous isles in the North Atlantic Ocean between Norway and Iceland, the Faroe Islands has 'everything you could hope for', according to Big 7 Travel. It boasts 'crystal clear waterfalls, rocky cliffs that seem to jut out of nowhere and velvety green hills'
Edit instruction: make the isles all white marble
Modified caption: 2. WHITE MARBLE ISLANDS: An archipelago of 18 mountainous white marble isles in the North Atlantic Ocean between Norway and Iceland, the White Marble Islands has 'everything you could hope for', according to Big 7 Travel. It boasts 'crystal clear waterfalls, rocky cliffs that seem to jut out of nowhere and velvety green hills'
```

ÙˆÙ‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„ØµÙˆØ±Ø©:

```python
dataset[idx]["image"]
```

![Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-dataset.png)

Ø³Ù†Ù‚ÙˆÙ… Ø£ÙˆÙ„Ø§Ù‹ Ø¨ØªØ¹Ø¯ÙŠÙ„ ØµÙˆØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù†Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠ.

Ø¯Ø¹Ù†Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ [`StableDiffusionInstructPix2PixPipeline`]:

```python
from diffusers import StableDiffusionInstructPix2PixPipeline

instruct_pix2pix_pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(
"timbrooks/instruct-pix2pix", torch_dtype=torch.float16
).to(device)
```

Ø§Ù„Ø¢Ù†ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª:

```python
import numpy as np


def edit_image(input_image, instruction):
    image = instruct_pix2pix_pipeline(
    instruction,
    image=input_image,
    output_type="np",
    generator=generator,
    ).images[0]
    return image

input_images = []
original_captions = []
modified_captions = []
edited_images = []

for idx in range(len(dataset)):
    input_image = dataset[idx]["image"]
    edit_instruction = dataset[idx]["edit"]
    edited_image = edit_image(input_image, edit_instruction)

    input_images.append(np.array(input_image))
    original_captions.append(dataset[idx]["input"])
    modified_captions.append(dataset[idx]["output"])
    edited_images.append(edited_image)
```

Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠØŒ Ù†Ù‚ÙˆÙ… Ø£ÙˆÙ„Ø§Ù‹ Ø¨ØªØ­Ù…ÙŠÙ„ Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ù„Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ CLIP:

```python
from transformers import (
CLIPTokenizer,
CLIPTextModelWithProjection,
CLIPVisionModelWithProjection,
CLIPImageProcessor,
)

clip_id = "openai/clip-vit-large-patch14"
tokenizer = CLIPTokenizer.from_pretrained(clip_id)
text_encoder = CLIPTextModelWithProjection.from_pretrained(clip_id).to(device)
image_processor = CLIPImageProcessor.from_pretrained(clip_id)
image_encoder = CLIPVisionModelWithProjection.from_pretrained(clip_id).to(device)
```

Ù„Ø§Ø­Ø¸ Ø£Ù†Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ CLIP Ù…Ø¹ÙŠÙ†Ø©ØŒ Ø£ÙŠ `openai/clip-vit-large-patch14`. ÙˆÙŠØ±Ø¬Ø¹ Ø°Ù„Ùƒ Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ù„Ù€ Stable Diffusion ØªÙ… Ø¥Ø¬Ø±Ø§Ø¤Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ù† CLIP. Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ [Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚](https://huggingface.co/docs/transformers/model_doc/clip).

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ `nn.Module` Ù…Ù† PyTorch Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠ:

```python
import torch.nn as nn
import torch.nn.functional as F


class DirectionalSimilarity(nn.Module):
    def __init__(self, tokenizer, text_encoder, image_processor, image_encoder):
        super().__init__()
        self.tokenizer = tokenizer
        self.text_encoder = text_encoder
        self.image_processor = image_processor
        self.image_encoder = image_encoder

    def preprocess_image(self, image):
        image = self.image_processor(image, return_tensors="pt")["pixel_values"]
        return {"pixel_values": image.to(device)}

    def tokenize_text(self, text):
        inputs = self.tokenizer(
        text,
        max_length=self.tokenizer.model_max_length,
        padding="max_length",
        truncation=True,
        return_tensors="pt",
        )
        return {"input_ids": inputs.input_ids.to(device)}

    def encode_image(self, image):
        preprocessed_image = self.preprocess_image(image)
        image_features = self.image_encoder(**preprocessed_image).image_embeds
        image_features = image_features / image_features.norm(dim=1, keepdim=True)
        return image_features

    def encode_text(self, text):
        tokenized_text = self.tokenize_text(text)
        text_features = self.text_encoder(**tokenized_text).text_embeds
        text_features = text_features / text_features.norm(dim=1, keepdim=True)
        return text_features

    def compute_directional_similarity(self, img_feat_one, img_feat_two, text_feat_one, text_feat_two):
        sim_direction = F.cosine_similarity(img_feat_two - img_feat_one, text_feat_two - text_feat_one)
        return sim_direction

    def forward(self, image_one, image_two, caption_one, caption_two):
        img_feat_one = self.encode_image(image_one)
        img_feat_two = self.encode_image(image_two)
        text_feat_one = self.encode_text(caption_one)
        text_feat_two = self.encode_text(caption_two)
        directional_similarity = self.compute_directional_similarity(
        img_feat_one, img_feat_two, text_feat_one, text_feat_two
        )
        return directional_similarity
```

Ø¯Ø¹Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… `DirectionalSimilarity` Ø§Ù„Ø¢Ù†.

```python
dir_similarity = DirectionalSimilarity(tokenizer, text_encoder, image_processor, image_encoder)
scores = []

for i in range(len(input_images)):
    original_image = input_images[i]
    original_caption = original_captions[i]
    edited_image = edited_images[i]
    modified_caption = modified_captions[i]

    similarity_score = dir_similarity(original_image, edited_image, original_caption, modified_caption)
    scores.append(float(similarity_score.detach().cpu()))

print(f"CLIP directional similarity: {np.mean(scores)}")
# ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ CLIP: 0.0797976553440094
```

Ù…Ø«Ù„ Ø¯Ø±Ø¬Ø© CLIPØŒ ÙƒÙ„Ù…Ø§ ÙƒØ§Ù†Øª Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠ CLIP Ø£Ø¹Ù„Ù‰ØŒ ÙƒØ§Ù† Ø°Ù„Ùƒ Ø£ÙØ¶Ù„.

ØªØ¬Ø¯Ø± Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø£Ù† `StableDiffusionInstructPix2PixPipeline` ØªØ¹Ø±Ø¶ Ø­Ø¬ØªÙŠÙ†ØŒ ÙˆÙ‡Ù…Ø§ `image_guidance_scale` Ùˆ`guidance_scale`ØŒ ÙˆØ§Ù„Ù„ØªØ§Ù† ØªØªÙŠØ­Ø§Ù† Ù„Ùƒ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©. Ù†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© Ù‡Ø§ØªÙŠÙ† Ø§Ù„Ø­Ø¬ØªÙŠÙ† ÙˆØ±Ø¤ÙŠØ© ØªØ£Ø«ÙŠØ±Ù‡Ù…Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠ.

ÙŠÙ…ÙƒÙ†Ù†Ø§ ØªÙˆØ³ÙŠØ¹ ÙÙƒØ±Ø© Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ Ù„Ù‚ÙŠØ§Ø³ Ù…Ø¯Ù‰ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©. Ù„Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¨Ø¨Ø³Ø§Ø·Ø© Ø¥Ø¬Ø±Ø§Ø¡ `F.cosine_similarity (img_feat_twoØŒ img_feat_one)`. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§ØªØŒ Ù…Ø§ Ø²Ù„Ù†Ø§ Ù†Ø±ÙŠØ¯ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„ØµÙˆØ± Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ØŒ Ø£ÙŠ Ø¯Ø±Ø¬Ø© ØªØ´Ø§Ø¨Ù‡ Ø¹Ø§Ù„ÙŠØ©.

ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ù…Ø§Ø«Ù„Ø© Ù…Ø«Ù„ [`StableDiffusionPix2PixZeroPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/pix2pix_zero#diffusers.StableDiffusionPix2PixZeroPipeline).

<Tip>
ÙŠØ¹ØªÙ…Ø¯ ÙƒÙ„ Ù…Ù† Ø¯Ø±Ø¬Ø© CLIP ÙˆØ§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠ CLIP Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ CLIPØŒ Ù…Ù…Ø§ Ù‚Ø¯ ÙŠØ¬Ø¹Ù„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ù…ØªØ­ÙŠØ²Ø©.
</Tip>

***ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† ØªÙ…Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø«Ù„ ISØŒ FID (Ø§Ù„ØªÙŠ ØªÙ…Øª Ù…Ù†Ø§Ù‚Ø´ØªÙ‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§)ØŒ Ø£Ùˆ KID Ø£Ù…Ø±Ù‹Ø§ ØµØ¹Ø¨Ù‹Ø§*** Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚ÙŠØ¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù‚Ø¯ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±Ø© Ù„Ù„ØµÙˆØ± ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© (Ù…Ø«Ù„ [Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª LAION-5B](https://laion.ai/blog/laion-5b/)). ÙˆÙŠØ±Ø¬Ø¹ Ø°Ù„Ùƒ Ø¥Ù„Ù‰ Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø´Ø¨ÙƒØ© InceptionNet (Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ImageNet-1k) Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ ØªØ¯Ø§Ø®Ù„ Ù…Ø­Ø¯ÙˆØ¯ Ø¨ÙŠÙ† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ù„Ù€ Stable Diffusion ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ù„Ù€ InceptionNetØŒ Ù„Ø°Ù„Ùƒ ÙØ¥Ù†Ù‡Ø§ Ù„ÙŠØ³Øª Ù…Ø±Ø´Ø­Ù‹Ø§ Ø¬ÙŠØ¯Ù‹Ø§ Ù‡Ù†Ø§ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª.

***ÙŠØ³Ø§Ø¹Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø§Ù„ÙØµÙ„. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ [DiT](https://huggingface.co/docs/diffusers/main/en/api/pipelines/dit). ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø´Ø±Ø· Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø´Ø±ÙˆØ·Ù‹Ø§ Ø¨ÙØµÙˆÙ„ ImageNet-1k.***
### Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø§Ù„ÙØ¦Ø©

Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ø§ ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø§Ù„ÙØ¦Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ³ÙˆÙ…Ø© Ø¨Ø§Ù„ÙØ¦Ø§Øª Ù…Ø«Ù„ [ImageNet-1k](https://huggingface.co/datasets/imagenet-1k). ØªØ´Ù…Ù„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„ØªÙ‚ÙŠÙŠÙ… Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø³Ø§ÙØ© ÙØ±Ø´ÙŠÙ‡ Ø§Ù†Ø³ÙŠØ§Ø¨ Ø§Ù„ÙØ±Ù‚ (FID)ØŒ ÙˆÙ…Ø³Ø§ÙØ© Ø§Ù†Ø³ÙŠØ§Ø¨ Ø§Ù„Ù†ÙˆØ§Ø© (KID)ØŒ ÙˆØ¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³ÙŠØ§Ø¨ (IS). ÙˆÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©ØŒ Ù†Ø±ÙƒØ² Ø¹Ù„Ù‰ FID ([Heusel et al.](https://arxiv.org/abs/1706.08500)). ÙˆØ³Ù†ÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø­Ø³Ø§Ø¨Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DiTPipeline`](https://huggingface.co/docs/diffusers/api/pipelines/dit)ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… [Ù†Ù…ÙˆØ°Ø¬ DiT](https://arxiv.orgMultiplier-free Transformer for Image Generation) ØªØ­Øª Ø§Ù„ØºØ·Ø§Ø¡.

ØªÙ‡Ø¯Ù FID Ø¥Ù„Ù‰ Ù‚ÙŠØ§Ø³ Ù…Ø¯Ù‰ ØªØ´Ø§Ø¨Ù‡ Ù…Ø¬Ù…ÙˆØ¹ØªÙŠÙ† Ù…Ù† Ø§Ù„ØµÙˆØ±. ÙˆÙÙ‚Ù‹Ø§ [Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ±Ø¯](https://mmgeneration.readthedocs.io/en/latest/quick_run.html#fid):

> ØªØ¹Ø¯ Ù…Ø³Ø§ÙØ© ÙØ±Ø´ÙŠÙ‡ Ø§Ù†Ø³ÙŠØ§Ø¨ Ø§Ù„ÙØ±Ù‚ Ù…Ù‚ÙŠØ§Ø³Ù‹Ø§ Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¬Ù…ÙˆØ¹ØªÙŠÙ† Ù…Ù† Ø§Ù„ØµÙˆØ±. ÙˆÙ‚Ø¯ Ø«Ø¨Øª Ø£Ù†Ù‡Ø§ ØªØªÙˆØ§ÙÙ‚ Ø¬ÙŠØ¯Ù‹Ø§ Ù…Ø¹ Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø±Ø¦ÙŠØ©ØŒ ÙˆÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø£ØºÙ„Ø¨ Ø§Ù„Ø£Ø­ÙŠØ§Ù† Ù„ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØªÙŠ ØªÙ†ØªØ¬Ù‡Ø§ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø®ØµÙ…ÙŠØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ©. ÙŠØªÙ… Ø­Ø³Ø§Ø¨ FID Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø­Ø³Ø§Ø¨ Ù…Ø³Ø§ÙØ© ÙØ±Ø´ÙŠÙ‡ Ø¨ÙŠÙ† Ø§Ø«Ù†ÙŠÙ† Ù…Ù† Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„ØºØ§ÙˆØ³ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªÙŠ ÙŠÙ†ØªØ¬Ù‡Ø§ Ù†Ù…ÙˆØ°Ø¬ Inception.

ØªØªÙ…Ø«Ù„ Ù‡Ø§ØªØ§Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ØªØ§Ù† Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø²ÙŠÙØ© (Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© ÙÙŠ Ø­Ø§Ù„ØªÙ†Ø§). ÙˆØ¹Ø§Ø¯Ø© Ù…Ø§ ÙŠØªÙ… Ø­Ø³Ø§Ø¨ FID Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹ØªÙŠÙ† ÙƒØ¨ÙŠØ±ØªÙŠÙ† Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ø³Ù†Ø¹Ù…Ù„ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹ØªÙŠÙ† ØµØºÙŠØ±ØªÙŠÙ† Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ù‚ÙˆÙ… Ø£ÙˆÙ„Ø§Ù‹ Ø¨ØªÙ†Ø²ÙŠÙ„ Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ImageNet-1k:

```python
from zipfile import ZipFile
import requests


def download(url, local_filepath):
    r = requests.get(url)
    with open(local_filepath, "wb") as f:
        f.write(r.content)
    return local_filepath

dummy_dataset_url = "https://hf.co/datasets/sayakpaul/sample-datasets/resolve/main/sample-imagenet-images.zip"
local_filepath = download(dummy_dataset_url, dummy_dataset_url.split("/")[-1])

with ZipFile(local_filepath, "r") as zipper:
    zipper.extractall(".")
```

```python
from PIL import Image
import os

dataset_path = "sample-imagenet-images"
image_paths = sorted([os.path.join(dataset_path, x) for x in os.listdir(dataset_path)])

real_images = [np.array(Image.open(path).convert("RGB")) for path in image_paths]
```

Ù‡Ø°Ù‡ 10 ØµÙˆØ± Ù…Ù† ÙØ¦Ø§Øª ImageNet-1k Ø§Ù„ØªØ§Ù„ÙŠØ©: "cassette_player"ØŒ "chain_saw" (x2)ØŒ "church"ØŒ "gas_pump" (x3)ØŒ "parachute" (x2)ØŒ Ùˆ "tench".

<p align="center">
<img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/real-images.png" alt="real-images"><br>
<em>Real images.</em>
</p>

Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø·Ø¨Ù‚ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ø¹Ù„ÙŠÙ‡Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø­Ø³Ø§Ø¨ FID.

```python
from torchvision.transforms import functional as F


def preprocess_image(image):
    image = torch.tensor(image).unsqueeze(0)
    image = image.permute(0, 3, 1, 2) / 255.0
    return F.center_crop(image, (256, 256))

real_images = torch.cat([preprocess_image(image) for image in real_images])
print(real_images.shape)
# torch.Size([10, 3, 256, 256])
```

Ø³Ù†Ù‚ÙˆÙ… Ø§Ù„Ø¢Ù† Ø¨ØªØ­Ù…ÙŠÙ„ [`DiTPipeline`](https://huggingface.co/docs/diffusers/api/pipelines/dit) Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ø¨Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡.

```python
from diffusers import DiTPipeline, DPMSolverMultistepScheduler

dit_pipeline = DiTPipeline.from_pretrained("facebook/DiT-XL-2-256", torch_dtype=torch.float16)
dit_pipeline.scheduler = DPMSolverMultistepScheduler.from_config(dit_pipeline.scheduler.config)
dit_pipeline = dit_pipeline.to("cuda")

words = [
    "cassette player",
    "chainsaw",
    "chainsaw",
    "church",
    "gas pump",
    "gas pump",
    "gas pump",
    "parachute",
    "parachute",
    "tench",
]

class_ids = dit_pipeline.get_label_ids(words)
output = dit_pipeline(class_labels=class_ids, generator=generator, output_type="np")

fake_images = output.images
fake_images = torch.tensor(fake_images)
fake_images = fake_images.permute(0, 3, 1, 2)
print(fake_images.shape)
# torch.Size([10, 3, 256, 256])
```

Ø§Ù„Ø¢Ù†ØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø­Ø³Ø§Ø¨ FID Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`torchmetrics`](https://torchmetrics.readthedocs.io/).

```python
from torchmetrics.image.fid import FrechetInceptionDistance

fid = FrechetInceptionDistance(normalize=True)
fid.update(real_images, real=True)
fid.update(fake_images, real=False)

print(f"FID: {float(fid.compute())}")
# FID: 177.7147216796875
```

ÙƒÙ„Ù…Ø§ Ø§Ù†Ø®ÙØ¶Øª Ù‚ÙŠÙ…Ø© FIDØŒ ÙƒØ§Ù† Ø°Ù„Ùƒ Ø£ÙØ¶Ù„. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¤Ø«Ø± Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø¹Ù„Ù‰ FID Ù‡Ù†Ø§:

- Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± (Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆØ§Ù„Ù…Ø²ÙŠÙØ©)
- Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±
- Ø¹Ø¯Ø¯ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±
- Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±

Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù†Ù‚Ø·ØªÙŠÙ† Ø§Ù„Ø£Ø®ÙŠØ±ØªÙŠÙ†ØŒ Ù…Ù† Ø§Ù„Ø¬ÙŠØ¯ Ø¥Ø°Ù† Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ø¨Ø± Ø¨Ø°ÙˆØ± ÙˆØ®Ø·ÙˆØ§Øª Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ø®ØªÙ„ÙØ©ØŒ Ø«Ù… Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Ù†ØªÙŠØ¬Ø© Ù…ØªÙˆØ³Ø·Ø©.

<Tip warning={true}>

ØªÙ…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ FID Ø¥Ù„Ù‰ Ø£Ù† ØªÙƒÙˆÙ† Ù‡Ø´Ø© Ù„Ø£Ù†Ù‡Ø§ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¹ÙˆØ§Ù…Ù„:

* Ù†Ù…ÙˆØ°Ø¬ Inception Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­Ø³Ø§Ø¨.
* Ø¯Ù‚Ø© ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø³Ø§Ø¨.
* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙˆØ±Ø© (Ù„ÙŠØ³ Ù†ÙØ³Ù‡ Ø¥Ø°Ø§ Ø¨Ø¯Ø£Ù†Ø§ Ù…Ù† PNGs Ù…Ù‚Ø§Ø¨Ù„ JPGs).

Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø°Ù„ÙƒØŒ ØªÙƒÙˆÙ† FID Ù…ÙÙŠØ¯Ø© ÙÙŠ ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø­ÙŠØ§Ù† Ø¹Ù†Ø¯ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ù…Ø§Ø«Ù„Ø©ØŒ ÙˆÙ„ÙƒÙ† Ù…Ù† Ø§Ù„ØµØ¹Ø¨ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙˆØ±Ù‚Ø© Ù…Ø§ Ù„Ù… ÙŠÙƒØ´Ù Ø§Ù„Ù…Ø¤Ù„ÙÙˆÙ† Ø¨Ø¹Ù†Ø§ÙŠØ© Ø¹Ù† Ø±Ù…Ø² Ù‚ÙŠØ§Ø³ FID.

ØªÙ†Ø·Ø¨Ù‚ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø§Ø· Ø£ÙŠØ¶Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø®Ø±Ù‰ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©ØŒ Ù…Ø«Ù„ KID Ùˆ IS.

</Tip>

ÙƒØ®Ø·ÙˆØ© Ø£Ø®ÙŠØ±Ø©ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ù‚ÙˆÙ… Ø¨Ø§Ù„ØªÙØªÙŠØ´ Ø§Ù„Ø¨ØµØ±ÙŠ Ø¹Ù„Ù‰ `fake_images`.

<p align="center">
<img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/fake-images.png" alt="fake-images"><br>
<em>Fake images.</em>
</p>