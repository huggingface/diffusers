<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# InstructPix2Pix

[InstructPix2Pix](https://arxiv.org/abs/2211.09800)ëŠ” text-conditioned diffusion ëª¨ë¸ì´ í•œ ì´ë¯¸ì§€ì— í¸ì§‘ì„ ë”°ë¥¼ ìˆ˜ ìˆë„ë¡ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì€ ë‹¤ìŒì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤:

<p align="center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-instruction.png" alt="instructpix2pix-inputs" width=600/>
</p>

ì¶œë ¥ì€ ì…ë ¥ ì´ë¯¸ì§€ì— í¸ì§‘ ì§€ì‹œê°€ ë°˜ì˜ëœ "ìˆ˜ì •ëœ" ì´ë¯¸ì§€ì…ë‹ˆë‹¤:

<p align="center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/output-gs%407-igs%401-steps%4050.png" alt="instructpix2pix-output" width=600/>
</p>

`train_instruct_pix2pix.py` ìŠ¤í¬ë¦½íŠ¸([ì—¬ê¸°](https://github.com/huggingface/diffusers/blob/main/examples/instruct_pix2pix/train_instruct_pix2pix.py)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)ëŠ” í•™ìŠµ ì ˆì°¨ë¥¼ ì„¤ëª…í•˜ê³  Stable Diffusionì— ì ìš©í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


*** `train_instruct_pix2pix.py`ëŠ” [ì›ë˜ êµ¬í˜„](https://github.com/timothybrooks/instruct-pix2pix)ì— ì¶©ì‹¤í•˜ë©´ì„œ InstructPix2Pix í•™ìŠµ ì ˆì°¨ë¥¼ êµ¬í˜„í•˜ê³  ìˆì§€ë§Œ, [ì†Œê·œëª¨ ë°ì´í„°ì…‹](https://huggingface.co/datasets/fusing/instructpix2pix-1000-samples)ì—ì„œë§Œ í…ŒìŠ¤íŠ¸ë¥¼ í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìµœì¢… ê²°ê³¼ì— ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ìœ„í•´, ë” í° ë°ì´í„°ì…‹ì—ì„œ ë” ê¸¸ê²Œ í•™ìŠµí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. [ì—¬ê¸°](https://huggingface.co/datasets/timbrooks/instructpix2pix-clip-filtered)ì—ì„œ InstructPix2Pix í•™ìŠµì„ ìœ„í•´ í° ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
***

## PyTorchë¡œ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê¸°

### ì¢…ì†ì„±(dependencies) ì„¤ì¹˜í•˜ê¸°

ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì—, ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•™ìŠµ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:

**ì¤‘ìš”**

ìµœì‹  ë²„ì „ì˜ ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•´, **ì›ë³¸ìœ¼ë¡œë¶€í„° ì„¤ì¹˜**í•˜ëŠ” ê²ƒê³¼ ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìì£¼ ì—…ë°ì´íŠ¸í•˜ê³  ì˜ˆì œë³„ ìš”êµ¬ì‚¬í•­ì„ ì„¤ì¹˜í•˜ê¸° ë•Œë¬¸ì— ìµœì‹  ìƒíƒœë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´, ìƒˆë¡œìš´ ê°€ìƒ í™˜ê²½ì—ì„œ ë‹¤ìŒ ìŠ¤í…ì„ ì‹¤í–‰í•˜ì„¸ìš”:

```bash
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
```

cd ëª…ë ¹ì–´ë¡œ ì˜ˆì œ í´ë”ë¡œ ì´ë™í•˜ì„¸ìš”.
```bash
cd examples/instruct_pix2pix
```

ì´ì œ ì‹¤í–‰í•˜ì„¸ìš”.
```bash
pip install -r requirements.txt
```

ê·¸ë¦¬ê³  [ğŸ¤—Accelerate](https://github.com/huggingface/accelerate/) í™˜ê²½ì—ì„œ ì´ˆê¸°í™”í•˜ì„¸ìš”:

```bash
accelerate config
```

í˜¹ì€ í™˜ê²½ì— ëŒ€í•œ ì§ˆë¬¸ ì—†ì´ ê¸°ë³¸ì ì¸ accelerate êµ¬ì„±ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì„¸ìš”.

```bash
accelerate config default
```

í˜¹ì€ ì‚¬ìš© ì¤‘ì¸ í™˜ê²½ì´ notebookê³¼ ê°™ì€ ëŒ€í™”í˜• ì‰˜ì€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ë‹¤ìŒ ì ˆì°¨ë¥¼ ë”°ë¼ì£¼ì„¸ìš”.

```python
from accelerate.utils import write_basic_config

write_basic_config()
```

### ì˜ˆì‹œ

ì´ì „ì— ì–¸ê¸‰í–ˆë“¯ì´, í•™ìŠµì„ ìœ„í•´ [ì‘ì€ ë°ì´í„°ì…‹](https://huggingface.co/datasets/fusing/instructpix2pix-1000-samples)ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ ë°ì´í„°ì…‹ì€ InstructPix2Pix ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ [ì›ë˜ì˜ ë°ì´í„°ì…‹](https://huggingface.co/datasets/timbrooks/instructpix2pix-clip-filtered)ë³´ë‹¤ ì‘ì€ ë²„ì „ì…ë‹ˆë‹¤. ìì‹ ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´, [í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°](create_dataset) ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

`MODEL_NAME` í™˜ê²½ ë³€ìˆ˜(í—ˆë¸Œ ëª¨ë¸ ë ˆí¬ì§€í† ë¦¬ ë˜ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ í¬í•¨ëœ í´ë” ê²½ë¡œ)ë¥¼ ì§€ì •í•˜ê³  [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path) ì¸ìˆ˜ì— ì „ë‹¬í•©ë‹ˆë‹¤. `DATASET_ID`ì— ë°ì´í„°ì…‹ ì´ë¦„ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤:


```bash
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export DATASET_ID="fusing/instructpix2pix-1000-samples"
```

ì§€ê¸ˆ, í•™ìŠµì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” ë ˆí¬ì§€í† ë¦¬ì˜ í•˜ìœ„ í´ë”ì˜ ëª¨ë“  êµ¬ì„±ìš”ì†Œ(`feature_extractor`, `scheduler`, `text_encoder`, `unet` ë“±)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

```bash
accelerate launch --mixed_precision="fp16" train_instruct_pix2pix.py \
    --pretrained_model_name_or_path=$MODEL_NAME \
    --dataset_name=$DATASET_ID \
    --enable_xformers_memory_efficient_attention \
    --resolution=256 --random_flip \
    --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing \
    --max_train_steps=15000 \
    --checkpointing_steps=5000 --checkpoints_total_limit=1 \
    --learning_rate=5e-05 --max_grad_norm=1 --lr_warmup_steps=0 \
    --conditioning_dropout_prob=0.05 \
    --mixed_precision=fp16 \
    --seed=42 \
    --push_to_hub
```


ì¶”ê°€ì ìœ¼ë¡œ, ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤ë¥¼ í•™ìŠµ ê³¼ì •ì— ëª¨ë‹ˆí„°ë§í•˜ì—¬ ê²€ì¦ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ ì§€ì›í•©ë‹ˆë‹¤. `report_to="wandb"`ì™€ ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
accelerate launch --mixed_precision="fp16" train_instruct_pix2pix.py \
    --pretrained_model_name_or_path=$MODEL_NAME \
    --dataset_name=$DATASET_ID \
    --enable_xformers_memory_efficient_attention \
    --resolution=256 --random_flip \
    --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing \
    --max_train_steps=15000 \
    --checkpointing_steps=5000 --checkpoints_total_limit=1 \
    --learning_rate=5e-05 --max_grad_norm=1 --lr_warmup_steps=0 \
    --conditioning_dropout_prob=0.05 \
    --mixed_precision=fp16 \
    --val_image_url="https://hf.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png" \
    --validation_prompt="make the mountains snowy" \
    --seed=42 \
    --report_to=wandb \
    --push_to_hub
 ```

ëª¨ë¸ ë””ë²„ê¹…ì— ìœ ìš©í•œ ì´ í‰ê°€ ë°©ë²• ê¶Œì¥í•©ë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `wandb`ë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒì„ ì£¼ëª©í•´ì£¼ì„¸ìš”. `pip install wandb`ë¡œ ì‹¤í–‰í•´ `wandb`ë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[ì—¬ê¸°](https://wandb.ai/sayakpaul/instruct-pix2pix/runs/ctr3kovq), ëª‡ ê°€ì§€ í‰ê°€ ë°©ë²•ê³¼ í•™ìŠµ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ëŠ” ì˜ˆì‹œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

 ***ì°¸ê³ : ì›ë³¸ ë…¼ë¬¸ì—ì„œ, ì €ìë“¤ì€ 256x256 ì´ë¯¸ì§€ í•´ìƒë„ë¡œ í•™ìŠµí•œ ëª¨ë¸ë¡œ 512x512ì™€ ê°™ì€ ë” í° í•´ìƒë„ë¡œ ì˜ ì¼ë°˜í™”ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” í•™ìŠµì— ì‚¬ìš©í•œ í° ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.***

 ## ë‹¤ìˆ˜ì˜ GPUë¡œ í•™ìŠµí•˜ê¸°

`accelerate`ëŠ” ì›í™œí•œ ë‹¤ìˆ˜ì˜ GPUë¡œ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. `accelerate`ë¡œ ë¶„ì‚° í•™ìŠµì„ ì‹¤í–‰í•˜ëŠ” [ì—¬ê¸°](https://huggingface.co/docs/accelerate/basic_tutorials/launch) ì„¤ëª…ì„ ë”°ë¼ í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ì˜ˆì‹œì˜ ëª…ë ¹ì–´ ì…ë‹ˆë‹¤:


```bash
accelerate launch --mixed_precision="fp16" --multi_gpu train_instruct_pix2pix.py \
 --pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 \
 --dataset_name=sayakpaul/instructpix2pix-1000-samples \
 --use_ema \
 --enable_xformers_memory_efficient_attention \
 --resolution=512 --random_flip \
 --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing \
 --max_train_steps=15000 \
 --checkpointing_steps=5000 --checkpoints_total_limit=1 \
 --learning_rate=5e-05 --lr_warmup_steps=0 \
 --conditioning_dropout_prob=0.05 \
 --mixed_precision=fp16 \
 --seed=42 \
 --push_to_hub
```

 ## ì¶”ë¡ í•˜ê¸°

ì¼ë‹¨ í•™ìŠµì´ ì™„ë£Œë˜ë©´, ì¶”ë¡  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

 ```python
import PIL
import requests
import torch
from diffusers import StableDiffusionInstructPix2PixPipeline

model_id = "your_model_id"  # <- ì´ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")
generator = torch.Generator("cuda").manual_seed(0)

url = "https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/test_pix2pix_4.png"


def download_image(url):
    image = PIL.Image.open(requests.get(url, stream=True).raw)
    image = PIL.ImageOps.exif_transpose(image)
    image = image.convert("RGB")
    return image


image = download_image(url)
prompt = "wipe out the lake"
num_inference_steps = 20
image_guidance_scale = 1.5
guidance_scale = 10

edited_image = pipe(
    prompt,
    image=image,
    num_inference_steps=num_inference_steps,
    image_guidance_scale=image_guidance_scale,
    guidance_scale=guidance_scale,
    generator=generator,
).images[0]
edited_image.save("edited_image.png")
```

í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•´ ì–»ì€ ì˜ˆì‹œì˜ ëª¨ë¸ ë ˆí¬ì§€í† ë¦¬ëŠ” ì—¬ê¸° [sayakpaul/instruct-pix2pix](https://huggingface.co/sayakpaul/instruct-pix2pix)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì„±ëŠ¥ì„ ìœ„í•œ ì†ë„ì™€ í’ˆì§ˆì„ ì œì–´í•˜ê¸° ìœ„í•´ ì„¸ ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤:

* `num_inference_steps`
* `image_guidance_scale`
* `guidance_scale`

íŠ¹íˆ, `image_guidance_scale`ì™€ `guidance_scale`ëŠ” ìƒì„±ëœ("ìˆ˜ì •ëœ") ì´ë¯¸ì§€ì—ì„œ í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.([ì—¬ê¸°](https://twitter.com/RisingSayak/status/1628392199196151808?s=20)ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.)


ë§Œì•½ InstructPix2Pix í•™ìŠµ ë°©ë²•ì„ ì‚¬ìš©í•´ ëª‡ ê°€ì§€ í¥ë¯¸ë¡œìš´ ë°©ë²•ì„ ì°¾ê³  ìˆë‹¤ë©´, ì´ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼[Instruction-tuning Stable Diffusion with InstructPix2Pix](https://huggingface.co/blog/instruction-tuning-sd)ì„ í™•ì¸í•´ì£¼ì„¸ìš”.