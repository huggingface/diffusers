<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->


# Text-to-image

<Tip warning={true}>

text-to-image íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸ëŠ” experimental ìƒíƒœì…ë‹ˆë‹¤. ê³¼ì í•©í•˜ê¸° ì‰½ê³  ì¹˜ëª…ì ì¸ ë§ê°ê³¼ ê°™ì€ ë¬¸ì œì— ë¶€ë”ªíˆê¸° ì‰½ìŠµë‹ˆë‹¤. ìì²´ ë°ì´í„°ì…‹ì—ì„œ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

</Tip>

Stable Diffusionê³¼ ê°™ì€ text-to-image ëª¨ë¸ì€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” PyTorch ë° Flaxë¥¼ ì‚¬ìš©í•˜ì—¬ ìì²´ ë°ì´í„°ì…‹ì—ì„œ [`CompVis/stable-diffusion-v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4) ëª¨ë¸ë¡œ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê°€ì´ë“œì— ì‚¬ìš©ëœ text-to-image íŒŒì¸íŠœë‹ì„ ìœ„í•œ ëª¨ë“  í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš° ì´ [ë¦¬í¬ì§€í† ë¦¬](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image)ì—ì„œ ìì„¸íˆ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì—, ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•™ìŠµ dependencyë“¤ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
pip install git+https://github.com/huggingface/diffusers.git
pip install -U -r requirements.txt
```

ê·¸ë¦¬ê³  [ğŸ¤—Accelerate](https://github.com/huggingface/accelerate/) í™˜ê²½ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤:

```bash
accelerate config
```

ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì´ë¯¸ ë³µì œí•œ ê²½ìš°, ì´ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹ , ë¡œì»¬ ì²´í¬ì•„ì›ƒ ê²½ë¡œë¥¼ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ëª…ì‹œí•  ìˆ˜ ìˆìœ¼ë©° ê±°ê¸°ì—ì„œ ë¡œë“œë©ë‹ˆë‹¤.

### í•˜ë“œì›¨ì–´ ìš”êµ¬ ì‚¬í•­

`gradient_checkpointing` ë° `mixed_precision`ì„ ì‚¬ìš©í•˜ë©´ ë‹¨ì¼ 24GB GPUì—ì„œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë†’ì€ `batch_size`ì™€ ë” ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ì„œëŠ” GPU ë©”ëª¨ë¦¬ê°€ 30GB ì´ìƒì¸ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. TPU ë˜ëŠ” GPUì—ì„œ íŒŒì¸íŠœë‹ì„ ìœ„í•´ JAXë‚˜ Flaxë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì•„ë˜](#flax-jax-finetuning)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

xFormersë¡œ memory efficient attentionì„ í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í›¨ì”¬ ë” ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [xFormersê°€ ì„¤ì¹˜](./optimization/xformers)ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  `--enable_xformers_memory_efficient_attention`ë¥¼ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ëª…ì‹œí•©ë‹ˆë‹¤.

xFormersëŠ” Flaxì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

## Hubì— ëª¨ë¸ ì—…ë¡œë“œí•˜ê¸°

í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì„ í—ˆë¸Œì— ì €ì¥í•©ë‹ˆë‹¤:

```bash
  --push_to_hub
```


## ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°

í•™ìŠµ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¼ì— ëŒ€ë¹„í•˜ì—¬ ì •ê¸°ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•´ ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•˜ë ¤ë©´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤.

```bash
  --checkpointing_steps=500
```

500ìŠ¤í…ë§ˆë‹¤ ì „ì²´ í•™ìŠµ stateê°€ 'output_dir'ì˜ í•˜ìœ„ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. ì²´í¬í¬ì¸íŠ¸ëŠ” 'checkpoint-'ì— ì§€ê¸ˆê¹Œì§€ í•™ìŠµëœ step ìˆ˜ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'checkpoint-1500'ì€ 1500 í•™ìŠµ step í›„ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì…ë‹ˆë‹¤.

í•™ìŠµì„ ì¬ê°œí•˜ê¸° ìœ„í•´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ë ¤ë©´ '--resume_from_checkpoint' ì¸ìˆ˜ë¥¼ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ëª…ì‹œí•˜ê³  ì¬ê°œí•  ì²´í¬í¬ì¸íŠ¸ë¥¼ ì§€ì •í•˜ì‹­ì‹œì˜¤. ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒ ì¸ìˆ˜ëŠ” 1500ê°œì˜ í•™ìŠµ step í›„ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œë¶€í„° í›ˆë ¨ì„ ì¬ê°œí•©ë‹ˆë‹¤.

```bash
  --resume_from_checkpoint="checkpoint-1500"
```

## íŒŒì¸íŠœë‹

<frameworkcontent>
<pt>
ë‹¤ìŒê³¼ ê°™ì´ [Naruto BLIP ìº¡ì…˜](https://huggingface.co/datasets/lambdalabs/naruto-blip-captions) ë°ì´í„°ì…‹ì—ì„œ íŒŒì¸íŠœë‹ ì‹¤í–‰ì„ ìœ„í•´ [PyTorch í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:


```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export dataset_name="lambdalabs/naruto-blip-captions"

accelerate launch train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name \
  --use_ema \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --mixed_precision="fp16" \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir="sd-naruto-model"
```

ìì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ë ¤ë©´ ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/index)ì—ì„œ ìš”êµ¬í•˜ëŠ” í˜•ì‹ì— ë”°ë¼ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ì„¸ìš”. [ë°ì´í„°ì…‹ì„ í—ˆë¸Œì— ì—…ë¡œë“œ](https://huggingface.co/docs/datasets/image_dataset#upload-dataset-to-the-hub)í•˜ê±°ë‚˜ [íŒŒì¼ë“¤ì´ ìˆëŠ” ë¡œì»¬ í´ë”ë¥¼ ì¤€ë¹„](https ://huggingface.co/docs/datasets/image_dataset#imagefolder)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ì ì»¤ìŠ¤í…€ loading logicì„ ì‚¬ìš©í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ì‹­ì‹œì˜¤. ë„ì›€ì´ ë˜ë„ë¡ ì½”ë“œì˜ ì ì ˆí•œ ìœ„ì¹˜ì— í¬ì¸í„°ë¥¼ ë‚¨ê²¼ìŠµë‹ˆë‹¤. ğŸ¤— ì•„ë˜ ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ëŠ” `TRAIN_DIR`ì˜ ë¡œì»¬ ë°ì´í„°ì…‹ìœ¼ë¡œë¥¼ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ê³¼ `OUTPUT_DIR`ì—ì„œ ëª¨ë¸ì„ ì €ì¥í•  ìœ„ì¹˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤:


```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export TRAIN_DIR="path_to_your_dataset"
export OUTPUT_DIR="path_to_save_model"

accelerate launch train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --train_data_dir=$TRAIN_DIR \
  --use_ema \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --mixed_precision="fp16" \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir=${OUTPUT_DIR}
```

</pt>
<jax>
[@duongna211](https://github.com/duongna21)ì˜ ê¸°ì—¬ë¡œ, Flaxë¥¼ ì‚¬ìš©í•´ TPU ë° GPUì—ì„œ Stable Diffusion ëª¨ë¸ì„ ë” ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” TPU í•˜ë“œì›¨ì–´ì—ì„œ ë§¤ìš° íš¨ìœ¨ì ì´ì§€ë§Œ GPUì—ì„œë„ í›Œë¥­í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤. Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” gradient checkpointingë‚˜ gradient accumulationê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì•„ì§ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë©”ëª¨ë¦¬ê°€ 30GB ì´ìƒì¸ GPU ë˜ëŠ” TPU v3ê°€ í•„ìš”í•©ë‹ˆë‹¤.

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ìš”êµ¬ ì‚¬í•­ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤:

```bash
pip install -U -r requirements_flax.txt
```

ê·¸ëŸ¬ë©´ ë‹¤ìŒê³¼ ê°™ì´ [Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_flax.py)ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export dataset_name="lambdalabs/naruto-blip-captions"

python train_text_to_image_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --output_dir="sd-naruto-model"
```

ìì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ë ¤ë©´ ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/index)ì—ì„œ ìš”êµ¬í•˜ëŠ” í˜•ì‹ì— ë”°ë¼ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ì„¸ìš”. [ë°ì´í„°ì…‹ì„ í—ˆë¸Œì— ì—…ë¡œë“œ](https://huggingface.co/docs/datasets/image_dataset#upload-dataset-to-the-hub)í•˜ê±°ë‚˜ [íŒŒì¼ë“¤ì´ ìˆëŠ” ë¡œì»¬ í´ë”ë¥¼ ì¤€ë¹„](https ://huggingface.co/docs/datasets/image_dataset#imagefolder)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ì ì»¤ìŠ¤í…€ loading logicì„ ì‚¬ìš©í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ì‹­ì‹œì˜¤. ë„ì›€ì´ ë˜ë„ë¡ ì½”ë“œì˜ ì ì ˆí•œ ìœ„ì¹˜ì— í¬ì¸í„°ë¥¼ ë‚¨ê²¼ìŠµë‹ˆë‹¤. ğŸ¤— ì•„ë˜ ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ëŠ” `TRAIN_DIR`ì˜ ë¡œì»¬ ë°ì´í„°ì…‹ìœ¼ë¡œë¥¼ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

```bash
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export TRAIN_DIR="path_to_your_dataset"

python train_text_to_image_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --train_data_dir=$TRAIN_DIR \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --mixed_precision="fp16" \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --output_dir="sd-naruto-model"
```
</jax>
</frameworkcontent>

## LoRA

Text-to-image ëª¨ë¸ íŒŒì¸íŠœë‹ì„ ìœ„í•´, ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµì„ ê°€ì†í™”í•˜ê¸° ìœ„í•œ íŒŒì¸íŠœë‹ ê¸°ìˆ ì¸ LoRA(Low-Rank Adaptation of Large Language Models)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LoRA í•™ìŠµ](lora#text-to-image) ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì¶”ë¡ 

í—ˆë¸Œì˜ ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” ëª¨ë¸ ì´ë¦„ì„ [`StableDiffusionPipeline`]ì— ì „ë‹¬í•˜ì—¬ ì¶”ë¡ ì„ ìœ„í•´ íŒŒì¸ íŠœë‹ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

<frameworkcontent>
<pt>
```python
from diffusers import StableDiffusionPipeline

model_path = "path_to_saved_model"
pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)
pipe.to("cuda")

image = pipe(prompt="yoda").images[0]
image.save("yoda-naruto.png")
```
</pt>
<jax>
```python
import jax
import numpy as np
from flax.jax_utils import replicate
from flax.training.common_utils import shard
from diffusers import FlaxStableDiffusionPipeline

model_path = "path_to_saved_model"
pipe, params = FlaxStableDiffusionPipeline.from_pretrained(model_path, dtype=jax.numpy.bfloat16)

prompt = "yoda naruto"
prng_seed = jax.random.PRNGKey(0)
num_inference_steps = 50

num_samples = jax.device_count()
prompt = num_samples * [prompt]
prompt_ids = pipeline.prepare_inputs(prompt)

# shard inputs and rng
params = replicate(params)
prng_seed = jax.random.split(prng_seed, jax.device_count())
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images
images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
image.save("yoda-naruto.png")
```
</jax>
</frameworkcontent>