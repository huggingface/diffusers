<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->


# Stable Diffusion text-to-image ë¯¸ì„¸ ì¡°ì •

[`train_text_to_image.py`](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image) ìŠ¤í¬ë¦½íŠ¸ëŠ” ìì²´ ë°ì´í„°ì…‹ì—ì„œ stable diffusion ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

<Tip warning={true}>

text-to-image ë¯¸ì„¸ ì¡°ì • ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‹¤í—˜ì ì…ë‹ˆë‹¤. ê³¼ì í•©í•˜ê¸° ì‰½ê³  ì¹˜ëª…ì ì¸ ë§ê°ê³¼ ê°™ì€ ë¬¸ì œì— ë¶€ë”ªíˆê¸° ì‰½ìŠµë‹ˆë‹¤. ìì²´ ë°ì´í„°ì…‹ì—ì„œ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
</Tip>


## ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê¸°

### dependency ì„¤ì¹˜í•˜ê¸°

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì—, ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•™ìŠµ dependencyë“¤ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
pip install git+https://github.com/huggingface/diffusers.git
pip install -U -r requirements.txt
```

ê·¸ë¦¬ê³  [ğŸ¤—ê°€ì†](https://github.com/huggingface/accelerate/) í™˜ê²½ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤:

```bash
accelerate config
```

ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ì‚¬ìš©í•˜ê¸° ì „ì— ëª¨ë¸ ë¼ì´ì„ ìŠ¤ì— ë™ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” ëª¨ë¸ ë²„ì „ `v1-4`ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, [ì´ ë§í¬](https://huggingface.co/CompVis/stable-diffusion-v1-4)ë¥¼ ë°©ë¬¸í•˜ì—¬ ë¼ì´ì„ ìŠ¤ë¥¼ ì½ê³  ë™ì˜í•˜ë©´ í™•ì¸ë€ì„ ì„ íƒí•˜ì‹­ì‹œì˜¤.

ğŸ¤— Hugging Face Hubì— ë“±ë¡ëœ ì‚¬ìš©ìì—¬ì•¼ í•˜ë©°, ì½”ë“œë¥¼ ì‘ë™í•˜ê¸° ìœ„í•´ ì•¡ì„¸ìŠ¤ í† í°ë„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì•¡ì„¸ìŠ¤ í† í°ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ë¬¸ì„œì˜ ì´ ì„¹ì…˜](https://huggingface.co/docs/hub/security-tokens)ì„ ì°¸ì¡°í•˜ì„¸ìš”.

ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ í† í°ì„ ì¸ì¦í•©ë‹ˆë‹¤.

```bash
huggingface-cli login
```

ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì´ë¯¸ ë³µì œí•œ ê²½ìš°, ì´ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹ , ë¡œì»¬ ì²´í¬ì•„ì›ƒ ê²½ë¡œë¥¼ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ëª…ì‹œí•  ìˆ˜ ìˆìœ¼ë©° ê±°ê¸°ì—ì„œ ë¡œë“œë©ë‹ˆë‹¤.

### ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ í•˜ë“œì›¨ì–´ ìš”êµ¬ ì‚¬í•­

`gradient_checkpointing` ë° `mixed_precision`ì„ ì‚¬ìš©í•˜ë©´ ë‹¨ì¼ 24GB GPUì—ì„œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë†’ì€ `batch_size`ì™€ ë” ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ì„œëŠ” GPU ë©”ëª¨ë¦¬ê°€ 30GB ì´ìƒì¸ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. TPU ë˜ëŠ” GPUì—ì„œ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•´ JAXë‚˜ Flaxë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì•„ë˜](#flax-jax-finetuning)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### ë¯¸ì„¸ ì¡°ì • ì˜ˆì‹œ

ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ëŠ” Hugging Face Hubì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” [Justin Pinkneysì´ ìº¡ì…˜í•œ Pokemon ë°ì´í„°ì…‹](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì • ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export dataset_name="lambdalabs/pokemon-blip-captions"

accelerate launch train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name \
  --use_ema \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --mixed_precision="fp16" \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir="sd-pokemon-model" 
```

ìì²´ í•™ìŠµ íŒŒì¼ì—ì„œ ì‹¤í–‰í•˜ë ¤ë©´ `datasets`ì— í•„ìš”í•œ í˜•ì‹ì— ë”°ë¼ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì„ í—ˆë¸Œì— ì—…ë¡œë“œí•˜ê±°ë‚˜ íŒŒì¼ì´ ìˆëŠ” ë¡œì»¬ í´ë”ë¥¼ ì¤€ë¹„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ì´ ë¬¸ì„œ](https://huggingface.co/docs/datasets/v2.4.0/en/image_load#imagefolder-with-metadata)ì—ì„œ ì´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

ì»¤ìŠ¤í…€ ë¡œë”© ë¡œì§ì„ ì‚¬ìš©í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì½”ë“œì˜ ì ì ˆí•œ ìœ„ì¹˜ì— í¬ì¸í„°ë¥¼ ë‚¨ê²¼ìŠµë‹ˆë‹¤ :)

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export TRAIN_DIR="path_to_your_dataset"
export OUTPUT_DIR="path_to_save_model"

accelerate launch train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --train_data_dir=$TRAIN_DIR \
  --use_ema \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --mixed_precision="fp16" \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir=${OUTPUT_DIR}
```

í•™ìŠµì´ ì™„ë£Œë˜ë©´ ëª¨ë¸ì€ ëª…ë ¹ì— ì§€ì •ëœ `OUTPUT_DIR`ì— ì €ì¥ë©ë‹ˆë‹¤. ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ë ¤ë©´, í•´ë‹¹ ê²½ë¡œë¥¼ `StableDiffusionPipeline`ìœ¼ë¡œ ì „ë‹¬í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤:

```python
from diffusers import StableDiffusionPipeline

model_path = "path_to_saved_model"
pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)
pipe.to("cuda")

image = pipe(prompt="yoda").images[0]
image.save("yoda-pokemon.png")
```

### Flax / JAX ë¯¸ì„¸ ì¡°ì •

[@duongna211](https://github.com/duongna21) ë•ë¶„ì— Flaxë¥¼ ì‚¬ìš©í•˜ì—¬ Stable Diffusionì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì´ëŠ” TPU í•˜ë“œì›¨ì–´ì—ì„œ ë§¤ìš° íš¨ìœ¨ì ì´ì§€ë§Œ GPUì—ì„œë„ í›Œë¥­í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ [Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_flax.py)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```Python
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export dataset_name="lambdalabs/pokemon-blip-captions"

python train_text_to_image_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --output_dir="sd-pokemon-model" 
```
