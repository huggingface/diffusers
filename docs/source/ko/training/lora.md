<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Low-Rank Adaptation of Large Language Models (LoRA)

[[open-in-colab]]

<Tip warning={true}>

ν„μ¬ LoRAλ” [`UNet2DConditionalModel`]μ μ–΄ν…μ… λ μ΄μ–΄μ—μ„λ§ μ§€μ›λ©λ‹λ‹¤.

</Tip>

[LoRA(Low-Rank Adaptation of Large Language Models)](https://arxiv.org/abs/2106.09685)λ” λ©”λ¨λ¦¬λ¥Ό μ κ² μ‚¬μ©ν•λ©΄μ„ λ€κ·λ¨ λ¨λΈμ ν•™μµμ„ κ°€μ†ν™”ν•λ” ν•™μµ λ°©λ²•μ…λ‹λ‹¤. μ΄λ” rank-decomposition weight ν–‰λ ¬ μ(**μ—…λ°μ΄νΈ ν–‰λ ¬**μ΄λΌκ³  ν•¨)μ„ μ¶”κ°€ν•κ³  μƒλ΅ μ¶”κ°€λ κ°€μ¤‘μΉ**λ§** ν•™μµν•©λ‹λ‹¤. μ—¬κΈ°μ—λ” λ‡ κ°€μ§€ μ¥μ μ΄ μμµλ‹λ‹¤.

- μ΄μ „μ— λ―Έλ¦¬ ν•™μµλ κ°€μ¤‘μΉλ” κ³ μ •λ μƒνƒλ΅ μ μ§€λλ―€λ΅ λ¨λΈμ΄ [μΉλ…μ μΈ λ§κ°](https://www.pnas.org/doi/10.1073/pnas.1611835114) κ²½ν–¥μ΄ μ—†μµλ‹λ‹¤.
- Rank-decomposition ν–‰λ ¬μ€ μ›λ λ¨λΈλ³΄λ‹¤ νλΌλ©”ν„° μκ°€ ν›¨μ”¬ μ μΌλ―€λ΅ ν•™μµλ LoRA κ°€μ¤‘μΉλ¥Ό μ‰½κ² λΌμ›λ„£μ„ μ μμµλ‹λ‹¤.
- LoRA λ§¤νΈλ¦­μ¤λ” μΌλ°μ μΌλ΅ μ›λ³Έ λ¨λΈμ μ–΄ν…μ… λ μ΄μ–΄μ— μ¶”κ°€λ©λ‹λ‹¤. π§¨ Diffusersλ” [`~diffusers.loaders.UNet2DConditionLoadersMixin.load_attn_procs`] λ©”μ„λ“λ¥Ό μ κ³µν•μ—¬ LoRA κ°€μ¤‘μΉλ¥Ό λ¨λΈμ μ–΄ν…μ… λ μ΄μ–΄λ΅ λ¶λ¬μµλ‹λ‹¤. `scale` λ§¤κ°λ³€μλ¥Ό ν†µν•΄ λ¨λΈμ΄ μƒλ΅μ΄ ν•™μµ μ΄λ―Έμ§€μ— λ§κ² μ΅°μ •λλ” λ²”μ„λ¥Ό μ μ–΄ν•  μ μμµλ‹λ‹¤.
- λ©”λ¨λ¦¬ ν¨μ¨μ„±μ΄ ν–¥μƒλμ–΄ Tesla T4, RTX 3080 λλ” RTX 2080 Tiμ™€ κ°™μ€ μ†λΉ„μμ© GPUμ—μ„ νμΈνλ‹μ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤! T4μ™€ κ°™μ€ GPUλ” λ¬΄λ£μ΄λ©° Kaggle λλ” Google Colab λ…ΈνΈλ¶μ—μ„ μ‰½κ² μ•΅μ„Έμ¤ν•  μ μμµλ‹λ‹¤.


<Tip>

π’΅ LoRAλ” μ–΄ν…μ… λ μ΄μ–΄μ—λ§ ν•μ •λμ§€λ” μ•μµλ‹λ‹¤. μ €μλ” μ–Έμ–΄ λ¨λΈμ μ–΄ν…μ… λ μ΄μ–΄λ¥Ό μμ •ν•λ” κ²ƒμ΄ λ§¤μ° ν¨μ¨μ μΌλ΅ μ£»μ€ μ„±λ¥μ„ μ–»κΈ°μ— μ¶©λ¶„ν•λ‹¤λ” κ²ƒμ„ λ°κ²¬ν–μµλ‹λ‹¤. μ΄κ²ƒμ΄ LoRA κ°€μ¤‘μΉλ¥Ό λ¨λΈμ μ–΄ν…μ… λ μ΄μ–΄μ— μ¶”κ°€ν•λ” κ²ƒμ΄ μΌλ°μ μΈ μ΄μ μ…λ‹λ‹¤. LoRA μ‘λ™ λ°©μ‹μ— λ€ν• μμ„Έν• λ‚΄μ©μ€ [Using LoRA for effective Stable Diffusion fine-tuning](https://huggingface.co/blog/lora) λΈ”λ΅κ·Έλ¥Ό ν™•μΈν•μ„Έμ”!

</Tip>

[cloneofsimo](https://github.com/cloneofsimo)λ” μΈκΈ° μλ” [lora](https://github.com/cloneofsimo/lora) GitHub λ¦¬ν¬μ§€ν† λ¦¬μ—μ„ Stable Diffusionμ„ μ„ν• LoRA ν•™μµμ„ μµμ΄λ΅ μ‹λ„ν–μµλ‹λ‹¤. π§¨ Diffusersλ” [text-to-image μƒμ„±](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image#training-with-lora) λ° [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#training-with-low-rank-adaptation-of-large-language-models-lora)μ„ μ§€μ›ν•©λ‹λ‹¤. μ΄ κ°€μ΄λ“λ” λ‘ κ°€μ§€λ¥Ό λ¨λ‘ μν–‰ν•λ” λ°©λ²•μ„ λ³΄μ—¬μ¤λ‹λ‹¤.

λ¨λΈμ„ μ €μ¥ν•κ±°λ‚ μ»¤λ®¤λ‹ν‹°μ™€ κ³µμ ν•λ ¤λ©΄ Hugging Face κ³„μ •μ— λ΅κ·ΈμΈν•μ„Έμ”(μ•„μ§ κ³„μ •μ΄ μ—†λ” κ²½μ° [μƒμ„±](https://huggingface.co/join)ν•μ„Έμ”):

```bash
huggingface-cli login
```

## Text-to-image

μμ‹­μ–µ κ°μ νλΌλ©”ν„°λ“¤μ΄ μλ” Stable Diffusionκ³Ό κ°™μ€ λ¨λΈμ„ νμΈνλ‹ν•λ” κ²ƒμ€ λλ¦¬κ³  μ–΄λ ¤μΈ μ μμµλ‹λ‹¤. LoRAλ¥Ό μ‚¬μ©ν•λ©΄ diffusion λ¨λΈμ„ νμΈνλ‹ν•λ” κ²ƒμ΄ ν›¨μ”¬ μ‰½κ³  λΉ λ¦…λ‹λ‹¤. 8λΉ„νΈ μµν‹°λ§μ΄μ €μ™€ κ°™μ€ νΈλ¦­μ— μμ΅΄ν•μ§€ μ•κ³ λ„ 11GBμ GPU RAMμΌλ΅ ν•λ“μ›¨μ–΄μ—μ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤.


### ν•™μµ[[dreambooth-training]]

[Naruto BLIP μΊ΅μ…](https://huggingface.co/datasets/lambdalabs/naruto-blip-captions) λ°μ΄ν„°μ…‹μΌλ΅ [`stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5)λ¥Ό νμΈνλ‹ν•΄ λ‚λ§μ ν¬μΌ“λ¬μ„ μƒμ„±ν•΄ λ³΄κ² μµλ‹λ‹¤.

μ‹μ‘ν•λ ¤λ©΄ `MODEL_NAME` λ° `DATASET_NAME` ν™κ²½ λ³€μκ°€ μ„¤μ •λμ–΄ μλ”μ§€ ν™•μΈν•μ‹­μ‹μ¤. `OUTPUT_DIR` λ° `HUB_MODEL_ID` λ³€μλ” μ„ νƒ μ‚¬ν•­μ΄λ©° ν—λΈμ—μ„ λ¨λΈμ„ μ €μ¥ν•  μ„μΉλ¥Ό μ§€μ •ν•©λ‹λ‹¤.

```bash
export MODEL_NAME="stable-diffusion-v1-5/stable-diffusion-v1-5"
export OUTPUT_DIR="/sddata/finetune/lora/naruto"
export HUB_MODEL_ID="naruto-lora"
export DATASET_NAME="lambdalabs/naruto-blip-captions"
```

ν•™μµμ„ μ‹μ‘ν•κΈ° μ „μ— μ•μ•„μ•Ό ν•  λ‡ κ°€μ§€ ν”λκ·Έκ°€ μμµλ‹λ‹¤.

* `--push_to_hub`λ¥Ό λ…μ‹ν•λ©΄ ν•™μµλ LoRA μ„λ² λ”©μ„ ν—λΈμ— μ €μ¥ν•©λ‹λ‹¤.
* `--report_to=wandb`λ” ν•™μµ κ²°κ³Όλ¥Ό κ°€μ¤‘μΉ λ° νΈν–¥ λ€μ‹λ³΄λ“μ— λ³΄κ³ ν•κ³  κΈ°λ΅ν•©λ‹λ‹¤(μλ¥Ό λ“¤μ–΄, μ΄ [λ³΄κ³ μ„](https://wandb.ai/pcuenq/text2image-fine-tune/run/b4k1w0tn?workspace=user-pcuenq)λ¥Ό μ°Έμ΅°ν•μ„Έμ”).
* `--learning_rate=1e-04`, μΌλ°μ μΌλ΅ LoRAμ—μ„ μ‚¬μ©ν•λ” κ²ƒλ³΄λ‹¤ λ” λ†’μ€ ν•™μµλ¥ μ„ μ‚¬μ©ν•  μ μμµλ‹λ‹¤.

μ΄μ  ν•™μµμ„ μ‹μ‘ν•  μ¤€λΉ„κ°€ λμ—μµλ‹λ‹¤ (μ „μ²΄ ν•™μµ μ¤ν¬λ¦½νΈλ” [μ—¬κΈ°](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)μ—μ„ μ°Ύμ„ μ μμµλ‹λ‹¤).

```bash
accelerate launch train_dreambooth_lora.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --checkpointing_steps=100 \
  --learning_rate=1e-4 \
  --report_to="wandb" \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=500 \
  --validation_prompt="A photo of sks dog in a bucket" \
  --validation_epochs=50 \
  --seed="0" \
  --push_to_hub
```

### μ¶”λ΅ [[dreambooth-inference]]

μ΄μ  [`StableDiffusionPipeline`]μ—μ„ κΈ°λ³Έ λ¨λΈμ„ λ¶λ¬μ™€ μ¶”λ΅ μ„ μ„ν•΄ λ¨λΈμ„ μ‚¬μ©ν•  μ μμµλ‹λ‹¤:

```py
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> model_base = "stable-diffusion-v1-5/stable-diffusion-v1-5"

>>> pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)
```

*κΈ°λ³Έ λ¨λΈμ κ°€μ¤‘μΉ μ„μ—* νμΈνλ‹λ DreamBooth λ¨λΈμ—μ„ LoRA κ°€μ¤‘μΉλ¥Ό λ¶λ¬μ¨ λ‹¤μ, λ” λΉ λ¥Έ μ¶”λ΅ μ„ μ„ν•΄ νμ΄ν”„λΌμΈμ„ GPUλ΅ μ΄λ™ν•©λ‹λ‹¤. LoRA κ°€μ¤‘μΉλ¥Ό ν”„λ¦¬μ§•λ μ‚¬μ „ ν›λ ¨λ λ¨λΈ κ°€μ¤‘μΉμ™€ λ³‘ν•©ν•  λ•, μ„ νƒμ μΌλ΅ 'scale' λ§¤κ°λ³€μλ΅ μ–΄λ μ •λ„μ κ°€μ¤‘μΉλ¥Ό λ³‘ν•©ν•  μ§€ μ΅°μ ν•  μ μμµλ‹λ‹¤:

<Tip>

π’΅ `0`μ `scale` κ°’μ€ LoRA κ°€μ¤‘μΉλ¥Ό μ‚¬μ©ν•μ§€ μ•μ•„ μ›λ λ¨λΈμ κ°€μ¤‘μΉλ§ μ‚¬μ©ν• κ²ƒκ³Ό κ°™κ³ , `1`μ `scale` κ°’μ€ νμΈνλ‹λ LoRA κ°€μ¤‘μΉλ§ μ‚¬μ©ν•¨μ„ μλ―Έν•©λ‹λ‹¤. 0κ³Ό 1 μ‚¬μ΄μ κ°’λ“¤μ€ λ‘ κ²°κ³Όλ“¤ μ‚¬μ΄λ΅ λ³΄κ°„λ©λ‹λ‹¤.

</Tip>

```py
>>> pipe.unet.load_attn_procs(model_path)
>>> pipe.to("cuda")
# LoRA νμΈνλ‹λ λ¨λΈμ κ°€μ¤‘μΉ μ λ°κ³Ό κΈ°λ³Έ λ¨λΈμ κ°€μ¤‘μΉ μ λ° μ‚¬μ©

>>> image = pipe(
...     "A picture of a sks dog in a bucket.",
...     num_inference_steps=25,
...     guidance_scale=7.5,
...     cross_attention_kwargs={"scale": 0.5},
... ).images[0]
# μ™„μ „ν νμΈνλ‹λ LoRA λ¨λΈμ κ°€μ¤‘μΉ μ‚¬μ©

>>> image = pipe("A picture of a sks dog in a bucket.", num_inference_steps=25, guidance_scale=7.5).images[0]
>>> image.save("bucket-dog.png")
```