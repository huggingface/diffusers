<!--Copyright 2025 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Low-Rank Adaptation of Large Language Models (LoRA)

[[open-in-colab]]

> [!WARNING]
> í˜„ìž¬ LoRAëŠ” [`UNet2DConditionalModel`]ì˜ ì–´í…ì…˜ ë ˆì´ì–´ì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.

[LoRA(Low-Rank Adaptation of Large Language Models)](https://huggingface.co/papers/2106.09685)ëŠ” ë©”ëª¨ë¦¬ë¥¼ ì ê²Œ ì‚¬ìš©í•˜ë©´ì„œ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ í•™ìŠµì„ ê°€ì†í™”í•˜ëŠ” í•™ìŠµ ë°©ë²•ìž…ë‹ˆë‹¤. ì´ëŠ” rank-decomposition weight í–‰ë ¬ ìŒ(**ì—…ë°ì´íŠ¸ í–‰ë ¬**ì´ë¼ê³  í•¨)ì„ ì¶”ê°€í•˜ê³  ìƒˆë¡œ ì¶”ê°€ëœ ê°€ì¤‘ì¹˜**ë§Œ** í•™ìŠµí•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ëª‡ ê°€ì§€ ìž¥ì ì´ ìžˆìŠµë‹ˆë‹¤.

- ì´ì „ì— ë¯¸ë¦¬ í•™ìŠµëœ ê°€ì¤‘ì¹˜ëŠ” ê³ ì •ëœ ìƒíƒœë¡œ ìœ ì§€ë˜ë¯€ë¡œ ëª¨ë¸ì´ [ì¹˜ëª…ì ì¸ ë§ê°](https://www.pnas.org/doi/10.1073/pnas.1611835114) ê²½í–¥ì´ ì—†ìŠµë‹ˆë‹¤.
- Rank-decomposition í–‰ë ¬ì€ ì›ëž˜ ëª¨ë¸ë³´ë‹¤ íŒŒë¼ë©”í„° ìˆ˜ê°€ í›¨ì”¬ ì ìœ¼ë¯€ë¡œ í•™ìŠµëœ LoRA ê°€ì¤‘ì¹˜ë¥¼ ì‰½ê²Œ ë¼ì›Œë„£ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
- LoRA ë§¤íŠ¸ë¦­ìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì›ë³¸ ëª¨ë¸ì˜ ì–´í…ì…˜ ë ˆì´ì–´ì— ì¶”ê°€ë©ë‹ˆë‹¤. ðŸ§¨ DiffusersëŠ” [`~diffusers.loaders.UNet2DConditionLoadersMixin.load_attn_procs`] ë©”ì„œë“œë¥¼ ì œê³µí•˜ì—¬ LoRA ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì˜ ì–´í…ì…˜ ë ˆì´ì–´ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. `scale` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ëª¨ë¸ì´ ìƒˆë¡œìš´ í•™ìŠµ ì´ë¯¸ì§€ì— ë§žê²Œ ì¡°ì •ë˜ëŠ” ë²”ìœ„ë¥¼ ì œì–´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì´ í–¥ìƒë˜ì–´ Tesla T4, RTX 3080 ë˜ëŠ” RTX 2080 Tiì™€ ê°™ì€ ì†Œë¹„ìžìš© GPUì—ì„œ íŒŒì¸íŠœë‹ì„ ì‹¤í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤! T4ì™€ ê°™ì€ GPUëŠ” ë¬´ë£Œì´ë©° Kaggle ë˜ëŠ” Google Colab ë…¸íŠ¸ë¶ì—ì„œ ì‰½ê²Œ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.


> [!TIP]
> ðŸ’¡ LoRAëŠ” ì–´í…ì…˜ ë ˆì´ì–´ì—ë§Œ í•œì •ë˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ì €ìžëŠ” ì–¸ì–´ ëª¨ë¸ì˜ ì–´í…ì…˜ ë ˆì´ì–´ë¥¼ ìˆ˜ì •í•˜ëŠ” ê²ƒì´ ë§¤ìš° íš¨ìœ¨ì ìœ¼ë¡œ ì£»ì€ ì„±ëŠ¥ì„ ì–»ê¸°ì— ì¶©ë¶„í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ LoRA ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì˜ ì–´í…ì…˜ ë ˆì´ì–´ì— ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ ì´ìœ ìž…ë‹ˆë‹¤. LoRA ìž‘ë™ ë°©ì‹ì— ëŒ€í•œ ìžì„¸í•œ ë‚´ìš©ì€ [Using LoRA for effective Stable Diffusion fine-tuning](https://huggingface.co/blog/lora) ë¸”ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”!

[cloneofsimo](https://github.com/cloneofsimo)ëŠ” ì¸ê¸° ìžˆëŠ” [lora](https://github.com/cloneofsimo/lora) GitHub ë¦¬í¬ì§€í† ë¦¬ì—ì„œ Stable Diffusionì„ ìœ„í•œ LoRA í•™ìŠµì„ ìµœì´ˆë¡œ ì‹œë„í–ˆìŠµë‹ˆë‹¤. ðŸ§¨ DiffusersëŠ” [text-to-image ìƒì„±](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image#training-with-lora) ë° [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#training-with-low-rank-adaptation-of-large-language-models-lora)ì„ ì§€ì›í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ë‘ ê°€ì§€ë¥¼ ëª¨ë‘ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ëª¨ë¸ì„ ì €ìž¥í•˜ê±°ë‚˜ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•˜ë ¤ë©´ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì„¸ìš”(ì•„ì§ ê³„ì •ì´ ì—†ëŠ” ê²½ìš° [ìƒì„±](https://huggingface.co/join)í•˜ì„¸ìš”):

```bash
hf auth login
```

## Text-to-image

ìˆ˜ì‹­ì–µ ê°œì˜ íŒŒë¼ë©”í„°ë“¤ì´ ìžˆëŠ” Stable Diffusionê³¼ ê°™ì€ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ëŠ” ê²ƒì€ ëŠë¦¬ê³  ì–´ë ¤ìš¸ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. LoRAë¥¼ ì‚¬ìš©í•˜ë©´ diffusion ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ëŠ” ê²ƒì´ í›¨ì”¬ ì‰½ê³  ë¹ ë¦…ë‹ˆë‹¤. 8ë¹„íŠ¸ ì˜µí‹°ë§ˆì´ì €ì™€ ê°™ì€ íŠ¸ë¦­ì— ì˜ì¡´í•˜ì§€ ì•Šê³ ë„ 11GBì˜ GPU RAMìœ¼ë¡œ í•˜ë“œì›¨ì–´ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.


### í•™ìŠµ[[dreambooth-training]]

[Naruto BLIP ìº¡ì…˜](https://huggingface.co/datasets/lambdalabs/naruto-blip-captions) ë°ì´í„°ì…‹ìœ¼ë¡œ [`stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5)ë¥¼ íŒŒì¸íŠœë‹í•´ ë‚˜ë§Œì˜ í¬ì¼“ëª¬ì„ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.

ì‹œìž‘í•˜ë ¤ë©´ `MODEL_NAME` ë° `DATASET_NAME` í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤. `OUTPUT_DIR` ë° `HUB_MODEL_ID` ë³€ìˆ˜ëŠ” ì„ íƒ ì‚¬í•­ì´ë©° í—ˆë¸Œì—ì„œ ëª¨ë¸ì„ ì €ìž¥í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

```bash
export MODEL_NAME="stable-diffusion-v1-5/stable-diffusion-v1-5"
export OUTPUT_DIR="/sddata/finetune/lora/naruto"
export HUB_MODEL_ID="naruto-lora"
export DATASET_NAME="lambdalabs/naruto-blip-captions"
```

í•™ìŠµì„ ì‹œìž‘í•˜ê¸° ì „ì— ì•Œì•„ì•¼ í•  ëª‡ ê°€ì§€ í”Œëž˜ê·¸ê°€ ìžˆìŠµë‹ˆë‹¤.

* `--push_to_hub`ë¥¼ ëª…ì‹œí•˜ë©´ í•™ìŠµëœ LoRA ìž„ë² ë”©ì„ í—ˆë¸Œì— ì €ìž¥í•©ë‹ˆë‹¤.
* `--report_to=wandb`ëŠ” í•™ìŠµ ê²°ê³¼ë¥¼ ê°€ì¤‘ì¹˜ ë° íŽ¸í–¥ ëŒ€ì‹œë³´ë“œì— ë³´ê³ í•˜ê³  ê¸°ë¡í•©ë‹ˆë‹¤(ì˜ˆë¥¼ ë“¤ì–´, ì´ [ë³´ê³ ì„œ](https://wandb.ai/pcuenq/text2image-fine-tune/run/b4k1w0tn?workspace=user-pcuenq)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”).
* `--learning_rate=1e-04`, ì¼ë°˜ì ìœ¼ë¡œ LoRAì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ë†’ì€ í•™ìŠµë¥ ì„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

ì´ì œ í•™ìŠµì„ ì‹œìž‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤ (ì „ì²´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” [ì—¬ê¸°](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)ì—ì„œ ì°¾ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤).

```bash
accelerate launch train_dreambooth_lora.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --checkpointing_steps=100 \
  --learning_rate=1e-4 \
  --report_to="wandb" \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=500 \
  --validation_prompt="A photo of sks dog in a bucket" \
  --validation_epochs=50 \
  --seed="0" \
  --push_to_hub
```

### ì¶”ë¡ [[dreambooth-inference]]

ì´ì œ [`StableDiffusionPipeline`]ì—ì„œ ê¸°ë³¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ì¶”ë¡ ì„ ìœ„í•´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:

```py
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> model_base = "stable-diffusion-v1-5/stable-diffusion-v1-5"

>>> pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)
```

*ê¸°ë³¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ìœ„ì—* íŒŒì¸íŠœë‹ëœ DreamBooth ëª¨ë¸ì—ì„œ LoRA ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¨ ë‹¤ìŒ, ë” ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ íŒŒì´í”„ë¼ì¸ì„ GPUë¡œ ì´ë™í•©ë‹ˆë‹¤. LoRA ê°€ì¤‘ì¹˜ë¥¼ í”„ë¦¬ì§•ëœ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ ë³‘í•©í•  ë•Œ, ì„ íƒì ìœ¼ë¡œ 'scale' ë§¤ê°œë³€ìˆ˜ë¡œ ì–´ëŠ ì •ë„ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë³‘í•©í•  ì§€ ì¡°ì ˆí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:

> [!TIP]
> ðŸ’¡ `0`ì˜ `scale` ê°’ì€ LoRA ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ ì›ëž˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë§Œ ì‚¬ìš©í•œ ê²ƒê³¼ ê°™ê³ , `1`ì˜ `scale` ê°’ì€ íŒŒì¸íŠœë‹ëœ LoRA ê°€ì¤‘ì¹˜ë§Œ ì‚¬ìš©í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ë“¤ì€ ë‘ ê²°ê³¼ë“¤ ì‚¬ì´ë¡œ ë³´ê°„ë©ë‹ˆë‹¤.

```py
>>> pipe.unet.load_attn_procs(model_path)
>>> pipe.to("cuda")
# LoRA íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì ˆë°˜ê³¼ ê¸°ë³¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì ˆë°˜ ì‚¬ìš©

>>> image = pipe(
...     "A picture of a sks dog in a bucket.",
...     num_inference_steps=25,
...     guidance_scale=7.5,
...     cross_attention_kwargs={"scale": 0.5},
... ).images[0]
# ì™„ì „ížˆ íŒŒì¸íŠœë‹ëœ LoRA ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì‚¬ìš©

>>> image = pipe("A picture of a sks dog in a bucket.", num_inference_steps=25, guidance_scale=7.5).images[0]
>>> image.save("bucket-dog.png")
```