<!--Copyright 2023 Custom Diffusion authors The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# ì»¤ìŠ¤í…€ Diffusion í•™ìŠµ ì˜ˆì œ 

[ì»¤ìŠ¤í…€ Diffusion](https://arxiv.org/abs/2212.04488)ì€ í”¼ì‚¬ì²´ì˜ ì´ë¯¸ì§€ ëª‡ ì¥(4~5ì¥)ë§Œ ì£¼ì–´ì§€ë©´ Stable Diffusionì²˜ëŸ¼ text-to-image ëª¨ë¸ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
'train_custom_diffusion.py' ìŠ¤í¬ë¦½íŠ¸ëŠ” í•™ìŠµ ê³¼ì •ì„ êµ¬í˜„í•˜ê³  ì´ë¥¼ Stable Diffusionì— ë§ê²Œ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì´ êµìœ¡ ì‚¬ë¡€ëŠ” [Nupur Kumari](https://nupurkmr9.github.io/)ê°€ ì œê³µí•˜ì˜€ìŠµë‹ˆë‹¤. (Custom Diffusionì˜ ì €ì ì¤‘ í•œëª…). 

## ë¡œì»¬ì—ì„œ PyTorchë¡œ ì‹¤í–‰í•˜ê¸°

### Dependencies ì„¤ì¹˜í•˜ê¸°

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•™ìŠµ dependenciesë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

**ì¤‘ìš”**

ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ì˜ ìµœì‹  ë²„ì „ì„ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í•˜ë ¤ë©´ **ì†ŒìŠ¤ë¡œë¶€í„° ì„¤ì¹˜**í•˜ëŠ” ê²ƒì„ ë§¤ìš° ê¶Œì¥í•˜ë©°, ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìì£¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë§Œí¼ ì¼ë¶€ ì˜ˆì œë³„ ìš”êµ¬ ì‚¬í•­ì„ ì„¤ì¹˜í•˜ê³  ì„¤ì¹˜ë¥¼ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ìƒˆ ê°€ìƒ í™˜ê²½ì—ì„œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:


```bash
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
```

[example folder](https://github.com/huggingface/diffusers/tree/main/examples/custom_diffusion)ë¡œ cdí•˜ì—¬ ì´ë™í•˜ì„¸ìš”.

```
cd examples/custom_diffusion
```

ì´ì œ ì‹¤í–‰

```bash
pip install -r requirements.txt
pip install clip-retrieval 
```

ê·¸ë¦¬ê³  [ğŸ¤—Accelerate](https://github.com/huggingface/accelerate/) í™˜ê²½ì„ ì´ˆê¸°í™”:

```bash
accelerate config
```

ë˜ëŠ” ì‚¬ìš©ì í™˜ê²½ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ì§€ ì•Šê³  ê¸°ë³¸ ê°€ì† êµ¬ì„±ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•˜ì„¸ìš”.

```bash
accelerate config default
```

ë˜ëŠ” ì‚¬ìš© ì¤‘ì¸ í™˜ê²½ì´ ëŒ€í™”í˜• ì…¸ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš°(ì˜ˆ: jupyter notebook)

```python
from accelerate.utils import write_basic_config

write_basic_config()
```
### ê³ ì–‘ì´ ì˜ˆì œ ğŸ˜º

ì´ì œ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. [ì—¬ê¸°](https://www.cs.cmu.edu/~custom-diffusion/assets/data.zip)ì—ì„œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶•ì„ í’‰ë‹ˆë‹¤. ì§ì ‘ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë ¤ë©´ [í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°](create_dataset) ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

ë˜í•œ 'clip-retrieval'ì„ ì‚¬ìš©í•˜ì—¬ 200ê°œì˜ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³ , regularizationìœ¼ë¡œì„œ ì´ë¥¼ í•™ìŠµ ë°ì´í„°ì…‹ì˜ íƒ€ê²Ÿ ì´ë¯¸ì§€ì™€ ê²°í•©í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì£¼ì–´ì§„ íƒ€ê²Ÿ ì´ë¯¸ì§€ì— ëŒ€í•œ ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ë©´ `prior_loss_weight=1.`ë¡œ `prior_preservation`, `real_prior` regularizationì„ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
í´ë˜ìŠ¤_í”„ë¡¬í”„íŠ¸`ëŠ” ëŒ€ìƒ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ì¹´í…Œê³ ë¦¬ ì´ë¦„ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì‹¤ì œ ì´ë¯¸ì§€ì—ëŠ” `class_prompt`ì™€ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ìº¡ì…˜ì´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì´ë¯¸ì§€ëŠ” `class_data_dir`ì— ì €ì¥ë©ë‹ˆë‹¤. ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ regularizationìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `real_prior`ë¥¼ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ë ¤ë©´ í›ˆë ¨ ì „ì— ì´ ëª…ë ¹ì„ ë¨¼ì € ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. 

```bash
pip install clip-retrieval
python retrieve.py --class_prompt cat --class_data_dir real_reg/samples_cat --num_class_images 200
```

**___ì°¸ê³ : [stable-diffusion-2](https://huggingface.co/stabilityai/stable-diffusion-2) 768x768 ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° 'í•´ìƒë„'ë¥¼ 768ë¡œ ë³€ê²½í•˜ì„¸ìš”.___**

ìŠ¤í¬ë¦½íŠ¸ëŠ” ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì™€ `pytorch_custom_diffusion_weights.bin` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ì €ì¥ì†Œì— ì €ì¥í•©ë‹ˆë‹¤.

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export OUTPUT_DIR="path-to-save-model"
export INSTANCE_DIR="./data/cat"

accelerate launch train_custom_diffusion.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --class_data_dir=./real_reg/samples_cat/ \
  --with_prior_preservation --real_prior --prior_loss_weight=1.0 \
  --class_prompt="cat" --num_class_images=200 \
  --instance_prompt="photo of a <new1> cat"  \
  --resolution=512  \
  --train_batch_size=2  \
  --learning_rate=1e-5  \
  --lr_warmup_steps=0 \
  --max_train_steps=250 \
  --scale_lr --hflip  \
  --modifier_token "<new1>" \
  --push_to_hub
```

**ë” ë‚®ì€ VRAM ìš”êµ¬ ì‚¬í•­(GPUë‹¹ 16GB)ìœ¼ë¡œ ë” ë¹ ë¥´ê²Œ í›ˆë ¨í•˜ë ¤ë©´ `--enable_xformers_memory_efficient_attention`ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì„¤ì¹˜ ë°©ë²•ì€ [ê°€ì´ë“œ](https://github.com/facebookresearch/xformers)ë¥¼ ë”°ë¥´ì„¸ìš”.**

ê°€ì¤‘ì¹˜ ë° í¸í–¥(`wandb`)ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ì„ ì¶”ì í•˜ê³  ì¤‘ê°„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ë ¤ë©´(ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤) ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:

* `wandb` ì„¤ì¹˜: `pip install wandb`.
* ë¡œê·¸ì¸ : `wandb login`. 
* ê·¸ëŸ° ë‹¤ìŒ íŠ¸ë ˆì´ë‹ì„ ì‹œì‘í•˜ëŠ” ë™ì•ˆ `validation_prompt`ë¥¼ ì§€ì •í•˜ê³  `report_to`ë¥¼ `wandb`ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ê´€ë ¨ ì¸ìˆ˜ë¥¼ êµ¬ì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:
    * `num_validation_images`
    * `validation_steps`

```bash
accelerate launch train_custom_diffusion.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --class_data_dir=./real_reg/samples_cat/ \
  --with_prior_preservation --real_prior --prior_loss_weight=1.0 \
  --class_prompt="cat" --num_class_images=200 \
  --instance_prompt="photo of a <new1> cat"  \
  --resolution=512  \
  --train_batch_size=2  \
  --learning_rate=1e-5  \
  --lr_warmup_steps=0 \
  --max_train_steps=250 \
  --scale_lr --hflip  \
  --modifier_token "<new1>" \
  --validation_prompt="<new1> cat sitting in a bucket" \
  --report_to="wandb" \
  --push_to_hub
```

ë‹¤ìŒì€ [Weights and Biases page](https://wandb.ai/sayakpaul/custom-diffusion/runs/26ghrcau)ì˜ ì˜ˆì‹œì´ë©°, ì—¬ëŸ¬ í•™ìŠµ ì„¸ë¶€ ì •ë³´ì™€ í•¨ê»˜ ì¤‘ê°„ ê²°ê³¼ë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

`--push_to_hub`ë¥¼ ì§€ì •í•˜ë©´ í•™ìŠµëœ íŒŒë¼ë¯¸í„°ê°€ í—ˆê¹… í˜ì´ìŠ¤ í—ˆë¸Œì˜ ë¦¬í¬ì§€í† ë¦¬ì— í‘¸ì‹œë©ë‹ˆë‹¤. ë‹¤ìŒì€ [ì˜ˆì œ ë¦¬í¬ì§€í† ë¦¬](https://huggingface.co/sayakpaul/custom-diffusion-cat)ì…ë‹ˆë‹¤.

### ë©€í‹° ì»¨ì…‰ì— ëŒ€í•œ í•™ìŠµ ğŸ±ğŸªµ

[this](https://github.com/ShivamShrirao/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)ì™€ ìœ ì‚¬í•˜ê²Œ ê° ì»¨ì…‰ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ëœ [json](https://github.com/adobe-research/custom-diffusion/blob/main/assets/concept_list.json) íŒŒì¼ì„ ì œê³µí•©ë‹ˆë‹¤.

ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ë ¤ë©´ json íŒŒì¼ì˜ ê° ì»¨ì…‰ì— ëŒ€í•´ ì´ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. 

```bash
pip install clip-retrieval
python retrieve.py --class_prompt {} --class_data_dir {} --num_class_images 200
```

ê·¸ëŸ¼ ìš°ë¦¬ëŠ” í•™ìŠµì‹œí‚¬ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export OUTPUT_DIR="path-to-save-model"

accelerate launch train_custom_diffusion.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --output_dir=$OUTPUT_DIR \
  --concepts_list=./concept_list.json \
  --with_prior_preservation --real_prior --prior_loss_weight=1.0 \
  --resolution=512  \
  --train_batch_size=2  \
  --learning_rate=1e-5  \
  --lr_warmup_steps=0 \
  --max_train_steps=500 \
  --num_class_images=200 \
  --scale_lr --hflip  \
  --modifier_token "<new1>+<new2>" \
  --push_to_hub
```

ë‹¤ìŒì€ [Weights and Biases page](https://wandb.ai/sayakpaul/custom-diffusion/runs/3990tzkg)ì˜ ì˜ˆì‹œì´ë©°, ë‹¤ë¥¸ í•™ìŠµ ì„¸ë¶€ ì •ë³´ì™€ í•¨ê»˜ ì¤‘ê°„ ê²°ê³¼ë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì‚¬ëŒ ì–¼êµ´ì— ëŒ€í•œ í•™ìŠµ

ì‚¬ëŒ ì–¼êµ´ì— ëŒ€í•œ íŒŒì¸íŠœë‹ì„ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì„¤ì •ì´ ë” íš¨ê³¼ì ì´ë¼ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤: `learning_rate=5e-6`, `max_train_steps=1000 to 2000`, `freeze_model=crossattn`ì„ ìµœì†Œ 15~20ê°œì˜ ì´ë¯¸ì§€ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ë ¤ë©´ í›ˆë ¨ ì „ì— ì´ ëª…ë ¹ì„ ë¨¼ì € ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.

```bash
pip install clip-retrieval
python retrieve.py --class_prompt person --class_data_dir real_reg/samples_person --num_class_images 200
```

ì´ì œ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”!

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export OUTPUT_DIR="path-to-save-model"
export INSTANCE_DIR="path-to-images"

accelerate launch train_custom_diffusion.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --class_data_dir=./real_reg/samples_person/ \
  --with_prior_preservation --real_prior --prior_loss_weight=1.0 \
  --class_prompt="person" --num_class_images=200 \
  --instance_prompt="photo of a <new1> person"  \
  --resolution=512  \
  --train_batch_size=2  \
  --learning_rate=5e-6  \
  --lr_warmup_steps=0 \
  --max_train_steps=1000 \
  --scale_lr --hflip --noaug \
  --freeze_model crossattn \
  --modifier_token "<new1>" \
  --enable_xformers_memory_efficient_attention \
  --push_to_hub
```

## ì¶”ë¡ 

ìœ„ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ í›„ì—ëŠ” ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ì— 'modifier token'(ì˜ˆ: ìœ„ ì˜ˆì œì—ì„œëŠ” \<new1\>)ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

```python
import torch
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16).to("cuda")
pipe.unet.load_attn_procs("path-to-save-model", weight_name="pytorch_custom_diffusion_weights.bin")
pipe.load_textual_inversion("path-to-save-model", weight_name="<new1>.bin")

image = pipe(
    "<new1> cat sitting in a bucket",
    num_inference_steps=100,
    guidance_scale=6.0,
    eta=1.0,
).images[0]
image.save("cat.png")
```

í—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ì´ëŸ¬í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§ì ‘ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import torch
from huggingface_hub.repocard import RepoCard
from diffusers import DiffusionPipeline

model_id = "sayakpaul/custom-diffusion-cat"
card = RepoCard.load(model_id)
base_model_id = card.data.to_dict()["base_model"]

pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16).to("cuda")
pipe.unet.load_attn_procs(model_id, weight_name="pytorch_custom_diffusion_weights.bin")
pipe.load_textual_inversion(model_id, weight_name="<new1>.bin")

image = pipe(
    "<new1> cat sitting in a bucket",
    num_inference_steps=100,
    guidance_scale=6.0,
    eta=1.0,
).images[0]
image.save("cat.png")
```

ë‹¤ìŒì€ ì—¬ëŸ¬ ì»¨ì…‰ìœ¼ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤:

```python
import torch
from huggingface_hub.repocard import RepoCard
from diffusers import DiffusionPipeline

model_id = "sayakpaul/custom-diffusion-cat-wooden-pot"
card = RepoCard.load(model_id)
base_model_id = card.data.to_dict()["base_model"]

pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16).to("cuda")
pipe.unet.load_attn_procs(model_id, weight_name="pytorch_custom_diffusion_weights.bin")
pipe.load_textual_inversion(model_id, weight_name="<new1>.bin")
pipe.load_textual_inversion(model_id, weight_name="<new2>.bin")

image = pipe(
    "the <new1> cat sculpture in the style of a <new2> wooden pot",
    num_inference_steps=100,
    guidance_scale=6.0,
    eta=1.0,
).images[0]
image.save("multi-subject.png")
```

ì—¬ê¸°ì„œ 'ê³ ì–‘ì´'ì™€ 'ë‚˜ë¬´ ëƒ„ë¹„'ëŠ” ì—¬ëŸ¬ ì»¨ì…‰ì„ ë§í•©ë‹ˆë‹¤.

### í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¶”ë¡ í•˜ê¸°

`--checkpointing_steps`  ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•œ ê²½ìš° í•™ìŠµ ê³¼ì •ì—ì„œ ì €ì¥ëœ ì „ì²´ ì²´í¬í¬ì¸íŠ¸ ì¤‘ í•˜ë‚˜ì—ì„œ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. 

## Gradsë¥¼ Noneìœ¼ë¡œ ì„¤ì •

ë” ë§ì€ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ì— `--set_grads_to_none` ì¸ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”. ì´ë ‡ê²Œ í•˜ë©´ ì„±ì ì´ 0ì´ ì•„ë‹Œ ì—†ìŒìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ íŠ¹ì • ë™ì‘ì´ ë³€ê²½ë˜ë¯€ë¡œ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì´ ì¸ìˆ˜ë¥¼ ì œê±°í•˜ì„¸ìš”.

ìì„¸í•œ ì •ë³´: https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html

## ì‹¤í—˜ ê²°ê³¼

ì‹¤í—˜ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ë‹¹ì‚¬ ì›¹í˜ì´ì§€](https://www.cs.cmu.edu/~custom-diffusion/)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. 