 <!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->



# Textual-Inversion

[[open-in-colab]]

[textual-inversion](https://arxiv.org/abs/2208.01618)ì€ ì†Œìˆ˜ì˜ ì˜ˆì‹œ ì´ë¯¸ì§€ì—ì„œ ìƒˆë¡œìš´ ì½˜ì…‰íŠ¸ë¥¼ í¬ì°©í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì›ë˜ [Latent Diffusion](https://github.com/CompVis/latent-diffusion)ì—ì„œ ì‹œì—°ë˜ì—ˆì§€ë§Œ, ì´í›„ [Stable Diffusion](https://huggingface.co/docs/diffusers/main/en/conceptual/stable_diffusion)ê³¼ ê°™ì€ ìœ ì‚¬í•œ ë‹¤ë¥¸ ëª¨ë¸ì—ë„ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. í•™ìŠµëœ ì½˜ì…‰íŠ¸ëŠ” text-to-image íŒŒì´í”„ë¼ì¸ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë” ì˜ ì œì–´í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ ì¸ì½”ë”ì˜ ì„ë² ë”© ê³µê°„ì—ì„œ ìƒˆë¡œìš´ 'ë‹¨ì–´'ë¥¼ í•™ìŠµí•˜ì—¬ ê°œì¸í™”ëœ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.

![Textual Inversion example](https://textual-inversion.github.io/static/images/editing/colorful_teapot.JPG)
<small>By using just 3-5 images you can teach new concepts to a model such as Stable Diffusion for personalized image generation <a href="https://github.com/rinongal/textual_inversion">(image source)</a>.</small>

ì´ ê°€ì´ë“œì—ì„œëŠ” textual-inversionìœ¼ë¡œ [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5) ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œ ì‚¬ìš©ëœ ëª¨ë“  textual-inversion í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” [ì—¬ê¸°](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚´ë¶€ì ìœ¼ë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ìì„¸íˆ ì‚´í´ë³´ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ í•´ë‹¹ ë§í¬ë¥¼ ì°¸ì¡°í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

<Tip>

[Stable Diffusion Textual Inversion Concepts Library](https://huggingface.co/sd-concepts-library)ì—ëŠ” ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì œì‘í•œ í•™ìŠµëœ textual-inversion ëª¨ë¸ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë” ë§ì€ ì½˜ì…‰íŠ¸ë“¤ì´ ì¶”ê°€ë˜ì–´ ìœ ìš©í•œ ë¦¬ì†ŒìŠ¤ë¡œ ì„±ì¥í•  ê²ƒì…ë‹ˆë‹¤!

</Tip>

ì‹œì‘í•˜ê¸° ì „ì— í•™ìŠµì„ ìœ„í•œ ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
pip install diffusers accelerate transformers
```

ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì˜ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´, [ğŸ¤—Accelerate](https://github.com/huggingface/accelerate/) í™˜ê²½ì„ ì´ˆê¸°í™”ì‹œí‚µë‹ˆë‹¤.

```bash
accelerate config
```

ë³„ë„ì˜ ì„¤ì •ì—†ì´, ê¸°ë³¸ ğŸ¤—Accelerate í™˜ê²½ì„ ì„¤ì •í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•˜ì„¸ìš”:

```bash
accelerate config default
```

ë˜ëŠ” ì‚¬ìš© ì¤‘ì¸ í™˜ê²½ì´ ë…¸íŠ¸ë¶ê³¼ ê°™ì€ ëŒ€í™”í˜• ì…¸ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

ë§ˆì§€ë§‰ìœ¼ë¡œ, Memory-Efficient Attentionì„ í†µí•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ [xFormers](https://huggingface.co/docs/diffusers/main/en/training/optimization/xformers)ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. xFormersë¥¼ ì„¤ì¹˜í•œ í›„, í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— `--enable_xformers_memory_efficient_attention` ì¸ìë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. xFormersëŠ” Flaxì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## í—ˆë¸Œì— ëª¨ë¸ ì—…ë¡œë“œí•˜ê¸°

ëª¨ë¸ì„ í—ˆë¸Œì— ì €ì¥í•˜ë ¤ë©´, í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
--push_to_hub
```

## ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°

í•™ìŠµì¤‘ì— ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì •ê¸°ì ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì–´ë–¤ ì´ìœ ë¡œë“  í•™ìŠµì´ ì¤‘ë‹¨ëœ ê²½ìš° ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í•™ìŠµì„ ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìë¥¼ ì „ë‹¬í•˜ë©´ 500ë‹¨ê³„ë§ˆë‹¤ ì „ì²´ í•™ìŠµ ìƒíƒœê°€ `output_dir`ì˜ í•˜ìœ„ í´ë”ì— ì²´í¬í¬ì¸íŠ¸ë¡œì„œ ì €ì¥ë©ë‹ˆë‹¤.

```bash
--checkpointing_steps=500
```

ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í•™ìŠµì„ ì¬ê°œí•˜ë ¤ë©´, í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ì¬ê°œí•  íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ì— ë‹¤ìŒ ì¸ìë¥¼ ì „ë‹¬í•˜ì„¸ìš”.

```bash
--resume_from_checkpoint="checkpoint-1500"
```

## íŒŒì¸ íŠœë‹

í•™ìŠµìš© ë°ì´í„°ì…‹ìœ¼ë¡œ [ê³ ì–‘ì´ ì¥ë‚œê° ë°ì´í„°ì…‹](https://huggingface.co/datasets/diffusers/cat_toy_example)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ì„¸ìš”. ì—¬ëŸ¬ë¶„ë§Œì˜ ê³ ìœ í•œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê³ ì í•œë‹¤ë©´, [í•™ìŠµìš© ë°ì´í„°ì…‹ ë§Œë“¤ê¸°](https://huggingface.co/docs/diffusers/training/create_dataset) ê°€ì´ë“œë¥¼ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

```py
from huggingface_hub import snapshot_download

local_dir = "./cat"
snapshot_download(
    "diffusers/cat_toy_example", local_dir=local_dir, repo_type="dataset", ignore_patterns=".gitattributes"
)
```

ëª¨ë¸ì˜ ë¦¬í¬ì§€í† ë¦¬ ID(ë˜ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ í¬í•¨ëœ ë””ë ‰í„°ë¦¬ ê²½ë¡œ)ë¥¼ `MODEL_NAME` í™˜ê²½ ë³€ìˆ˜ì— í• ë‹¹í•˜ê³ , í•´ë‹¹ ê°’ì„ [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path) ì¸ìì— ì „ë‹¬í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ `DATA_DIR` í™˜ê²½ ë³€ìˆ˜ì— í• ë‹¹í•©ë‹ˆë‹¤.

ì´ì œ [í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ íŒŒì¼ì„ ìƒì„±í•˜ê³  ë¦¬í¬ì§€í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.

- `learned_embeds.bin`
- `token_identifier.txt`
- `type_of_concept.txt`.

<Tip>

ğŸ’¡V100 GPU 1ê°œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ í•™ìŠµì—ëŠ” ìµœëŒ€ 1ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤. í•™ìŠµì´ ì™„ë£Œë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ë™ì•ˆ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì•„ë˜ ì„¹ì…˜ì—ì„œ [textual-inversionì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€](https://huggingface.co/docs/diffusers/training/text_inversion#how-it-works) ììœ ë¡­ê²Œ í™•ì¸í•˜ì„¸ìš” !

</Tip>

<frameworkcontent>
<pt>
```bash
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export DATA_DIR="./cat"

accelerate launch textual_inversion.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --train_data_dir=$DATA_DIR \
  --learnable_property="object" \
  --placeholder_token="<cat-toy>" --initializer_token="toy" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --max_train_steps=3000 \
  --learning_rate=5.0e-04 --scale_lr \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --output_dir="textual_inversion_cat" \
  --push_to_hub
```

<Tip>

ğŸ’¡í•™ìŠµ ì„±ëŠ¥ì„ ì˜¬ë¦¬ê¸° ìœ„í•´, í”Œë ˆì´ìŠ¤í™€ë” í† í°(`<cat-toy>`)ì„ (ë‹¨ì¼í•œ ì„ë² ë”© ë²¡í„°ê°€ ì•„ë‹Œ) ë³µìˆ˜ì˜ ì„ë² ë”© ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒ ì—­ì‹œ ê³ ë ¤í•  ìˆìŠµë‹ˆë‹¤.  ì´ëŸ¬í•œ íŠ¸ë¦­ì´ ëª¨ë¸ì´ ë³´ë‹¤ ë³µì¡í•œ ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼(ì•ì„œ ë§í•œ ì½˜ì…‰íŠ¸)ì„ ë” ì˜ ìº¡ì²˜í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³µìˆ˜ì˜ ì„ë² ë”© ë²¡í„° í•™ìŠµì„ í™œì„±í™”í•˜ë ¤ë©´ ë‹¤ìŒ ì˜µì…˜ì„ ì „ë‹¬í•˜ì‹­ì‹œì˜¤.

```bash
--num_vectors=5
```

</Tip>
</pt>
<jax>

TPUì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ê²½ìš°, [Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion_flax.py)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê²Œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œë³´ì„¸ìš”. (ë¬¼ë¡  GPUì—ì„œë„ ì‘ë™í•©ë‹ˆë‹¤.) ë™ì¼í•œ ì„¤ì •ì—ì„œ Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” PyTorch í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë³´ë‹¤ ìµœì†Œ 70% ë” ë¹¨ë¼ì•¼ í•©ë‹ˆë‹¤! âš¡ï¸

ì‹œì‘í•˜ê¸° ì•ì„œ Flaxì— ëŒ€í•œ ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
pip install -U -r requirements_flax.txt
```

ëª¨ë¸ì˜ ë¦¬í¬ì§€í† ë¦¬ ID(ë˜ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ í¬í•¨ëœ ë””ë ‰í„°ë¦¬ ê²½ë¡œ)ë¥¼ `MODEL_NAME` í™˜ê²½ ë³€ìˆ˜ì— í• ë‹¹í•˜ê³ , í•´ë‹¹ ê°’ì„ [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path) ì¸ìì— ì „ë‹¬í•©ë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ [í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion_flax.py)ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export DATA_DIR="./cat"

python textual_inversion_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --train_data_dir=$DATA_DIR \
  --learnable_property="object" \
  --placeholder_token="<cat-toy>" --initializer_token="toy" \
  --resolution=512 \
  --train_batch_size=1 \
  --max_train_steps=3000 \
  --learning_rate=5.0e-04 --scale_lr \
  --output_dir="textual_inversion_cat" \
  --push_to_hub
```
</jax>
</frameworkcontent>

### ì¤‘ê°„ ë¡œê¹…

ëª¨ë¸ì˜ í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ëŠ” ë° ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš°, í•™ìŠµ ê³¼ì •ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ê°„ ë¡œê¹…ì„ í™œì„±í™”í•©ë‹ˆë‹¤.

- `validation_prompt` : ìƒ˜í”Œì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸(ê¸°ë³¸ê°’ì€ `None`ìœ¼ë¡œ ì„¤ì •ë˜ë©°, ì´ ë•Œ ì¤‘ê°„ ë¡œê¹…ì€ ë¹„í™œì„±í™”ë¨)
- `num_validation_images` : ìƒì„±í•  ìƒ˜í”Œ ì´ë¯¸ì§€ ìˆ˜
- `validation_steps` : `validation_prompt`ë¡œë¶€í„° ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ì „ ìŠ¤í…ì˜ ìˆ˜

```bash
--validation_prompt="A <cat-toy> backpack"
--num_validation_images=4
--validation_steps=100
```

## ì¶”ë¡ 

ëª¨ë¸ì„ í•™ìŠµí•œ í›„ì—ëŠ”, í•´ë‹¹ ëª¨ë¸ì„ [`StableDiffusionPipeline`]ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

textual-inversion ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ textual-inversionì„ í†µí•´ ì–»ì–´ì§„ ì„ë² ë”© ë²¡í„°ë§Œì„ ì €ì¥í•©ë‹ˆë‹¤. í•´ë‹¹ ì„ë² ë”© ë²¡í„°ë“¤ì€ í…ìŠ¤íŠ¸ ì¸ì½”ë”ì˜ ì„ë² ë”© í–‰ë ¬ì— ì¶”ê°€ë˜ì–´ ìˆìŠµìŠµë‹ˆë‹¤.

<frameworkcontent>
<pt>
<Tip>

ğŸ’¡ ì»¤ë®¤ë‹ˆí‹°ëŠ” [sd-concepts-library](https://huggingface.co/sd-concepts-library) ë¼ëŠ” ëŒ€ê·œëª¨ì˜ textual-inversion ì„ë² ë”© ë²¡í„° ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. textual-inversion ì„ë² ë”©ì„ ë°‘ë°”ë‹¥ë¶€í„° í•™ìŠµí•˜ëŠ” ëŒ€ì‹ , í•´ë‹¹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë³¸ì¸ì´ ì°¾ëŠ” textual-inversion ì„ë² ë”©ì´ ì´ë¯¸ ì¶”ê°€ë˜ì–´ ìˆì§€ ì•Šì€ì§€ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.

</Tip>

textual-inversion ì„ë² ë”© ë²¡í„°ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ì„œëŠ”, ë¨¼ì € í•´ë‹¹ ì„ë² ë”© ë²¡í„°ë¥¼ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ”  [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/docs/diffusers/training/runwayml/stable-diffusion-v1-5) ëª¨ë¸ì´ ì‚¬ìš©ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³  ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤.

```python
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")
```

ë‹¤ìŒìœ¼ë¡œ `TextualInversionLoaderMixin.load_textual_inversion` í•¨ìˆ˜ë¥¼ í†µí•´, textual-inversion ì„ë² ë”© ë²¡í„°ë¥¼ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ì´ì „ì˜ `<cat-toy>` ì˜ˆì œì˜ ì„ë² ë”©ì„ ë¶ˆëŸ¬ì˜¬ ê²ƒì…ë‹ˆë‹¤.

```python
pipe.load_textual_inversion("sd-concepts-library/cat-toy")
```

ì´ì œ í”Œë ˆì´ìŠ¤í™€ë” í† í°(`<cat-toy>`)ì´ ì˜ ë™ì‘í•˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
prompt = "A <cat-toy> backpack"

image = pipe(prompt, num_inference_steps=50).images[0]
image.save("cat-backpack.png")
```

`TextualInversionLoaderMixin.load_textual_inversion`ì€ Diffusers í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ í…ìŠ¤íŠ¸ ì„ë² ë”© ë²¡í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼, [Automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ì„ë² ë”© ë²¡í„°ë„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë ¤ë©´, ë¨¼ì € [civitAI](https://civitai.com/models/3036?modelVersionId=8387)ì—ì„œ ì„ë² ë”© ë²¡í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•œ ë‹¤ìŒ ë¡œì»¬ì—ì„œ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.

```python
pipe.load_textual_inversion("./charturnerv2.pt")
```
</pt>
<jax>

í˜„ì¬ Flaxì— ëŒ€í•œ `load_textual_inversion` í•¨ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í•™ìŠµ í›„ textual-inversion ì„ë² ë”© ë²¡í„°ê°€ ëª¨ë¸ì˜ ì¼ë¶€ë¡œì„œ ì €ì¥ë˜ì—ˆëŠ”ì§€ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒì€ ë‹¤ë¥¸ Flax ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import jax
import numpy as np
from flax.jax_utils import replicate
from flax.training.common_utils import shard
from diffusers import FlaxStableDiffusionPipeline

model_path = "path-to-your-trained-model"
pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(model_path, dtype=jax.numpy.bfloat16)

prompt = "A <cat-toy> backpack"
prng_seed = jax.random.PRNGKey(0)
num_inference_steps = 50

num_samples = jax.device_count()
prompt = num_samples * [prompt]
prompt_ids = pipeline.prepare_inputs(prompt)

# shard inputs and rng
params = replicate(params)
prng_seed = jax.random.split(prng_seed, jax.device_count())
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images
images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
image.save("cat-backpack.png")
```
</jax>
</frameworkcontent>

## ì‘ë™ ë°©ì‹

![Diagram from the paper showing overview](https://textual-inversion.github.io/static/images/training/training.JPG)
<small>Architecture overview from the Textual Inversion <a href="https://textual-inversion.github.io/">blog post.</a></small>

ì¼ë°˜ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì— ì „ë‹¬ë˜ê¸° ì „ì— ì„ë² ë”©ìœ¼ë¡œ í† í°í™”ë©ë‹ˆë‹¤. textual-inversionì€ ë¹„ìŠ·í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì§€ë§Œ, ìœ„ ë‹¤ì´ì–´ê·¸ë¨ì˜ íŠ¹ìˆ˜ í† í° `S*`ë¡œë¶€í„° ìƒˆë¡œìš´ í† í° ì„ë² ë”© `v*`ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ëª¨ë¸ì˜ ì•„ì›ƒí’‹ì€ ë””í“¨ì „ ëª¨ë¸ì„ ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ë””í“¨ì „ ëª¨ë¸ì´ ë‹¨ ëª‡ ê°œì˜ ì˜ˆì œ ì´ë¯¸ì§€ì—ì„œ ì‹ ì†í•˜ê³  ìƒˆë¡œìš´ ì½˜ì…‰íŠ¸ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.

ì´ë¥¼ ìœ„í•´ textual-inversionì€ ì œë„ˆë ˆì´í„° ëª¨ë¸ê³¼ í•™ìŠµìš© ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆ ë²„ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì œë„ˆë ˆì´í„°ëŠ” ë…¸ì´ì¦ˆê°€ ì ì€ ë²„ì „ì˜ ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•˜ë ¤ê³  ì‹œë„í•˜ë©° í† í° ì„ë² ë”© `v*`ì€ ì œë„ˆë ˆì´í„°ì˜ ì„±ëŠ¥ì— ë”°ë¼ ìµœì í™”ë©ë‹ˆë‹¤. í† í° ì„ë² ë”©ì´ ìƒˆë¡œìš´ ì½˜ì…‰íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ í¬ì°©í•˜ë©´ ë””í“¨ì „ ëª¨ë¸ì— ë” ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ë…¸ì´ì¦ˆê°€ ì ì€ ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìµœì í™” í”„ë¡œì„¸ìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ì— ìˆ˜ì²œ ë²ˆì— ë…¸ì¶œë¨ìœ¼ë¡œì¨ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.

