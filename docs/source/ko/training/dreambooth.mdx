<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# DreamBooth ë¯¸ì„¸ ì¡°ì • ì˜ˆì‹œ

[DreamBooth](https://arxiv.org/abs/2208.12242)ëŠ” í•œ ì£¼ì œì— ëŒ€í•œ ì ì€ ì´ë¯¸ì§€(3~5ê°œ)ë§Œìœ¼ë¡œë„ stable diffusionê³¼ ê°™ì´ text-to-image ëª¨ë¸ì„ ê°œì¸í™”í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

![í”„ë¡œì íŠ¸ ë¸”ë¡œê·¸ë¡œë¶€í„°ì˜ DreamBooth ì˜ˆì‹œ](https://dreambooth.github.io/DreamBooth_files/teaser_static.jpg)
_[í”„ë¡œì íŠ¸ ë¸”ë¡œê·¸](https://dreambooth.github.io)ë¡œë¶€í„°ì˜ DreamBooth ì˜ˆì‹œ._

[Dreambooth í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)ëŠ” ì‚¬ì „ í•™ìŠµëœ Stable Diffusion ëª¨ë¸ì—ì„œ í•™ìŠµ ìˆœì„œë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

<Tip warning={true}>

Dreambooth ë¯¸ì„¸ ì¡°ì •ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ë§¤ìš° ë¯¼ê°í•˜ê³  ê³¼ì í•©ë˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ê¶Œì¥ ì„¤ì •ì´ í¬í•¨ëœ [ì‹¬ì¸µ ë¶„ì„](https://huggingface.co/blog/dreambooth)ì„ ì‚´í´ë³´ê³  ê±°ê¸°ì„œì—ì„œ ì‹œì‘í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

</Tip>

## ë¡œì»¬ì—ì„œ í•™ìŠµí•˜ê¸°

### dependency ì„¤ì¹˜í•˜ê¸°

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì—, ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•™ìŠµ dependencyë“¤ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ `main` github ë¸Œëœì¹˜ì—ì„œ `diffusers`ë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.


```bash
pip install git+https://github.com/huggingface/diffusers
pip install -U -r diffusers/examples/dreambooth/requirements.txt
```

xFormersëŠ” í•™ìŠµ ìš”êµ¬ ì‚¬í•­ì˜ ì¼ë¶€ëŠ” ì•„ë‹ˆì§€ë§Œ [ê°€ëŠ¥í•˜ë©´ ì„¤ì¹˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤](../optimization/xformers). ì´ëŠ” í›ˆë ¨ ì†ë„ë¥¼ ë†’ì´ê³  ë©”ëª¨ë¦¬ ì§‘ì•½ë„ë¥¼ ë‚®ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ëª¨ë“  dependencyê°€ ì„¸íŒ…ë˜ì—ˆìœ¼ë©´, ë‹¤ìŒìœ¼ë¡œ [ğŸ¤— ê°€ì†](https://github.com/huggingface/accelerate/) í™˜ê²½ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
accelerate config
```

ì´ ì˜ˆì‹œì—ì„œëŠ” ëª¨ë¸ ë²„ì „ `v1-4`ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, [ì´ ë§í¬](https://huggingface.co/CompVis/stable-diffusion-v1-4)ë¥¼ ë°©ë¬¸í•˜ì—¬ ë¼ì´ì„ ìŠ¤ë¥¼ ì£¼ì˜ ê¹Šê²Œ ì½ì–´ë³¸ í›„ ì§„í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

ì•„ë˜ ëª…ë ¹ì€ ëª¨ë¸ì˜ í—ˆë¸Œ id `CompVis/stable-diffusion-v1-4`ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— í—ˆë¸Œì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤. ë¦¬í¬ì§€í† ë¦¬ë¥¼ ë¡œì»¬ë¡œ ë³µì œí•˜ê³  ì²´í¬ì•„ì›ƒì´ ì €ì¥ëœ ì‹œìŠ¤í…œì˜ ë¡œì»¬ ê²½ë¡œë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

### ê°„ë‹¨í•œ ê°œ ì˜ˆì‹œ

ì´ ì˜ˆì‹œì—ì„œëŠ” [ì´ ì´ë¯¸ì§€ë“¤](https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ)ë¥¼ ì‚¬ìš©í•˜ì—¬ Dreambooth í”„ë¡œì„¸ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Stable Diffusionì— ìƒˆë¡œìš´ ê°œë…ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ê·¸ê²ƒë“¤ì€ ìš°ë¦¬ì˜ í›ˆë ¨ ë°ì´í„°ê°€ ë  ê²ƒì…ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‹œìŠ¤í…œ ì–´ë”˜ê°€ì— ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.

ê·¸ëŸ° ë‹¤ìŒ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=400
```

### ì‚¬ì „ ë³´ì¡´ ì†ì‹¤ì„ ì‚¬ìš©í•œ í•™ìŠµ

ê³¼ì í•©ê³¼ language driftë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ì „ ë³´ì¡´ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš° ìì„¸í•œ ë‚´ìš©ì€ ë…¼ë¬¸ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤. ì‚¬ì „ ë³´ì¡´ì„ ìœ„í•´ ë™ì¼í•œ í´ë˜ìŠ¤ì˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ êµìœ¡ í”„ë¡œì„¸ìŠ¤ì˜ ì¼ë¶€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¢‹ì€ ì ì€ Stable Diffusion ëª¨ë¸ ìì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤! í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ìš°ë¦¬ê°€ ì§€ì •í•œ ë¡œì»¬ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.

ë…¼ë¬¸ì— ë”°ë¥´ë©´, ì‚¬ì „ ë³´ì¡´ì„ ìœ„í•´ `num_epochs * num_samples`ê°œì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. 200-300ê°œì—ì„œ ëŒ€ë¶€ë¶„ ì˜ ì‘ë™í•©ë‹ˆë‹¤.

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```

### í•™ìŠµ ì¤‘ ì²´í¬í¬ì¸íŠ¸ ì €ì¥í•˜ê¸°

Dreamboothë¡œ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ê³¼ì í•©í•˜ê¸° ì‰¬ìš°ë¯€ë¡œ, ë•Œë•Œë¡œ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— ì •ê¸°ì ì¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤. ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ì¤‘ í•˜ë‚˜ê°€ ìµœì¢… ëª¨ë¸ë³´ë‹¤ ë” ì˜ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
  --checkpointing_steps=500
```

ì´ë ‡ê²Œ í•˜ë©´ `output_dir`ì˜ í•˜ìœ„ í´ë”ì— ì „ì²´ í•™ìŠµ ìƒíƒœê°€ ì €ì¥ë©ë‹ˆë‹¤. í•˜ìœ„ í´ë” ì´ë¦„ì€ ì ‘ë‘ì‚¬ `checkpoint-`ë¡œ ì‹œì‘í•˜ê³  ì§€ê¸ˆê¹Œì§€ ìˆ˜í–‰ëœ step ìˆ˜ì…ë‹ˆë‹¤. ì˜ˆ: `checkpoint-1500`ì€ 1500 í•™ìŠµ step í›„ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì…ë‹ˆë‹¤.

#### ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í›ˆë ¨ ì¬ê°œí•˜ê¸°

ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í›ˆë ¨ì„ ì¬ê°œí•˜ë ¤ë©´, `--resume_from_checkpoint` ì¸ìˆ˜ë¥¼ ì „ë‹¬í•œ ë‹¤ìŒ ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸ì˜ ì´ë¦„ì„ ì§€ì •í•˜ë©´ ë©ë‹ˆë‹¤. íŠ¹ìˆ˜ ë¬¸ìì—´ `"latest"`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ëœ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸(ì¦‰, step ìˆ˜ê°€ ê°€ì¥ ë§ì€ ì²´í¬í¬ì¸íŠ¸)ì—ì„œ ì¬ê°œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒì€ 1500 step í›„ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œë¶€í„° í•™ìŠµì„ ì¬ê°œí•©ë‹ˆë‹¤:

```bash
  --resume_from_checkpoint="checkpoint-1500"
```

ì›í•˜ëŠ” ê²½ìš° ì¼ë¶€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ê¸°íšŒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ìˆ˜í–‰í•˜ê¸°

ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ëŠ” í›ˆë ¨ ì¬ê°œì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ë¿ë§Œ ì•„ë‹ˆë¼ ì˜µí‹°ë§ˆì´ì €, ë°ì´í„° ë¡œë” ë° í•™ìŠµë¥ ì˜ ìƒíƒœë„ í¬í•¨ë©ë‹ˆë‹¤.

ì¶”ë¡ ì„ ìœ„í•´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ë¨¼ì € ì´ë¥¼ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from accelerate import Accelerator
from diffusers import DiffusionPipeline

# í•™ìŠµì— ì‚¬ìš©ëœ ê²ƒê³¼ ë™ì¼í•œ ì¸ìˆ˜(ëª¨ë¸, ê°œì •)ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
model_id = "CompVis/stable-diffusion-v1-4"
pipeline = DiffusionPipeline.from_pretrained(model_id)

accelerator = Accelerator()

# ì´ˆê¸° í•™ìŠµì— `--train_text_encoder`ê°€ ì‚¬ìš©ëœ ê²½ìš° text_encoderë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
unet, text_encoder = accelerator.prepare(pipeline.unet, pipeline.text_encoder)

# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¡œë¶€í„° ìƒíƒœë¥¼ ë³µì›í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì ˆëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
accelerator.load_state("/sddata/dreambooth/daruma-v2-1/checkpoint-100")

# unwrapped ëª¨ë¸ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë‹¤ì‹œ ë¹Œë“œí•©ë‹ˆë‹¤.(.unet and .text_encoderë¡œì˜ í• ë‹¹ë„ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤)
pipeline = DiffusionPipeline.from_pretrained(
    model_id,
    unet=accelerator.unwrap_model(unet),
    text_encoder=accelerator.unwrap_model(text_encoder),
)

# ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê±°ë‚˜ ì €ì¥í•˜ê±°ë‚˜, í—ˆë¸Œì— í‘¸ì‹œí•©ë‹ˆë‹¤.
pipeline.save_pretrained("dreambooth-pipeline")
```

### 16GB GPUì—ì„œ í›ˆë ¨í•˜ê¸°

Gradient checkpointingê³¼ [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)ì˜ 8ë¹„íŠ¸ ì˜µí‹°ë§ˆì´ì €ì˜ ë„ì›€ìœ¼ë¡œ, 16GB GPUì—ì„œ dreamboothë¥¼ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
pip install bitsandbytes
```

ê·¸ ë‹¤ìŒ, í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— `--use_8bit_adam` ì˜µì…˜ì„ ëª…ì‹œí•©ë‹ˆë‹¤.

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=2 --gradient_checkpointing \
  --use_8bit_adam \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```

### UNetë¿ë§Œ ì•„ë‹ˆë¼ í…ìŠ¤íŠ¸ ì¸ì½”ë” ë¯¸ì„¸ ì¡°ì •

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë˜í•œ `unet`ê³¼ í•¨ê»˜ `text_encoder`ë¥¼ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ íŠ¹íˆ ì–¼êµ´ì—ì„œ í›¨ì”¬ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì œê³µí•œë‹¤ëŠ” ê²ƒì´ ì‹¤í—˜ì ìœ¼ë¡œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ë¸”ë¡œê·¸](https://huggingface.co/blog/dreambooth)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

ì´ ì˜µì…˜ì„ í™œì„±í™”í•˜ë ¤ë©´, í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— `--train_text_encoder` ì¸ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.

<Tip>
í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ í•™ìŠµí•˜ë ¤ë©´ ì¶”ê°€ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ë¯€ë¡œ, í•™ìŠµì— 16GB GPUì— ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì˜µì…˜ì„ ì‚¬ìš©í•˜ë ¤ë©´ ìµœì†Œ 24GB VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.
</Tip>

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --train_text_encoder \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --use_8bit_adam
  --gradient_checkpointing \
  --learning_rate=2e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```

### 8GB GPUì—ì„œ í•™ìŠµí•˜ê¸°

[DeepSpeed](https://www.deepspeed.ai/)ë¥¼ ì‚¬ìš©í•˜ë©´ ì¼ë¶€ í…ì„œë¥¼ VRAMì—ì„œ CPU ë˜ëŠ” NVMEë¡œ ì˜¤í”„ë¡œë“œí•˜ì—¬ ë” ì ì€ GPU ë©”ëª¨ë¦¬ë¡œ í•™ìŠµí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

DeepSpeedëŠ” `accelerate config`ë¡œ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµ¬ì„±í•˜ëŠ” ë™ì•ˆ, "DeepSpeedë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"ì— ì˜ˆë¼ê³  ëŒ€ë‹µí•˜ì„¸ìš”. DeepSpeed 2ë‹¨ê³„, fp16 í˜¼í•© ì •ë°€ë„ë¥¼ ê²°í•©í•˜ê³  ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ëª¨ë‘ CPUë¡œ ì˜¤í”„ë¡œë“œí•˜ë©´ 8GB VRAM ë¯¸ë§Œì—ì„œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨ì ì€ ë” ë§ì€ ì‹œìŠ¤í…œ RAM(ì•½ 25GB)ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¶”ê°€ êµ¬ì„± ì˜µì…˜ì€ [DeepSpeed ë¬¸ì„œ](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

ê¸°ë³¸ Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ DeepSpeedì˜ íŠ¹ìˆ˜ ë²„ì „ì¸ Adam `deepspeed.ops.adam.DeepSpeedCPUAdam`ìœ¼ë¡œ ë³€ê²½í•˜ë©´ ì†ë„ê°€ ìƒë‹¹íˆ í–¥ìƒë˜ì§€ë§Œ, í™œì„±í™”í•˜ë ¤ë©´ ì‹œìŠ¤í…œì˜ CUDA ë„êµ¬ ì²´ì¸ ë²„ì „ì´ PyTorchë¡œ ì„¤ì¹˜ëœ ê²ƒê³¼ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤. 8ë¹„íŠ¸ ì˜µí‹°ë§ˆì´ì €ëŠ” í˜„ì¬ DeepSpeedì™€ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --sample_batch_size=1 \
  --gradient_accumulation_steps=1 --gradient_checkpointing \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800 \
  --mixed_precision=fp16
```

## ì¶”ë¡ 

ëª¨ë¸ì„ í•™ìŠµí•œ í›„ì—ëŠ”, ëª¨ë¸ì´ ì €ì¥ëœ ê²½ë¡œë¥¼ í‘œì‹œí•˜ê¸°ë§Œ í•˜ë©´ `StableDiffusionPipeline`ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ì— í•™ìŠµì— ì‚¬ìš©ëœ íŠ¹ìˆ˜ `ì‹ë³„ì`(ì´ì „ ì˜ˆì‹œì˜ `sks`)ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

```python
from diffusers import StableDiffusionPipeline
import torch

model_id = "path_to_saved_model"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

prompt = "A photo of sks dog in a bucket"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("dog-bucket.png")
```

[ì €ì¥ëœ í•™ìŠµ ì²´í¬í¬ì¸íŠ¸](#performing-inference-using-a-saved-checkpoint)ì—ì„œë„ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.