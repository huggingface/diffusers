<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# DreamBooth

[DreamBooth](https://arxiv.org/abs/2208.12242)ëŠ” í•œ ì£¼ì œì— ëŒ€í•œ ì ì€ ì´ë¯¸ì§€(3~5ê°œ)ë§Œìœ¼ë¡œë„ stable diffusionê³¼ ê°™ì´ text-to-image ëª¨ë¸ì„ ê°œì¸í™”í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì¥ë©´, í¬ì¦ˆ ë° ì¥ë©´(ë·°)ì—ì„œ í”¼ì‚¬ì²´ì— ëŒ€í•´ ë§¥ë½í™”(contextualized)ëœ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![í”„ë¡œì íŠ¸ ë¸”ë¡œê·¸ì—ì„œì˜ DreamBooth ì˜ˆì‹œ](https://dreambooth.github.io/DreamBooth_files/teaser_static.jpg)
<small>ì—ì„œì˜ Dreambooth ì˜ˆì‹œ <a href="https://dreambooth.github.io">project's blog.</a></small>


ì´ ê°€ì´ë“œëŠ” ë‹¤ì–‘í•œ GPU, Flax ì‚¬ì–‘ì— ëŒ€í•´ [`CompVis/stable-diffusion-v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4) ëª¨ë¸ë¡œ DreamBoothë¥¼ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë” ê¹Šì´ íŒŒê³ ë“¤ì–´ ì‘ë™ ë°©ì‹ì„ í™•ì¸í•˜ëŠ” ë° ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš°, ì´ ê°€ì´ë“œì— ì‚¬ìš©ëœ DreamBoothì˜ ëª¨ë“  í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ [ì—¬ê¸°](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•™ìŠµì— í•„ìš”í•œ dependenciesë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ `main` GitHub ë¸Œëœì¹˜ì—ì„œ ğŸ§¨ Diffusersë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

```bash
pip install git+https://github.com/huggingface/diffusers
pip install -U -r diffusers/examples/dreambooth/requirements.txt
```

xFormersëŠ” í•™ìŠµì— í•„ìš”í•œ ìš”êµ¬ ì‚¬í•­ì€ ì•„ë‹ˆì§€ë§Œ, ê°€ëŠ¥í•˜ë©´ [ì„¤ì¹˜](../optimization/xformers)í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ê³  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ëª¨ë“  dependenciesì„ ì„¤ì •í•œ í›„ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì—¬ [ğŸ¤— Accelerate](https://github.com/huggingface/accelerate/) í™˜ê²½ì„ ë‹¤ìŒê³¼ ê°™ì´ ì´ˆê¸°í™”í•©ë‹ˆë‹¤:

```bash
accelerate config
```

ë³„ë„ ì„¤ì • ì—†ì´ ê¸°ë³¸ ğŸ¤— Accelerate í™˜ê²½ì„ ì„¤ì¹˜í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•©ë‹ˆë‹¤:

```bash
accelerate config default
```

ë˜ëŠ” í˜„ì¬ í™˜ê²½ì´ ë…¸íŠ¸ë¶ê³¼ ê°™ì€ ëŒ€í™”í˜• ì…¸ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš° ë‹¤ìŒì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

## íŒŒì¸íŠœë‹

<Tip warning={true}>

DreamBooth íŒŒì¸íŠœë‹ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ë§¤ìš° ë¯¼ê°í•˜ê³  ê³¼ì í•©ë˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ì ì ˆí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ ë‹¤ì–‘í•œ ê¶Œì¥ ì„¤ì •ì´ í¬í•¨ëœ [ì‹¬ì¸µ ë¶„ì„](https://huggingface.co/blog/dreambooth)ì„ ì‚´í´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

</Tip>

<frameworkcontent>
<pt>
[ëª‡ ì¥ì˜ ê°•ì•„ì§€ ì´ë¯¸ì§€ë“¤](https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ)ë¡œ DreamBoothë¥¼ ì‹œë„í•´ë´…ì‹œë‹¤. 
ì´ë¥¼ ë‹¤ìš´ë¡œë“œí•´ ë””ë ‰í„°ë¦¬ì— ì €ì¥í•œ ë‹¤ìŒ `INSTANCE_DIR` í™˜ê²½ ë³€ìˆ˜ë¥¼ í•´ë‹¹ ê²½ë¡œë¡œ ì„¤ì •í•©ë‹ˆë‹¤:


```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export OUTPUT_DIR="path_to_saved_model"
```

ê·¸ëŸ° ë‹¤ìŒ, ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì „ì²´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” [ì—¬ê¸°](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤):

```bash
accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=400
```
</pt>
<jax>

TPUì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆê±°ë‚˜ ë” ë¹ ë¥´ê²Œ í›ˆë ¨í•˜ê³  ì‹¶ë‹¤ë©´ [Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_flax.py)ë¥¼ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Flax í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” gradient checkpointing ë˜ëŠ” gradient accumulationì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë©”ëª¨ë¦¬ê°€ 30GB ì´ìƒì¸ GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ìš”êµ¬ ì‚¬í•­ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.

```bash
pip install -U -r requirements.txt
```

ê·¸ëŸ¬ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="path-to-instance-images"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --learning_rate=5e-6 \
  --max_train_steps=400
```
</jax>
</frameworkcontent>

### Prior-preserving(ì‚¬ì „ ë³´ì¡´) lossë¥¼ ì‚¬ìš©í•œ íŒŒì¸íŠœë‹

ê³¼ì í•©ê³¼ language driftë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ì „ ë³´ì¡´ì´ ì‚¬ìš©ë©ë‹ˆë‹¤(ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš° [ë…¼ë¬¸](https://arxiv.org/abs/2208.12242)ì„ ì°¸ì¡°í•˜ì„¸ìš”).  ì‚¬ì „ ë³´ì¡´ì„ ìœ„í•´ ë™ì¼í•œ í´ë˜ìŠ¤ì˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ì˜ ì¼ë¶€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¢‹ì€ ì ì€ Stable Diffusion ëª¨ë¸ ìì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤! í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ìš°ë¦¬ê°€ ì§€ì •í•œ ë¡œì»¬ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.

ì €ìë“¤ì— ë”°ë¥´ë©´ ì‚¬ì „ ë³´ì¡´ì„ ìœ„í•´ `num_epochs * num_samples`ê°œì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. 200-300ê°œì—ì„œ ëŒ€ë¶€ë¶„ ì˜ ì‘ë™í•©ë‹ˆë‹¤.

<frameworkcontent>
<pt>
```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```
</pt>
<jax>
```bash
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="path-to-instance-images"
export CLASS_DIR="path-to-class-images"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --learning_rate=5e-6 \
  --num_class_images=200 \
  --max_train_steps=800
```
</jax>
</frameworkcontent>

## í…ìŠ¤íŠ¸ ì¸ì½”ë”ì™€ and UNetë¡œ íŒŒì¸íŠœë‹í•˜ê¸°

í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ `unet`ê³¼ í•¨ê»˜ `text_encoder`ë¥¼ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì—ì„œ(ìì„¸í•œ ë‚´ìš©ì€ [ğŸ§¨ Diffusersë¥¼ ì‚¬ìš©í•´ DreamBoothë¡œ Stable Diffusion í•™ìŠµí•˜ê¸°](https://huggingface.co/blog/dreambooth) ê²Œì‹œë¬¼ì„ í™•ì¸í•˜ì„¸ìš”), íŠ¹íˆ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ í›¨ì”¬ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<Tip warning={true}>

í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ í•™ìŠµì‹œí‚¤ë ¤ë©´ ì¶”ê°€ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•´ 16GB GPUë¡œëŠ” ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì˜µì…˜ì„ ì‚¬ìš©í•˜ë ¤ë©´ ìµœì†Œ 24GB VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.

</Tip>

`--train_text_encoder` ì¸ìˆ˜ë¥¼ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ì „ë‹¬í•˜ì—¬ `text_encoder` ë° `unet`ì„ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

<frameworkcontent>
<pt>
```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --train_text_encoder \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --use_8bit_adam
  --gradient_checkpointing \
  --learning_rate=2e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```
</pt>
<jax>
```bash
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="path-to-instance-images"
export CLASS_DIR="path-to-class-images"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --train_text_encoder \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --learning_rate=2e-6 \
  --num_class_images=200 \
  --max_train_steps=800
```
</jax>
</frameworkcontent>

## LoRAë¡œ íŒŒì¸íŠœë‹í•˜ê¸°

DreamBoothì—ì„œ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ í•™ìŠµì„ ê°€ì†í™”í•˜ê¸° ìœ„í•œ íŒŒì¸íŠœë‹ ê¸°ìˆ ì¸ LoRA(Low-Rank Adaptation of Large Language Models)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LoRA í•™ìŠµ](training/lora#dreambooth) ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### í•™ìŠµ ì¤‘ ì²´í¬í¬ì¸íŠ¸ ì €ì¥í•˜ê¸°

Dreamboothë¡œ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ê³¼ì í•©í•˜ê¸° ì‰¬ìš°ë¯€ë¡œ, ë•Œë•Œë¡œ í•™ìŠµ ì¤‘ì— ì •ê¸°ì ì¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤. ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ì¤‘ í•˜ë‚˜ê°€ ìµœì¢… ëª¨ë¸ë³´ë‹¤ ë” ì˜ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ë ¤ë©´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
  --checkpointing_steps=500
```

ì´ë ‡ê²Œ í•˜ë©´ `output_dir`ì˜ í•˜ìœ„ í´ë”ì— ì „ì²´ í•™ìŠµ ìƒíƒœê°€ ì €ì¥ë©ë‹ˆë‹¤. í•˜ìœ„ í´ë” ì´ë¦„ì€ ì ‘ë‘ì‚¬ `checkpoint-`ë¡œ ì‹œì‘í•˜ê³  ì§€ê¸ˆê¹Œì§€ ìˆ˜í–‰ëœ step ìˆ˜ì…ë‹ˆë‹¤. ì˜ˆì‹œë¡œ `checkpoint-1500`ì€ 1500 í•™ìŠµ step í›„ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì…ë‹ˆë‹¤.

#### ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í›ˆë ¨ ì¬ê°œí•˜ê¸°

ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í›ˆë ¨ì„ ì¬ê°œí•˜ë ¤ë©´, `--resume_from_checkpoint` ì¸ìˆ˜ë¥¼ ì „ë‹¬í•œ ë‹¤ìŒ ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸ì˜ ì´ë¦„ì„ ì§€ì •í•˜ë©´ ë©ë‹ˆë‹¤. íŠ¹ìˆ˜ ë¬¸ìì—´ `"latest"`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ëœ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸(ì¦‰, step ìˆ˜ê°€ ê°€ì¥ ë§ì€ ì²´í¬í¬ì¸íŠ¸)ì—ì„œ ì¬ê°œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒì€ 1500 step í›„ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œë¶€í„° í•™ìŠµì„ ì¬ê°œí•©ë‹ˆë‹¤:

```bash
  --resume_from_checkpoint="checkpoint-1500"
```

ì›í•˜ëŠ” ê²½ìš° ì¼ë¶€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ìˆ˜í–‰í•˜ê¸°

ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ëŠ” í›ˆë ¨ ì¬ê°œì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ë¿ë§Œ ì•„ë‹ˆë¼ ì˜µí‹°ë§ˆì´ì €, ë°ì´í„° ë¡œë” ë° í•™ìŠµë¥ ì˜ ìƒíƒœë„ í¬í•¨ë©ë‹ˆë‹¤.

**`"accelerate>=0.16.0"`**ì´ ì„¤ì¹˜ëœ ê²½ìš° ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

```python
from diffusers import DiffusionPipeline, UNet2DConditionModel
from transformers import CLIPTextModel
import torch

# í•™ìŠµì— ì‚¬ìš©ëœ ê²ƒê³¼ ë™ì¼í•œ ì¸ìˆ˜(model, revision)ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
model_id = "CompVis/stable-diffusion-v1-4"

unet = UNet2DConditionModel.from_pretrained("/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet")

# `args.train_text_encoder`ë¡œ í•™ìŠµí•œ ê²½ìš°ë©´ í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ ê¼­ ë¶ˆëŸ¬ì˜¤ì„¸ìš”
text_encoder = CLIPTextModel.from_pretrained("/sddata/dreambooth/daruma-v2-1/checkpoint-100/text_encoder")

pipeline = DiffusionPipeline.from_pretrained(model_id, unet=unet, text_encoder=text_encoder, dtype=torch.float16)
pipeline.to("cuda")

# ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê±°ë‚˜ ì €ì¥í•˜ê±°ë‚˜, í—ˆë¸Œì— í‘¸ì‹œí•©ë‹ˆë‹¤.
pipeline.save_pretrained("dreambooth-pipeline")
```

If you have **`"accelerate<0.16.0"`** installed, you need to convert it to an inference pipeline first:

```python
from accelerate import Accelerator
from diffusers import DiffusionPipeline

# í•™ìŠµì— ì‚¬ìš©ëœ ê²ƒê³¼ ë™ì¼í•œ ì¸ìˆ˜(model, revision)ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
model_id = "CompVis/stable-diffusion-v1-4"
pipeline = DiffusionPipeline.from_pretrained(model_id)

accelerator = Accelerator()

# ì´ˆê¸° í•™ìŠµì— `--train_text_encoder`ê°€ ì‚¬ìš©ëœ ê²½ìš° text_encoderë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
unet, text_encoder = accelerator.prepare(pipeline.unet, pipeline.text_encoder)

# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¡œë¶€í„° ìƒíƒœë¥¼ ë³µì›í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì ˆëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
accelerator.load_state("/sddata/dreambooth/daruma-v2-1/checkpoint-100")

# unwrapped ëª¨ë¸ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë‹¤ì‹œ ë¹Œë“œí•©ë‹ˆë‹¤.(.unet and .text_encoderë¡œì˜ í• ë‹¹ë„ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤)
pipeline = DiffusionPipeline.from_pretrained(
    model_id,
    unet=accelerator.unwrap_model(unet),
    text_encoder=accelerator.unwrap_model(text_encoder),
)

# ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê±°ë‚˜ ì €ì¥í•˜ê±°ë‚˜, í—ˆë¸Œì— í‘¸ì‹œí•©ë‹ˆë‹¤.
pipeline.save_pretrained("dreambooth-pipeline")
```

## ê° GPU ìš©ëŸ‰ì—ì„œì˜ ìµœì í™”

í•˜ë“œì›¨ì–´ì— ë”°ë¼ 16GBì—ì„œ 8GBê¹Œì§€ GPUì—ì„œ DreamBoothë¥¼ ìµœì í™”í•˜ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤!

### xFormers

[xFormers](https://github.com/facebookresearch/xformers)ëŠ” Transformersë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•œ toolboxì´ë©°, ğŸ§¨ Diffusersì—ì„œ ì‚¬ìš©ë˜ëŠ”[memory-efficient attention](https://facebookresearch.github.io/xformers/components/ops.html#module-xformers.ops)  ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. [xFormersë¥¼ ì„¤ì¹˜](./optimization/xformers)í•œ ë‹¤ìŒ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:

```bash
  --enable_xformers_memory_efficient_attention
```

xFormersëŠ” Flaxì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

### ê·¸ë˜ë””ì–¸íŠ¸ ì—†ìŒìœ¼ë¡œ ì„¤ì •

ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ [ê¸°ìš¸ê¸° ì„¤ì •](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html)ì„ 0 ëŒ€ì‹  `None`ìœ¼ë¡œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¡œ ì¸í•´ íŠ¹ì • ë™ì‘ì´ ë³€ê²½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì´ ì¸ìˆ˜ë¥¼ ì œê±°í•´ ë³´ì‹­ì‹œì˜¤. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¸ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ `None`ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

```bash
  --set_grads_to_none
```

### 16GB GPU

Gradient checkpointingê³¼ [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)ì˜ 8ë¹„íŠ¸ ì˜µí‹°ë§ˆì´ì €ì˜ ë„ì›€ìœ¼ë¡œ, 16GB GPUì—ì„œ dreamboothë¥¼ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. bitsandbytesê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

```bash
pip install bitsandbytes
```

ê·¸ ë‹¤ìŒ, í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— `--use_8bit_adam` ì˜µì…˜ì„ ëª…ì‹œí•©ë‹ˆë‹¤:

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=2 --gradient_checkpointing \
  --use_8bit_adam \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```

### 12GB GPU

12GB GPUì—ì„œ DreamBoothë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ gradient checkpointing, 8ë¹„íŠ¸ ì˜µí‹°ë§ˆì´ì €, xFormersë¥¼ í™œì„±í™”í•˜ê³  ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ `None`ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path-to-instance-images"
export CLASS_DIR="path-to-class-images"
export OUTPUT_DIR="path-to-save-model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 --gradient_checkpointing \
  --use_8bit_adam \
  --enable_xformers_memory_efficient_attention \
  --set_grads_to_none \
  --learning_rate=2e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800
```

### 8GB GPUì—ì„œ í•™ìŠµí•˜ê¸°

8GB GPUì— ëŒ€í•´ì„œëŠ” [DeepSpeed](https://www.deepspeed.ai/)ë¥¼ ì‚¬ìš©í•´ ì¼ë¶€ í…ì„œë¥¼ VRAMì—ì„œ CPU ë˜ëŠ” NVMEë¡œ ì˜¤í”„ë¡œë“œí•˜ì—¬ ë” ì ì€ GPU ë©”ëª¨ë¦¬ë¡œ í•™ìŠµí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

ğŸ¤— Accelerate í™˜ê²½ì„ êµ¬ì„±í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:

```bash
accelerate config
```

í™˜ê²½ êµ¬ì„± ì¤‘ì— DeepSpeedë¥¼ ì‚¬ìš©í•  ê²ƒì„ í™•ì¸í•˜ì„¸ìš”.
ê·¸ëŸ¬ë©´ DeepSpeed stage 2, fp16 í˜¼í•© ì •ë°€ë„ë¥¼ ê²°í•©í•˜ê³  ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ëª¨ë‘ CPUë¡œ ì˜¤í”„ë¡œë“œí•˜ë©´ 8GB VRAM ë¯¸ë§Œì—ì„œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
ë‹¨ì ì€ ë” ë§ì€ ì‹œìŠ¤í…œ RAM(ì•½ 25GB)ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¶”ê°€ êµ¬ì„± ì˜µì…˜ì€ [DeepSpeed ë¬¸ì„œ](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

ë˜í•œ ê¸°ë³¸ Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ DeepSpeedì˜ ìµœì í™”ëœ Adam ë²„ì „ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
ì´ëŠ” ìƒë‹¹í•œ ì†ë„ í–¥ìƒì„ ìœ„í•œ Adamì¸ [`deepspeed.ops.adam.DeepSpeedCPUAdam`](https://deepspeed.readthedocs.io/en/latest/optimizers.html#adam-cpu)ì…ë‹ˆë‹¤. 
`DeepSpeedCPUAdam`ì„ í™œì„±í™”í•˜ë ¤ë©´ ì‹œìŠ¤í…œì˜ CUDA toolchain ë²„ì „ì´ PyTorchì™€ í•¨ê»˜ ì„¤ì¹˜ëœ ê²ƒê³¼ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.

8ë¹„íŠ¸ ì˜µí‹°ë§ˆì´ì €ëŠ” í˜„ì¬ DeepSpeedì™€ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤:

```bash
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="path_to_training_images"
export CLASS_DIR="path_to_class_images"
export OUTPUT_DIR="path_to_saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --instance_data_dir=$INSTANCE_DIR \
  --class_data_dir=$CLASS_DIR \
  --output_dir=$OUTPUT_DIR \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="a photo of sks dog" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --sample_batch_size=1 \
  --gradient_accumulation_steps=1 --gradient_checkpointing \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=200 \
  --max_train_steps=800 \
  --mixed_precision=fp16
```

## ì¶”ë¡ 

ëª¨ë¸ì„ í•™ìŠµí•œ í›„ì—ëŠ”, ëª¨ë¸ì´ ì €ì¥ëœ ê²½ë¡œë¥¼ ì§€ì •í•´ [`StableDiffusionPipeline`]ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ì— í•™ìŠµì— ì‚¬ìš©ëœ íŠ¹ìˆ˜ `ì‹ë³„ì`(ì´ì „ ì˜ˆì‹œì˜ `sks`)ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

**`"accelerate>=0.16.0"`**ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ” ê²½ìš° ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from diffusers import StableDiffusionPipeline
import torch

model_id = "path_to_saved_model"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

prompt = "A photo of sks dog in a bucket"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("dog-bucket.png")
```

[ì €ì¥ëœ í•™ìŠµ ì²´í¬í¬ì¸íŠ¸](#inference-from-a-saved-checkpoint)ì—ì„œë„ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
