<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Shap-E

[[open-in-colab]]

Shap-EëŠ” ë¹„ë””ì˜¤ ê²Œì„ ê°œë°œ, ì¸í…Œë¦¬ì–´ ë””ìì¸, ê±´ì¶•ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” 3D ì—ì…‹ì„ ìƒì„±í•˜ê¸° ìœ„í•œ conditional ëª¨ë¸ì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ 3D ì—ì…‹ ë°ì´í„°ì…‹ì„ í•™ìŠµë˜ì—ˆê³ , ê° ì˜¤ë¸Œì íŠ¸ì˜ ë” ë§ì€ ë·°ë¥¼ ë Œë”ë§í•˜ê³  4K point cloud ëŒ€ì‹  16Kë¥¼ ìƒì„±í•˜ë„ë¡ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤. Shap-E ëª¨ë¸ì€ ë‘ ë‹¨ê³„ë¡œ í•™ìŠµë©ë‹ˆë‹¤:

1. ì¸ì½”ë”ê°€ 3D ì—ì…‹ì˜ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì™€ ë Œë”ë§ëœ ë·°ë¥¼ ë°›ì•„ë“¤ì´ê³  ì—ì…‹ì„ ë‚˜íƒ€ë‚´ëŠ” implicit functionsì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
2. ì¸ì½”ë”ê°€ ìƒì„±í•œ latentsë¥¼ ë°”íƒ•ìœ¼ë¡œ diffusion ëª¨ë¸ì„ í›ˆë ¨í•˜ì—¬ neural radiance fields(NeRF) ë˜ëŠ” textured 3D ë©”ì‹œë¥¼ ìƒì„±í•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ 3D ì—ì…‹ì„ ë” ì‰½ê²Œ ë Œë”ë§í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” Shap-Eë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚˜ë§Œì˜ 3D ì—ì…‹ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë³´ì…ë‹ˆë‹¤!

ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

```py
# Colabì—ì„œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê¸° ìœ„í•´ ì£¼ì„ì„ ì œì™¸í•˜ì„¸ìš”
#!pip install -q diffusers transformers accelerate trimesh
```

## Text-to-3D

3D ê°ì²´ì˜ gifë¥¼ ìƒì„±í•˜ë ¤ë©´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ [`ShapEPipeline`]ì— ì „ë‹¬í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ 3D ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```py
import torch
from diffusers import ShapEPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16, variant="fp16")
pipe = pipe.to(device)

guidance_scale = 15.0
prompt = ["A firecracker", "A birthday cupcake"]

images = pipe(
    prompt,
    guidance_scale=guidance_scale,
    num_inference_steps=64,
    frame_size=256,
).images
```

ì´ì œ [`~utils.export_to_gif`] í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ë¥¼ 3D ê°ì²´ì˜ gifë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```py
from diffusers.utils import export_to_gif

export_to_gif(images[0], "firecracker_3d.gif")
export_to_gif(images[1], "cake_3d.gif")
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/firecracker_out.gif"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">prompt = "A firecracker"</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/cake_out.gif"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">prompt = "A birthday cupcake"</figcaption>
  </div>
</div>

## Image-to-3D

ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œë¶€í„° 3D ê°œì²´ë¥¼ ìƒì„±í•˜ë ¤ë©´ [`ShapEImg2ImgPipeline`]ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì™„ì „íˆ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [Kandinsky 2.1](../api/pipelines/kandinsky) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```py
from diffusers import DiffusionPipeline
import torch

prior_pipeline = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16, use_safetensors=True).to("cuda")

prompt = "A cheeseburger, white background"

image_embeds, negative_image_embeds = prior_pipeline(prompt, guidance_scale=1.0).to_tuple()
image = pipeline(
    prompt,
    image_embeds=image_embeds,
    negative_image_embeds=negative_image_embeds,
).images[0]

image.save("burger.png")
```

ì¹˜ì¦ˆë²„ê±°ë¥¼ [`ShapEImg2ImgPipeline`]ì— ì „ë‹¬í•˜ì—¬ 3D representationì„ ìƒì„±í•©ë‹ˆë‹¤.

```py
from PIL import Image
from diffusers import ShapEImg2ImgPipeline
from diffusers.utils import export_to_gif

pipe = ShapEImg2ImgPipeline.from_pretrained("openai/shap-e-img2img", torch_dtype=torch.float16, variant="fp16").to("cuda")

guidance_scale = 3.0
image = Image.open("burger.png").resize((256, 256))

images = pipe(
    image,
    guidance_scale=guidance_scale,
    num_inference_steps=64,
    frame_size=256,
).images

gif_path = export_to_gif(images[0], "burger_3d.gif")
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/burger_in.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">cheeseburger</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/shap_e/burger_out.gif"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">3D cheeseburger</figcaption>
  </div>
</div>

## ë©”ì‹œ ìƒì„±í•˜ê¸°

Shap-EëŠ” ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë Œë”ë§í•  textured ë©”ì‹œ ì¶œë ¥ì„ ìƒì„±í•  ìˆ˜ë„ ìˆëŠ” ìœ ì—°í•œ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ [Dataset viewer](https://huggingface.co/docs/hub/datasets-viewer#dataset-preview)ë¥¼ ì‚¬ìš©í•´ ë©”ì‹œ ì‹œê°í™”ë¥¼ ì§€ì›í•˜ëŠ” `glb` íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

`output_type` ë§¤ê°œë³€ìˆ˜ë¥¼ `"mesh"`ë¡œ ì§€ì •í•¨ìœ¼ë¡œì¨ [`ShapEPipeline`]ê³¼ [`ShapEImg2ImgPipeline`] ëª¨ë‘ì— ëŒ€í•œ ë©”ì‹œ ì¶œë ¥ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
import torch
from diffusers import ShapEPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16, variant="fp16")
pipe = pipe.to(device)

guidance_scale = 15.0
prompt = "A birthday cupcake"

images = pipe(prompt, guidance_scale=guidance_scale, num_inference_steps=64, frame_size=256, output_type="mesh").images
```

ë©”ì‹œ ì¶œë ¥ì„ `ply` íŒŒì¼ë¡œ ì €ì¥í•˜ë ¤ë©´ [`~utils.export_to_ply`] í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

<Tip>

ì„ íƒì ìœ¼ë¡œ [`~utils.export_to_obj`] í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œ ì¶œë ¥ì„ `obj` íŒŒì¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë©”ì‹œ ì¶œë ¥ì„ ì €ì¥í•  ìˆ˜ ìˆì–´ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ì—ì„œ ë”ìš± ìœ ì—°í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

</Tip>

```py
from diffusers.utils import export_to_ply

ply_path = export_to_ply(images[0], "3d_cake.ply")
print(f"Saved to folder: {ply_path}")
```

ê·¸ ë‹¤ìŒ trimesh ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ `ply` íŒŒì¼ì„ `glb` íŒŒì¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
import trimesh

mesh = trimesh.load("3d_cake.ply")
mesh_export = mesh.export("3d_cake.glb", file_type="glb")
```

ê¸°ë³¸ì ìœ¼ë¡œ ë©”ì‹œ ì¶œë ¥ì€ ì•„ë˜ìª½ ì‹œì ì— ì´ˆì ì´ ë§ì¶°ì ¸ ìˆì§€ë§Œ íšŒì „ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ê¸°ë³¸ ì‹œì ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
import trimesh
import numpy as np

mesh = trimesh.load("3d_cake.ply")
rot = trimesh.transformations.rotation_matrix(-np.pi / 2, [1, 0, 0])
mesh = mesh.apply_transform(rot)
mesh_export = mesh.export("3d_cake.glb", file_type="glb")
```

ë©”ì‹œ íŒŒì¼ì„ ë°ì´í„°ì…‹ ë ˆí¬ì§€í† ë¦¬ì— ì—…ë¡œë“œí•´ Dataset viewerë¡œ ì‹œê°í™”í•˜ì„¸ìš”!

<div class="flex justify-center">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/3D-cake.gif"/>
</div>
