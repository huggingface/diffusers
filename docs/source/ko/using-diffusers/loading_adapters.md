<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# ì–´ëŒ‘í„° ë¶ˆëŸ¬ì˜¤ê¸°

[[open-in-colab]]

íŠ¹ì • ë¬¼ì²´ì˜ ì´ë¯¸ì§€ ë˜ëŠ” íŠ¹ì • ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ diffusion ëª¨ë¸ì„ ê°œì¸í™”í•˜ê¸° ìœ„í•œ ëª‡ ê°€ì§€ [í•™ìŠµ](../training/overview) ê¸°ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•™ìŠµ ë°©ë²•ì€ ê°ê° ë‹¤ë¥¸ ìœ í˜•ì˜ ì–´ëŒ‘í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì¼ë¶€ ì–´ëŒ‘í„°ëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ë°˜ë©´, ë‹¤ë¥¸ ì–´ëŒ‘í„°ëŠ” ì„ë² ë”© ë˜ëŠ” ê°€ì¤‘ì¹˜ì˜ ì‘ì€ ë¶€ë¶„ë§Œ ìˆ˜ì •í•©ë‹ˆë‹¤. ì´ëŠ” ê° ì–´ëŒ‘í„°ì˜ ë¡œë”© í”„ë¡œì„¸ìŠ¤ë„ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” DreamBooth, textual inversion ë° LoRA ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

<Tip>

ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸ì™€ ì„ë² ë”©ì€ [Stable Diffusion Conceptualizer](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer), [LoRA the Explorer](https://huggingface.co/spaces/multimodalart/LoraTheExplorer), [Diffusers Models Gallery](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery)ì—ì„œ ì°¾ì•„ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

</Tip>

## DreamBooth

[DreamBooth](https://dreambooth.github.io/)ëŠ” ë¬¼ì²´ì˜ ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•œ *diffusion ëª¨ë¸ ì „ì²´*ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ê³¼ ì„¤ì •ìœ¼ë¡œ í•´ë‹¹ ë¬¼ì²´ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ëª¨ë¸ì´ ë¬¼ì²´ ì´ë¯¸ì§€ì™€ ì—°ê´€ì‹œí‚¤ëŠ” ë°©ë²•ì„ í•™ìŠµí•˜ëŠ” í”„ë¡¬í”„íŠ¸ì— íŠ¹ìˆ˜ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ëª¨ë“  í•™ìŠµ ë°©ë²• ì¤‘ì—ì„œ ë“œë¦¼ë¶€ìŠ¤ëŠ” ì „ì²´ ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— íŒŒì¼ í¬ê¸°ê°€ ê°€ì¥ í½ë‹ˆë‹¤(ë³´í†µ ëª‡ GB).

HergÃ©ê°€ ê·¸ë¦° ë‹¨ 10ê°œì˜ ì´ë¯¸ì§€ë¡œ í•™ìŠµëœ [herge_style](https://huggingface.co/sd-dreambooth-library/herge-style) ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì™€ í•´ë‹¹ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì´ ì‘ë™í•˜ë ¤ë©´ ì²´í¬í¬ì¸íŠ¸ë¥¼ íŠ¸ë¦¬ê±°í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì— íŠ¹ìˆ˜ ë‹¨ì–´ `herge_style`ì„ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤:

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("sd-dreambooth-library/herge-style", torch_dtype=torch.float16).to("cuda")
prompt = "A cute herge_style brown bear eating a slice of pizza, stunning color scheme, masterpiece, illustration"
image = pipeline(prompt).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_dreambooth.png" />
</div>

## Textual inversion

[Textual inversion](https://textual-inversion.github.io/)ì€ DreamBoothì™€ ë§¤ìš° ìœ ì‚¬í•˜ë©° ëª‡ ê°œì˜ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ íŠ¹ì • ê°œë…(ìŠ¤íƒ€ì¼, ê°œì²´)ì„ ìƒì„±í•˜ëŠ” diffusion ëª¨ë¸ì„ ê°œì¸í™”í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ í”„ë¡¬í”„íŠ¸ì— íŠ¹ì • ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìƒˆë¡œìš´ ì„ë² ë”©ì„ í•™ìŠµí•˜ê³  ì°¾ì•„ë‚´ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ diffusion ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ê³  í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ëŠ” ë¹„êµì  ì‘ì€(ìˆ˜ KB) íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

Textual inversionì€ ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— DreamBoothì²˜ëŸ¼ ë‹¨ë…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë©° ë˜ ë‹¤ë¥¸ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", torch_dtype=torch.float16).to("cuda")
```

ì´ì œ [`~loaders.TextualInversionLoaderMixin.load_textual_inversion`] ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ textual inversion ì„ë² ë”©ì„ ë¶ˆëŸ¬ì™€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [sd-concepts-library/gta5-artwork](https://huggingface.co/sd-concepts-library/gta5-artwork) ì„ë² ë”©ì„ ë¶ˆëŸ¬ì™€ ë³´ê² ìŠµë‹ˆë‹¤. ì´ë¥¼ íŠ¸ë¦¬ê±°í•˜ë ¤ë©´ í”„ë¡¬í”„íŠ¸ì— íŠ¹ìˆ˜ ë‹¨ì–´ `<gta5-artwork>`ë¥¼ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤:

```py
pipeline.load_textual_inversion("sd-concepts-library/gta5-artwork")
prompt = "A cute brown bear eating a slice of pizza, stunning color scheme, masterpiece, illustration, <gta5-artwork> style"
image = pipeline(prompt).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_txt_embed.png" />
</div>

Textual inversionì€ ë˜í•œ ë°”ëŒì§í•˜ì§€ ì•Šì€ ì‚¬ë¬¼ì— ëŒ€í•´ *ë„¤ê±°í‹°ë¸Œ ì„ë² ë”©*ì„ ìƒì„±í•˜ì—¬ ëª¨ë¸ì´ íë¦¿í•œ ì´ë¯¸ì§€ë‚˜ ì†ì˜ ì¶”ê°€ ì†ê°€ë½ê³¼ ê°™ì€ ë°”ëŒì§í•˜ì§€ ì•Šì€ ì‚¬ë¬¼ì´ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í•˜ë„ë¡ í•™ìŠµí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ê°œì„ í•˜ëŠ” ê²ƒì´ ì‰¬ìš´ ë°©ë²•ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì´ì „ê³¼ ê°™ì´ ì„ë² ë”©ì„ [`~loaders.TextualInversionLoaderMixin.load_textual_inversion`]ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ì§€ë§Œ ì´ë²ˆì—ëŠ” ë‘ ê°œì˜ ë§¤ê°œë³€ìˆ˜ê°€ ë” í•„ìš”í•©ë‹ˆë‹¤:

- `weight_name`: íŒŒì¼ì´ íŠ¹ì • ì´ë¦„ì˜ ğŸ¤— Diffusers í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš°ì´ê±°ë‚˜ íŒŒì¼ì´ A1111 í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš°, ë¶ˆëŸ¬ì˜¬ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì§€ì •í•©ë‹ˆë‹¤.
- `token`: ì„ë² ë”©ì„ íŠ¸ë¦¬ê±°í•˜ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©í•  íŠ¹ìˆ˜ ë‹¨ì–´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

[sayakpaul/EasyNegative-test](https://huggingface.co/sayakpaul/EasyNegative-test) ì„ë² ë”©ì„ ë¶ˆëŸ¬ì™€ ë³´ê² ìŠµë‹ˆë‹¤:

```py
pipeline.load_textual_inversion(
    "sayakpaul/EasyNegative-test", weight_name="EasyNegative.safetensors", token="EasyNegative"
)
```

ì´ì œ `token`ì„ ì‚¬ìš©í•´ ë„¤ê±°í‹°ë¸Œ ì„ë² ë”©ì´ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
prompt = "A cute brown bear eating a slice of pizza, stunning color scheme, masterpiece, illustration, EasyNegative"
negative_prompt = "EasyNegative"

image = pipeline(prompt, negative_prompt=negative_prompt, num_inference_steps=50).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_neg_embed.png" />
</div>

## LoRA

[Low-Rank Adaptation (LoRA)](https://huggingface.co/papers/2106.09685)ì€ ì†ë„ê°€ ë¹ ë¥´ê³  íŒŒì¼ í¬ê¸°ê°€ (ìˆ˜ë°± MBë¡œ) ì‘ê¸° ë•Œë¬¸ì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œì˜ ë‹¤ë¥¸ ë°©ë²•ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, LoRAëŠ” ëª‡ ì¥ì˜ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ì„ í•™ìŠµí•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” diffusion ëª¨ë¸ì— ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë¥¼ ì‚½ì…í•œ ë‹¤ìŒ ì „ì²´ ëª¨ë¸ ëŒ€ì‹  ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë§Œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ë”°ë¼ì„œ LoRAë¥¼ ë” ë¹ ë¥´ê²Œ í•™ìŠµì‹œí‚¤ê³  ë” ì‰½ê²Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<Tip>

LoRAëŠ” ë‹¤ë¥¸ í•™ìŠµ ë°©ë²•ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë§¤ìš° ì¼ë°˜ì ì¸ í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, DreamBoothì™€ LoRAë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë˜í•œ ìƒˆë¡­ê³  ê³ ìœ í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ê°œì˜ LoRAë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë³‘í•©í•˜ëŠ” ê²ƒì´ ì ì  ë” ì¼ë°˜í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë³‘í•©ì€ ì´ ë¶ˆëŸ¬ì˜¤ê¸° ê°€ì´ë“œì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë¯€ë¡œ ìì„¸í•œ ë‚´ìš©ì€ ì‹¬ì¸µì ì¸ [LoRA ë³‘í•©](merge_loras) ê°€ì´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

</Tip>

LoRAëŠ” ë‹¤ë¥¸ ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤:

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")
```

ê·¸ë¦¬ê³  [`~loaders.LoraLoaderMixin.load_lora_weights`] ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ [ostris/super-cereal-sdxl-lora](https://huggingface.co/ostris/super-cereal-sdxl-lora) ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ê°€ì¤‘ì¹˜ íŒŒì¼ëª…ì„ ì§€ì •í•©ë‹ˆë‹¤:

```py
pipeline.load_lora_weights("ostris/super-cereal-sdxl-lora", weight_name="cereal_box_sdxl_v1.safetensors")
prompt = "bears, pizza bites"
image = pipeline(prompt).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_lora.png" />
</div>

[`~loaders.LoraLoaderMixin.load_lora_weights`] ë©”ì„œë“œëŠ” LoRA ê°€ì¤‘ì¹˜ë¥¼ UNetê³¼ í…ìŠ¤íŠ¸ ì¸ì½”ë”ì— ëª¨ë‘ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì´ ë©”ì„œë“œëŠ” í•´ë‹¹ ì¼€ì´ìŠ¤ì—ì„œ LoRAë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì„ í˜¸ë˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤:

- LoRA ê°€ì¤‘ì¹˜ì— UNet ë° í…ìŠ¤íŠ¸ ì¸ì½”ë”ì— ëŒ€í•œ ë³„ë„ì˜ ì‹ë³„ìê°€ ì—†ëŠ” ê²½ìš°
- LoRA ê°€ì¤‘ì¹˜ì— UNetê³¼ í…ìŠ¤íŠ¸ ì¸ì½”ë”ì— ëŒ€í•œ ë³„ë„ì˜ ì‹ë³„ìê°€ ìˆëŠ” ê²½ìš°

í•˜ì§€ë§Œ LoRA ê°€ì¤‘ì¹˜ë§Œ UNetì— ë¡œë“œí•´ì•¼ í•˜ëŠ” ê²½ìš°ì—ëŠ” [`~loaders.UNet2DConditionLoadersMixin.load_attn_procs`] ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [jbilcke-hf/sdxl-cinematic-1](https://huggingface.co/jbilcke-hf/sdxl-cinematic-1) LoRAë¥¼ ë¶ˆëŸ¬ì™€ ë³´ê² ìŠµë‹ˆë‹¤:

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")
pipeline.unet.load_attn_procs("jbilcke-hf/sdxl-cinematic-1", weight_name="pytorch_lora_weights.safetensors")

# í”„ë¡¬í”„íŠ¸ì—ì„œ cnmtë¥¼ ì‚¬ìš©í•˜ì—¬ LoRAë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.
prompt = "A cute cnmt eating a slice of pizza, stunning color scheme, masterpiece, illustration"
image = pipeline(prompt).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_attn_proc.png" />
</div>

LoRA ê°€ì¤‘ì¹˜ë¥¼ ì–¸ë¡œë“œí•˜ë ¤ë©´ [`~loaders.LoraLoaderMixin.unload_lora_weights`] ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ LoRA ê°€ì¤‘ì¹˜ë¥¼ ì‚­ì œí•˜ê³  ëª¨ë¸ì„ ì›ë˜ ê°€ì¤‘ì¹˜ë¡œ ë³µì›í•©ë‹ˆë‹¤:

```py
pipeline.unload_lora_weights()
```

### LoRA ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¼ ì¡°ì •í•˜ê¸°

[`~loaders.LoraLoaderMixin.load_lora_weights`] ë° [`~loaders.UNet2DConditionLoadersMixin.load_attn_procs`] ëª¨ë‘ `cross_attention_kwargs={"scale": 0.5}` íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì—¬ ì–¼ë§ˆë‚˜ LoRA ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í• ì§€ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°’ì´ `0`ì´ë©´ ê¸°ë³¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ê³ , ê°’ì´ `1`ì´ë©´ ì™„ì „íˆ ë¯¸ì„¸ ì¡°ì •ëœ LoRAë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.

ë ˆì´ì–´ë‹¹ ì‚¬ìš©ë˜ëŠ” LoRA ê°€ì¤‘ì¹˜ì˜ ì–‘ì„ ë³´ë‹¤ ì„¸ë°€í•˜ê²Œ ì œì–´í•˜ë ¤ë©´ [`~loaders.LoraLoaderMixin.set_adapters`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì–¼ë§ˆë§Œí¼ ì¡°ì •í• ì§€ ì§€ì •í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```python
pipe = ... # íŒŒì´í”„ë¼ì¸ ìƒì„±
pipe.load_lora_weights(..., adapter_name="my_adapter")
scales = {
    "text_encoder": 0.5,
    "text_encoder_2": 0.5,  # íŒŒì´í”„ì— ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸ ì¸ì½”ë”ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš© ê°€ëŠ¥
    "unet": {
        "down": 0.9,  # down ë¶€ë¶„ì˜ ëª¨ë“  íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìŠ¤ì¼€ì¼ 0.9ë¥¼ ì‚¬ìš©
        # "mid"  # ì´ ì˜ˆì œì—ì„œëŠ” "mid"ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì¤‘ê°„ ë¶€ë¶„ì˜ ëª¨ë“  íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê¸°ë³¸ ìŠ¤ì¼€ì¼ 1.0ì„ ì‚¬ìš©
        "up": {
            "block_0": 0.6,  # # upì˜ 0ë²ˆì§¸ ë¸”ë¡ì— ìˆëŠ” 3ê°œì˜ íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ëª¨ë‘ ìŠ¤ì¼€ì¼ 0.6ì„ ì‚¬ìš©
            "block_1": [0.4, 0.8, 1.0],  # upì˜ ì²« ë²ˆì§¸ ë¸”ë¡ì— ìˆëŠ” 3ê°œì˜ íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê°ê° ìŠ¤ì¼€ì¼ 0.4, 0.8, 1.0ì„ ì‚¬ìš©
        }
    }
}
pipe.set_adapters("my_adapter", scales)
```

ì´ëŠ” ì—¬ëŸ¬ ì–´ëŒ‘í„°ì—ì„œë„ ì‘ë™í•©ë‹ˆë‹¤. ë°©ë²•ì€ [ì´ ê°€ì´ë“œ](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference#customize-adapters-strength)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

<Tip warning={true}>

í˜„ì¬ [`~loaders.LoraLoaderMixin.set_adapters`]ëŠ” ì–´í…ì…˜ ê°€ì¤‘ì¹˜ì˜ ìŠ¤ì¼€ì¼ë§ë§Œ ì§€ì›í•©ë‹ˆë‹¤. LoRAì— ë‹¤ë¥¸ ë¶€ë¶„(ì˜ˆ: resnets or down-/upsamplers)ì´ ìˆëŠ” ê²½ìš° 1.0ì˜ ìŠ¤ì¼€ì¼ì„ ìœ ì§€í•©ë‹ˆë‹¤.

</Tip>

### Kohyaì™€ TheLastBen

ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì¸ê¸° ìˆëŠ” ë‹¤ë¥¸ LoRA trainerë¡œëŠ” [Kohya](https://github.com/kohya-ss/sd-scripts/)ì™€ [TheLastBen](https://github.com/TheLastBen/fast-stable-diffusion)ì˜ trainerê°€ ìˆìŠµë‹ˆë‹¤. ì´ trainerë“¤ì€ ğŸ¤— Diffusersê°€ í›ˆë ¨í•œ ê²ƒê³¼ëŠ” ë‹¤ë¥¸ LoRA ì²´í¬í¬ì¸íŠ¸ë¥¼ ìƒì„±í•˜ì§€ë§Œ, ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<hfoptions id="other-trainers">
<hfoption id="Kohya">

Kohya LoRAë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´, ì˜ˆì‹œë¡œ [Civitai](https://civitai.com/)ì—ì„œ [Blueprintify SD XL 1.0](https://civitai.com/models/150986/blueprintify-sd-xl-10) ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤:

```sh
!wget https://civitai.com/api/download/models/168776 -O blueprintify-sd-xl-10.safetensors
```

LoRA ì²´í¬í¬ì¸íŠ¸ë¥¼ [`~loaders.LoraLoaderMixin.load_lora_weights`] ë©”ì„œë“œë¡œ ë¶ˆëŸ¬ì˜¤ê³  `weight_name` íŒŒë¼ë¯¸í„°ì— íŒŒì¼ëª…ì„ ì§€ì •í•©ë‹ˆë‹¤:

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")
pipeline.load_lora_weights("path/to/weights", weight_name="blueprintify-sd-xl-10.safetensors")
```

ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```py
# LoRAë¥¼ íŠ¸ë¦¬ê±°í•˜ê¸° ìœ„í•´ bl3uprintë¥¼ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©
prompt = "bl3uprint, a highly detailed blueprint of the eiffel tower, explaining how to build all parts, many txt, blueprint grid backdrop"
image = pipeline(prompt).images[0]
image
```

<Tip warning={true}>

Kohya LoRAë¥¼ ğŸ¤— Diffusersì™€ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ ëª‡ ê°€ì§€ ì œí•œ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤:

- [ì—¬ê¸°](https://github.com/huggingface/diffusers/pull/4287/#issuecomment-1655110736)ì— ì„¤ëª…ëœ ì—¬ëŸ¬ ê°€ì§€ ì´ìœ ë¡œ ì¸í•´ ì´ë¯¸ì§€ê°€ ComfyUIì™€ ê°™ì€ UIì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ë‹¤ë¥´ê²Œ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- [LyCORIS ì²´í¬í¬ì¸íŠ¸](https://github.com/KohakuBlueleaf/LyCORIS)ê°€ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. [`~loaders.LoraLoaderMixin.load_lora_weights`] ë©”ì„œë“œëŠ” LoRA ë° LoCon ëª¨ë“ˆë¡œ LyCORIS ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆì§€ë§Œ, Hada ë° LoKRì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

</Tip>

</hfoption>
<hfoption id="TheLastBen">

TheLastBenì—ì„œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [TheLastBen/William_Eggleston_Style_SDXL](https://huggingface.co/TheLastBen/William_Eggleston_Style_SDXL) ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ë ¤ë©´:

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")
pipeline.load_lora_weights("TheLastBen/William_Eggleston_Style_SDXL", weight_name="wegg.safetensors")

# LoRAë¥¼ íŠ¸ë¦¬ê±°í•˜ê¸° ìœ„í•´ william egglestonë¥¼ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©
prompt = "a house by william eggleston, sunrays, beautiful, sunlight, sunrays, beautiful"
image = pipeline(prompt=prompt).images[0]
image
```

</hfoption>
</hfoptions>

## IP-Adapter

[IP-Adapter](https://ip-adapter.github.io/)ëŠ” ëª¨ë“  diffusion ëª¨ë¸ì— ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²½ëŸ‰ ì–´ëŒ‘í„°ì…ë‹ˆë‹¤. ì´ ì–´ëŒ‘í„°ëŠ” ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ featureì˜ cross-attention ë ˆì´ì–´ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì‘ë™í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë“  ëª¨ë¸ ì»´í¬ë„ŒíŠ¸íŠ¼ freezeë˜ê³  UNetì˜ embedded ì´ë¯¸ì§€ featuresë§Œ í•™ìŠµë©ë‹ˆë‹¤. ë”°ë¼ì„œ IP-Adapter íŒŒì¼ì€ ì¼ë°˜ì ìœ¼ë¡œ ìµœëŒ€ 100MBì— ë¶ˆê³¼í•©ë‹ˆë‹¤.

ë‹¤ì–‘í•œ ì‘ì—…ê³¼ êµ¬ì²´ì ì¸ ì‚¬ìš© ì‚¬ë¡€ì— IP-Adapterë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [IP-Adapter](../using-diffusers/ip_adapter) ê°€ì´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> [!TIP]
> DiffusersëŠ” í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì¼ë¶€ íŒŒì´í”„ë¼ì¸ì— ëŒ€í•´ì„œë§Œ IP-Adapterë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ë©‹ì§„ ì‚¬ìš© ì‚¬ë¡€ê°€ ìˆëŠ” ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì´í”„ë¼ì¸ì— IP-Adapterë¥¼ í†µí•©í•˜ê³  ì‹¶ë‹¤ë©´ ì–¸ì œë“ ì§€ ê¸°ëŠ¥ ìš”ì²­ì„ ì—¬ì„¸ìš”!
> ê³µì‹ IP-Adapter ì²´í¬í¬ì¸íŠ¸ëŠ” [h94/IP-Adapter](https://huggingface.co/h94/IP-Adapter)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‹œì‘í•˜ë ¤ë©´ Stable Diffusion ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.

```py
from diffusers import AutoPipelineForText2Image
import torch
from diffusers.utils import load_image

pipeline = AutoPipelineForText2Image.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", torch_dtype=torch.float16).to("cuda")
```

ê·¸ëŸ° ë‹¤ìŒ IP-Adapter ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì™€ [`~loaders.IPAdapterMixin.load_ip_adapter`] ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.

```py
pipeline.load_ip_adapter("h94/IP-Adapter", subfolder="models", weight_name="ip-adapter_sd15.bin")
```

ë¶ˆëŸ¬ì˜¨ ë’¤, ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ê°€ì´ë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_neg_embed.png")
generator = torch.Generator(device="cpu").manual_seed(33)
images = pipeline(
Â  Â  prompt='best quality, high quality, wearing sunglasses',
Â  Â  ip_adapter_image=image,
Â  Â  negative_prompt="monochrome, lowres, bad anatomy, worst quality, low quality",
Â  Â  num_inference_steps=50,
Â  Â  generator=generator,
).images[0]
images
```

<div class="flex justify-center">
Â  Â  <img src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/ip-bear.png" />
</div>

### IP-Adapter Plus

IP-AdapterëŠ” ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ featureë¥¼ ìƒì„±í•©ë‹ˆë‹¤. IP-Adapter ë¦¬í¬ì§€í† ë¦¬ì— `image_encoder` í•˜ìœ„ í´ë”ê°€ ìˆëŠ” ê²½ìš°, ì´ë¯¸ì§€ ì¸ì½”ë”ê°€ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ íŒŒì´í”„ë¼ì¸ì— ë“±ë¡ë©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°, [`~transformers.CLIPVisionModelWithProjection`] ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ íŒŒì´í”„ë¼ì¸ì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

ì´ëŠ” ViT-H ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ëŠ” *IP-Adapter Plus* ì²´í¬í¬ì¸íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì¼€ì´ìŠ¤ì…ë‹ˆë‹¤.

```py
from transformers import CLIPVisionModelWithProjection

image_encoder = CLIPVisionModelWithProjection.from_pretrained(
    "h94/IP-Adapter",
    subfolder="models/image_encoder",
    torch_dtype=torch.float16
)

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    image_encoder=image_encoder,
    torch_dtype=torch.float16
).to("cuda")

pipeline.load_ip_adapter("h94/IP-Adapter", subfolder="sdxl_models", weight_name="ip-adapter-plus_sdxl_vit-h.safetensors")
```

### IP-Adapter Face ID ëª¨ë¸

IP-Adapter FaceID ëª¨ë¸ì€ CLIP ì´ë¯¸ì§€ ì„ë² ë”© ëŒ€ì‹  `insightface`ì—ì„œ ìƒì„±í•œ ì´ë¯¸ì§€ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ì‹¤í—˜ì ì¸ IP Adapterì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ ì¤‘ ì¼ë¶€ëŠ” LoRAë¥¼ ì‚¬ìš©í•˜ì—¬ ID ì¼ê´€ì„±ì„ ê°œì„ í•˜ê¸°ë„ í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ `insightface`ì™€ í•´ë‹¹ ìš”êµ¬ ì‚¬í•­ì„ ëª¨ë‘ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

<Tip warning={true}>
InsightFace ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì€ ë¹„ìƒì—…ì  ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, IP-Adapter-FaceID ëª¨ë¸ì€ ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ë¦´ë¦¬ì¦ˆë˜ì—ˆìœ¼ë©° ìƒì—…ì  ìš©ë„ë¡œëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
</Tip>

```py
pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16
).to("cuda")

pipeline.load_ip_adapter("h94/IP-Adapter-FaceID", subfolder=None, weight_name="ip-adapter-faceid_sdxl.bin", image_encoder_folder=None)
```

ë‘ ê°€ì§€ IP ì–´ëŒ‘í„° FaceID Plus ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš°, ì´ ëª¨ë¸ë“¤ì€ ë” ë‚˜ì€ ì‚¬ì‹¤ê°ì„ ì–»ê¸° ìœ„í•´ `insightface`ì™€ CLIP ì´ë¯¸ì§€ ì„ë² ë”©ì„ ëª¨ë‘ ì‚¬ìš©í•˜ë¯€ë¡œ, CLIP ì´ë¯¸ì§€ ì¸ì½”ë”ë„ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.

```py
from transformers import CLIPVisionModelWithProjection

image_encoder = CLIPVisionModelWithProjection.from_pretrained(
    "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
    torch_dtype=torch.float16,
)

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    image_encoder=image_encoder,
    torch_dtype=torch.float16
).to("cuda")

pipeline.load_ip_adapter("h94/IP-Adapter-FaceID", subfolder=None, weight_name="ip-adapter-faceid-plus_sd15.bin")
```
