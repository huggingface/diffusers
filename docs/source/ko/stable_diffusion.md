<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì¸ Diffusion

[[open-in-colab]]

íŠ¹ì • ìŠ¤íƒ€ì¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì›í•˜ëŠ” ë‚´ìš©ì„ í¬í•¨í•˜ë„ë¡[`DiffusionPipeline`]ì„ ì„¤ì •í•˜ëŠ” ê²ƒì€ ê¹Œë‹¤ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¢…ì¢… ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ë¥¼ ì–»ê¸°ê¹Œì§€ [`DiffusionPipeline`]ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬´ì—ì„œ ìœ ë¥¼ ì°½ì¡°í•˜ëŠ” ê²ƒì€ íŠ¹íˆ ì¶”ë¡ ì„ ë°˜ë³µí•´ì„œ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ê³„ì‚° ì§‘ì•½ì ì¸ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.

ê·¸ë ‡ê¸° ë•Œë¬¸ì— íŒŒì´í”„ë¼ì¸ì—ì„œ *ê³„ì‚°*(ì†ë„) ë° *ë©”ëª¨ë¦¬*(GPU RAM) íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ì—¬ ì¶”ë¡  ì£¼ê¸° ì‚¬ì´ì˜ ì‹œê°„ì„ ë‹¨ì¶•í•˜ì—¬ ë” ë¹ ë¥´ê²Œ ë°˜ë³µí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” [`DiffusionPipeline`]ì„ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê³  íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

[`stable-diffusion-v1-5/stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5) ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì‹œì‘í•©ë‹ˆë‹¤:

```python
from diffusers import DiffusionPipeline

model_id = "stable-diffusion-v1-5/stable-diffusion-v1-5"
pipeline = DiffusionPipeline.from_pretrained(model_id)
```

ì˜ˆì œ í”„ë¡¬í”„íŠ¸ëŠ” "portrait of an old warrior chief" ì´ì§€ë§Œ, ììœ ë¡­ê²Œ ìì‹ ë§Œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤:

```python
prompt = "portrait photo of a old warrior chief"
```

## ì†ë„

<Tip>

ğŸ’¡ GPUì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ GPU ì œê³µì—…ì²´ì—ì„œ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!. [Colab](https://colab.research.google.com/)

</Tip>

ì¶”ë¡  ì†ë„ë¥¼ ë†’ì´ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• ì¤‘ í•˜ë‚˜ëŠ” Pytorch ëª¨ë“ˆì„ ì‚¬ìš©í•  ë•Œì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ GPUì— íŒŒì´í”„ë¼ì¸ì„ ë°°ì¹˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

```python
pipeline = pipeline.to("cuda")
```

ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ë¥¼ ì‚¬ìš©í•˜ê³  [ì¬í˜„ì„±](./using-diffusers/reusing_seeds)ì— ëŒ€í•œ ì‹œë“œë¥¼ ì„¤ì •í•˜ì„¸ìš”:

```python
import torch

generator = torch.Generator("cuda").manual_seed(0)
```

ì´ì œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
image = pipeline(prompt, generator=generator).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_1.png">
</div>

ì´ í”„ë¡œì„¸ìŠ¤ëŠ” T4 GPUì—ì„œ ì•½ 30ì´ˆê°€ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤(í• ë‹¹ëœ GPUê°€ T4ë³´ë‹¤ ë‚˜ì€ ê²½ìš° ë” ë¹ ë¥¼ ìˆ˜ ìˆìŒ). ê¸°ë³¸ì ìœ¼ë¡œ [`DiffusionPipeline`]ì€ 50ê°œì˜ ì¶”ë¡  ë‹¨ê³„ì— ëŒ€í•´ ì „ì²´ `float32` ì •ë°€ë„ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. `float16`ê³¼ ê°™ì€ ë” ë‚®ì€ ì •ë°€ë„ë¡œ ì „í™˜í•˜ê±°ë‚˜ ì¶”ë¡  ë‹¨ê³„ë¥¼ ë” ì ê²Œ ì‹¤í–‰í•˜ì—¬ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

`float16`ìœ¼ë¡œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤:


```python
import torch

pipeline = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipeline = pipeline.to("cuda")
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_2.png">
</div>

ì´ë²ˆì—ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ì•½ 11ì´ˆë°–ì— ê±¸ë¦¬ì§€ ì•Šì•„ ì´ì „ë³´ë‹¤ 3ë°° ê°€ê¹Œì´ ë¹¨ë¼ì¡ŒìŠµë‹ˆë‹¤!

<Tip>

ğŸ’¡ íŒŒì´í”„ë¼ì¸ì€ í•­ìƒ `float16`ì—ì„œ ì‹¤í–‰í•  ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥í•˜ë©°, ì§€ê¸ˆê¹Œì§€ ì¶œë ¥ í’ˆì§ˆì´ ì €í•˜ë˜ëŠ” ê²½ìš°ëŠ” ê±°ì˜ ì—†ì—ˆìŠµë‹ˆë‹¤.

</Tip>

ë˜ ë‹¤ë¥¸ ì˜µì…˜ì€ ì¶”ë¡  ë‹¨ê³„ì˜ ìˆ˜ë¥¼ ì¤„ì´ëŠ” ê²ƒì…ë‹ˆë‹¤. ë³´ë‹¤ íš¨ìœ¨ì ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì„ íƒí•˜ë©´ ì¶œë ¥ í’ˆì§ˆ ì €í•˜ ì—†ì´ ë‹¨ê³„ ìˆ˜ë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ëª¨ë¸ê³¼ í˜¸í™˜ë˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” `compatibles` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ [`DiffusionPipeline`]ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
pipeline.scheduler.compatibles
[
    diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,
    diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,
    diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,
    diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,
    diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,
    diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,
    diffusers.schedulers.scheduling_ddpm.DDPMScheduler,
    diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,
    diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,
    diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,
    diffusers.schedulers.scheduling_pndm.PNDMScheduler,
    diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,
    diffusers.schedulers.scheduling_ddim.DDIMScheduler,
]
```

Stable Diffusion ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì•½ 50ê°œì˜ ì¶”ë¡  ë‹¨ê³„ê°€ í•„ìš”í•œ [`PNDMScheduler`]ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, [`DPMSolverMultistepScheduler`]ì™€ ê°™ì´ ì„±ëŠ¥ì´ ë” ë›°ì–´ë‚œ ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì•½ 20ê°œ ë˜ëŠ” 25ê°œì˜ ì¶”ë¡  ë‹¨ê³„ë§Œ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ìƒˆ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë¡œë“œí•˜ë ¤ë©´ [`ConfigMixin.from_config`] ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
from diffusers import DPMSolverMultistepScheduler

pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)
```

`num_inference_steps`ë¥¼ 20ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤:

```python
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_3.png">
</div>

ì¶”ë¡ ì‹œê°„ì„ 4ì´ˆë¡œ ë‹¨ì¶•í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤! âš¡ï¸

## ë©”ëª¨ë¦¬

íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í–¥ìƒì˜ ë˜ ë‹¤ë¥¸ í•µì‹¬ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ëŠ” ê²ƒì¸ë°, ì´ˆë‹¹ ìƒì„±ë˜ëŠ” ì´ë¯¸ì§€ ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ë ¤ê³  í•˜ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì— ê°„ì ‘ì ìœ¼ë¡œ ë” ë¹ ë¥¸ ì†ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. í•œ ë²ˆì— ìƒì„±í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ ìˆ˜ë¥¼ í™•ì¸í•˜ëŠ” ê°€ì¥ ì‰¬ìš´ ë°©ë²•ì€ `OutOfMemoryError`(OOM)ì´ ë°œìƒí•  ë•Œê¹Œì§€ ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë¥¼ ì‹œë„í•´ ë³´ëŠ” ê²ƒì…ë‹ˆë‹¤.

í”„ë¡¬í”„íŠ¸ ëª©ë¡ê³¼ `Generators`ì—ì„œ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì¢‹ì€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ê²½ìš° ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê° `Generator`ì— ì‹œë“œë¥¼ í• ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤.

```python
def get_inputs(batch_size=1):
    generator = [torch.Generator("cuda").manual_seed(i) for i in range(batch_size)]
    prompts = batch_size * [prompt]
    num_inference_steps = 20

    return {"prompt": prompts, "generator": generator, "num_inference_steps": num_inference_steps}
```

ë˜í•œ ê° ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤:

```python
from PIL import Image


def image_grid(imgs, rows=2, cols=2):
    w, h = imgs[0].size
    grid = Image.new("RGB", size=(cols * w, rows * h))

    for i, img in enumerate(imgs):
        grid.paste(img, box=(i % cols * w, i // cols * h))
    return grid
```

`batch_size=4`ë¶€í„° ì‹œì‘í•´ ì–¼ë§ˆë‚˜ ë§ì€ ë©”ëª¨ë¦¬ë¥¼ ì†Œë¹„í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:

```python
images = pipeline(**get_inputs(batch_size=4)).images
image_grid(images)
```

RAMì´ ë” ë§ì€ GPUê°€ ì•„ë‹ˆë¼ë©´ ìœ„ì˜ ì½”ë“œì—ì„œ `OOM` ì˜¤ë¥˜ê°€ ë°˜í™˜ë˜ì—ˆì„ ê²ƒì…ë‹ˆë‹¤! ëŒ€ë¶€ë¶„ì˜ ë©”ëª¨ë¦¬ëŠ” cross-attention ë ˆì´ì–´ê°€ ì°¨ì§€í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ë°°ì¹˜ë¡œ ì‹¤í–‰í•˜ëŠ” ëŒ€ì‹  ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ ìƒë‹¹í•œ ì–‘ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ì—¬ [`~DiffusionPipeline.enable_attention_slicing`] í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤:


```python
pipeline.enable_attention_slicing()
```

ì´ì œ `batch_size`ë¥¼ 8ë¡œ ëŠ˜ë ¤ë³´ì„¸ìš”!

```python
images = pipeline(**get_inputs(batch_size=8)).images
image_grid(images, rows=2, cols=4)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_5.png">
</div>

ì´ì „ì—ëŠ” 4ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ìƒì„±í•  ìˆ˜ë„ ì—†ì—ˆì§€ë§Œ, ì´ì œëŠ” ì´ë¯¸ì§€ë‹¹ ì•½ 3.5ì´ˆ ë§Œì— 8ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì´ëŠ” ì•„ë§ˆë„ í’ˆì§ˆ ì €í•˜ ì—†ì´ T4 GPUì—ì„œ ê°€ì¥ ë¹ ë¥¸ ì†ë„ì¼ ê²ƒì…ë‹ˆë‹¤.

## í’ˆì§ˆ

ì§€ë‚œ ë‘ ì„¹ì…˜ì—ì„œëŠ” `fp16`ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì˜ ì†ë„ë¥¼ ìµœì í™”í•˜ê³ , ë” ì„±ëŠ¥ì´ ì¢‹ì€ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ë‹¨ê³„ì˜ ìˆ˜ë¥¼ ì¤„ì´ê³ , attention slicingì„ í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì†Œë¹„ë¥¼ ì¤„ì´ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤. ì´ì œ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì§‘ì¤‘ì ìœ¼ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.


### ë” ë‚˜ì€ ì²´í¬í¬ì¸íŠ¸

ê°€ì¥ í™•ì‹¤í•œ ë‹¨ê³„ëŠ” ë” ë‚˜ì€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Stable Diffusion ëª¨ë¸ì€ ì¢‹ì€ ì¶œë°œì ì´ë©°, ê³µì‹ ì¶œì‹œ ì´í›„ ëª‡ ê°€ì§€ ê°œì„ ëœ ë²„ì „ë„ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìµœì‹  ë²„ì „ì„ ì‚¬ìš©í•œë‹¤ê³  í•´ì„œ ìë™ìœ¼ë¡œ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì—¬ì „íˆ ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì§ì ‘ ì‹¤í—˜í•´ë³´ê³ , [negative prompts](https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/) ì‚¬ìš© ë“± ì•½ê°„ì˜ ì¡°ì‚¬ë¥¼ í†µí•´ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ì–´ì•¼ í•©ë‹ˆë‹¤.

ì´ ë¶„ì•¼ê°€ ì„±ì¥í•¨ì— ë”°ë¼ íŠ¹ì • ìŠ¤íƒ€ì¼ì„ ì—°ì¶œí•  ìˆ˜ ìˆë„ë¡ ì„¸ë°€í•˜ê²Œ ì¡°ì •ëœ ê³ í’ˆì§ˆ ì²´í¬í¬ì¸íŠ¸ê°€ ì ì  ë” ë§ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤. [Hub](https://huggingface.co/models?library=diffusers&sort=downloads)ì™€ [Diffusers Gallery](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery)ë¥¼ ë‘˜ëŸ¬ë³´ê³  ê´€ì‹¬ ìˆëŠ” ê²ƒì„ ì°¾ì•„ë³´ì„¸ìš”!


### ë” ë‚˜ì€ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ

í˜„ì¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ êµì²´í•´ ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. Stability AIì˜ ìµœì‹  [autodecoder](https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main/vae)ë¥¼ íŒŒì´í”„ë¼ì¸ì— ë¡œë“œí•˜ê³  ëª‡ ê°€ì§€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤:


```python
from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float16).to("cuda")
pipeline.vae = vae
images = pipeline(**get_inputs(batch_size=8)).images
image_grid(images, rows=2, cols=4)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_6.png">
</div>

### ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ëŠ” *prompt engineering*ì´ë¼ê³  í•  ì •ë„ë¡œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‹œ ê³ ë ¤í•´ì•¼ í•  ëª‡ ê°€ì§€ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ìƒì„±í•˜ë ¤ëŠ” ì´ë¯¸ì§€ ë˜ëŠ” ìœ ì‚¬í•œ ì´ë¯¸ì§€ê°€ ì¸í„°ë„·ì— ì–´ë–»ê²Œ ì €ì¥ë˜ì–´ ìˆëŠ”ê°€?
- ë‚´ê°€ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ë¡œ ëª¨ë¸ì„ ìœ ë„í•˜ê¸° ìœ„í•´ ì–´ë–¤ ì¶”ê°€ ì„¸ë¶€ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ”ê°€?

ì´ë¥¼ ì—¼ë‘ì— ë‘ê³  ìƒ‰ìƒê³¼ ë” ë†’ì€ í’ˆì§ˆì˜ ë””í…Œì¼ì„ í¬í•¨í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•´ ë´…ì‹œë‹¤:


```python
prompt += ", tribal panther make up, blue on red, side profile, looking away, serious eyes"
prompt += " 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta"
```

ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```python
images = pipeline(**get_inputs(batch_size=8)).images
image_grid(images, rows=2, cols=4)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_7.png">
</div>

ê½¤ ì¸ìƒì ì…ë‹ˆë‹¤! `1`ì˜ ì‹œë“œë¥¼ ê°€ì§„ `Generator`ì— í•´ë‹¹í•˜ëŠ” ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ì— í”¼ì‚¬ì²´ì˜ ë‚˜ì´ì— ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì¡°ê¸ˆ ë” ì¡°ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```python
prompts = [
    "portrait photo of the oldest warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a old warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a young warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
]

generator = [torch.Generator("cuda").manual_seed(1) for _ in range(len(prompts))]
images = pipeline(prompt=prompts, generator=generator, num_inference_steps=25).images
image_grid(images)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_8.png">
</div>

## ë‹¤ìŒ ë‹¨ê³„

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ê³„ì‚° ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ë†’ì´ê³  ìƒì„±ëœ ì¶œë ¥ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ [`DiffusionPipeline`]ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë” ë¹ ë¥´ê²Œ ë§Œë“œëŠ” ë° ê´€ì‹¬ì´ ìˆë‹¤ë©´ ë‹¤ìŒ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚´í´ë³´ì„¸ìš”:

- [PyTorch 2.0](./optimization/torch2.0) ë° [`torch.compile`](https://pytorch.org/docs/stable/generated/torch.compile.html)ì´ ì–´ë–»ê²Œ ì¶”ë¡  ì†ë„ë¥¼ 5~300% í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ì„¸ìš”. A100 GPUì—ì„œëŠ” ì¶”ë¡  ì†ë„ê°€ ìµœëŒ€ 50%ê¹Œì§€ ë¹¨ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
- PyTorch 2ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš°, [xFormers](./optimization/xformers)ë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ PyTorch 1.13.1ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ì†ë„ê°€ ë¹¨ë¼ì§€ê³  ë©”ëª¨ë¦¬ ì†Œë¹„ê°€ ì¤„ì–´ë“­ë‹ˆë‹¤.
- ëª¨ë¸ ì˜¤í”„ë¡œë”©ê³¼ ê°™ì€ ë‹¤ë¥¸ ìµœì í™” ê¸°ë²•ì€ [ì´ ê°€ì´ë“œ](./optimization/fp16)ì—ì„œ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.