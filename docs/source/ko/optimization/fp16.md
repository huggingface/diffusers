<!--Copyright 2025 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# ë©”ëª¨ë¦¬ì™€ ì†ë„

ë©”ëª¨ë¦¬ ë˜ëŠ” ì†ë„ì— ëŒ€í•´ ğŸ¤— Diffusers *ì¶”ë¡ *ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ê¸°ìˆ ê³¼ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
ì¼ë°˜ì ìœ¼ë¡œ, memory-efficient attentionì„ ìœ„í•´ [xFormers](https://github.com/facebookresearch/xformers) ì‚¬ìš©ì„ ì¶”ì²œí•˜ê¸° ë•Œë¬¸ì—, ì¶”ì²œí•˜ëŠ” [ì„¤ì¹˜ ë°©ë²•](xformers)ì„ ë³´ê³  ì„¤ì¹˜í•´ ë³´ì„¸ìš”.

ë‹¤ìŒ ì„¤ì •ì´ ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

|                  | ì§€ì—°ì‹œê°„  | ì†ë„ í–¥ìƒ |
| ---------------- | ------- | ------- |
| ë³„ë„ ì„¤ì • ì—†ìŒ      | 9.50s   | x1      |
| cuDNN auto-tuner | 9.37s   | x1.01   |
| fp16             | 3.61s   | x2.63   |
| Channels Last ë©”ëª¨ë¦¬ í˜•ì‹     | 3.30s   | x2.88   |
| traced UNet      | 3.21s   | x2.96   |
| memory-efficient attention | 2.63s  | x3.61   |

<em>
   NVIDIA TITAN RTXì—ì„œ 50 DDIM ìŠ¤í…ì˜ "a photo of an astronaut riding a horse on mars" í”„ë¡¬í”„íŠ¸ë¡œ 512x512 í¬ê¸°ì˜ ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
</em>

## cuDNN auto-tuner í™œì„±í™”í•˜ê¸°

[NVIDIA cuDNN](https://developer.nvidia.com/cudnn)ì€ ì»¨ë³¼ë£¨ì…˜ì„ ê³„ì‚°í•˜ëŠ” ë§ì€ ì•Œê³ ë¦¬ì¦˜ì„ ì§€ì›í•©ë‹ˆë‹¤. AutotunerëŠ” ì§§ì€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ê³  ì£¼ì–´ì§„ ì…ë ¥ í¬ê¸°ì— ëŒ€í•´ ì£¼ì–´ì§„ í•˜ë“œì›¨ì–´ì—ì„œ ìµœê³ ì˜ ì„±ëŠ¥ì„ ê°€ì§„ ì»¤ë„ì„ ì„ íƒí•©ë‹ˆë‹¤.

**ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬**ë¥¼ í™œìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì— (ë‹¤ë¥¸ ìœ í˜•ë“¤ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŒ), ë‹¤ìŒ ì„¤ì •ì„ í†µí•´ ì¶”ë¡  ì „ì— cuDNN autotunerë¥¼ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import torch

torch.backends.cudnn.benchmark = True
```

### fp32 ëŒ€ì‹  tf32 ì‚¬ìš©í•˜ê¸°  (Ampere ë° ì´í›„ CUDA ì¥ì¹˜ë“¤ì—ì„œ)

Ampere ë° ì´í›„ CUDA ì¥ì¹˜ì—ì„œ í–‰ë ¬ê³± ë° ì»¨ë³¼ë£¨ì…˜ì€ TensorFloat32(TF32) ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ì§€ë§Œ ì•½ê°„ ëœ ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ê¸°ë³¸ì ìœ¼ë¡œ PyTorchëŠ” ì»¨ë³¼ë£¨ì…˜ì— ëŒ€í•´ TF32 ëª¨ë“œë¥¼ í™œì„±í™”í•˜ì§€ë§Œ í–‰ë ¬ ê³±ì…ˆì€ í™œì„±í™”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë„¤íŠ¸ì›Œí¬ì— ì™„ì „í•œ float32 ì •ë°€ë„ê°€ í•„ìš”í•œ ê²½ìš°ê°€ ì•„ë‹ˆë©´ í–‰ë ¬ ê³±ì…ˆì— ëŒ€í•´ì„œë„ ì´ ì„¤ì •ì„ í™œì„±í™”í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜ì˜ ì •í™•ë„ ì†ì‹¤ì´ ìˆì§€ë§Œ, ê³„ì‚° ì†ë„ë¥¼ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ê·¸ê²ƒì— ëŒ€í•´ [ì—¬ê¸°](https://huggingface.co/docs/transformers/v4.18.0/en/performance#tf32)ì„œ ë” ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶”ë¡ í•˜ê¸° ì „ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤:

```python
import torch

torch.backends.cuda.matmul.allow_tf32 = True
```

## ë°˜ì •ë°€ë„ ê°€ì¤‘ì¹˜

ë” ë§ì€ GPU ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê³  ë” ë¹ ë¥¸ ì†ë„ë¥¼ ì–»ê¸° ìœ„í•´ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ì •ë°€ë„(half precision)ë¡œ ì§ì ‘ ë¶ˆëŸ¬ì˜¤ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì—¬ê¸°ì—ëŠ” `fp16`ì´ë¼ëŠ” ë¸Œëœì¹˜ì— ì €ì¥ëœ float16 ë²„ì „ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ê·¸ ë•Œ `float16` ìœ í˜•ì„ ì‚¬ìš©í•˜ë„ë¡ PyTorchì— ì§€ì‹œí•˜ëŠ” ì‘ì—…ì´ í¬í•¨ë©ë‹ˆë‹¤.

```Python
pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",

    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]
```

> [!WARNING]
> ì–´ë–¤ íŒŒì´í”„ë¼ì¸ì—ì„œë„ [`torch.autocast`](https://pytorch.org/docs/stable/amp.html#torch.autocast) ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê³ , ìˆœìˆ˜í•œ float16 ì •ë°€ë„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ í•­ìƒ ëŠë¦¬ê¸° ë•Œë¬¸ì— ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

## ì¶”ê°€ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ìŠ¬ë¼ì´ìŠ¤ ì–´í…ì…˜

ì¶”ê°€ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´, í•œ ë²ˆì— ëª¨ë‘ ê³„ì‚°í•˜ëŠ” ëŒ€ì‹  ë‹¨ê³„ì ìœ¼ë¡œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ìŠ¬ë¼ì´ìŠ¤ ë²„ì „ì˜ ì–´í…ì…˜(attention)ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> [!TIP]
> Attention slicingì€ ëª¨ë¸ì´ í•˜ë‚˜ ì´ìƒì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” í•œ, ë°°ì¹˜ í¬ê¸°ê°€ 1ì¸ ê²½ìš°ì—ë„ ìœ ìš©í•©ë‹ˆë‹¤.
>   í•˜ë‚˜ ì´ìƒì˜ ì–´í…ì…˜ í—¤ë“œê°€ ìˆëŠ” ê²½ìš° *QK^T* ì–´í…ì…˜ ë§¤íŠ¸ë¦­ìŠ¤ëŠ” ìƒë‹¹í•œ ì–‘ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•  ìˆ˜ ìˆëŠ” ê° í—¤ë“œì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ê³„ì‚°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê° í—¤ë“œì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ì–´í…ì…˜ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ë ¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì¶”ë¡  ì „ì— íŒŒì´í”„ë¼ì¸ì—ì„œ [`~StableDiffusionPipeline.enable_attention_slicing`]ë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤:

```Python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",

    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
pipe.enable_attention_slicing()
image = pipe(prompt).images[0]
```

ì¶”ë¡  ì‹œê°„ì´ ì•½ 10% ëŠë ¤ì§€ëŠ” ì•½ê°„ì˜ ì„±ëŠ¥ ì €í•˜ê°€ ìˆì§€ë§Œ ì´ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ 3.2GB ì •ë„ì˜ ì‘ì€ VRAMìœ¼ë¡œë„ Stable Diffusionì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!


## ë” í° ë°°ì¹˜ë¥¼ ìœ„í•œ sliced VAE ë””ì½”ë“œ

ì œí•œëœ VRAMì—ì„œ ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ë””ì½”ë”©í•˜ê±°ë‚˜ 32ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë°°ì¹˜ë¥¼ í™œì„±í™”í•˜ê¸° ìœ„í•´, ë°°ì¹˜ì˜ latent ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— í•˜ë‚˜ì”© ë””ì½”ë”©í•˜ëŠ” ìŠ¬ë¼ì´ìŠ¤ VAE ë””ì½”ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ë¥¼ [`~StableDiffusionPipeline.enable_attention_slicing`] ë˜ëŠ” [`~StableDiffusionPipeline.enable_xformers_memory_efficient_attention`]ê³¼ ê²°í•©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¶”ê°€ë¡œ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

VAE ë””ì½”ë“œë¥¼ í•œ ë²ˆì— í•˜ë‚˜ì”© ìˆ˜í–‰í•˜ë ¤ë©´ ì¶”ë¡  ì „ì— íŒŒì´í”„ë¼ì¸ì—ì„œ [`~StableDiffusionPipeline.enable_vae_slicing`]ì„ í˜¸ì¶œí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:

```Python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",

    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
pipe.enable_vae_slicing()
images = pipe([prompt] * 32).images
```

ë‹¤ì¤‘ ì´ë¯¸ì§€ ë°°ì¹˜ì—ì„œ VAE ë””ì½”ë“œê°€ ì•½ê°„ì˜ ì„±ëŠ¥ í–¥ìƒì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ë‹¨ì¼ ì´ë¯¸ì§€ ë°°ì¹˜ì—ì„œëŠ” ì„±ëŠ¥ ì˜í–¥ì€ ì—†ìŠµë‹ˆë‹¤.


<a name="sequential_offloading"></a>
## ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê°€ì† ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ CPUë¡œ ì˜¤í”„ë¡œë”©

ì¶”ê°€ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê°€ì¤‘ì¹˜ë¥¼ CPUë¡œ ì˜¤í”„ë¡œë“œí•˜ê³  ìˆœë°©í–¥ ì „ë‹¬ì„ ìˆ˜í–‰í•  ë•Œë§Œ GPUë¡œ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

CPU ì˜¤í”„ë¡œë”©ì„ ìˆ˜í–‰í•˜ë ¤ë©´ [`~StableDiffusionPipeline.enable_sequential_cpu_offload`]ë¥¼ í˜¸ì¶œí•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤:

```Python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",

    torch_dtype=torch.float16,
)

prompt = "a photo of an astronaut riding a horse on mars"
pipe.enable_sequential_cpu_offload()
image = pipe(prompt).images[0]
```

ê·¸ëŸ¬ë©´ ë©”ëª¨ë¦¬ ì†Œë¹„ë¥¼ 3GB ë¯¸ë§Œìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì°¸ê³ ë¡œ ì´ ë°©ë²•ì€ ì „ì²´ ëª¨ë¸ì´ ì•„ë‹Œ ì„œë¸Œëª¨ë“ˆ ìˆ˜ì¤€ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ì´ëŠ” ë©”ëª¨ë¦¬ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ì§€ë§Œ í”„ë¡œì„¸ìŠ¤ì˜ ë°˜ë³µì  íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ì¶”ë¡  ì†ë„ê°€ í›¨ì”¬ ëŠë¦½ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì˜ UNet êµ¬ì„± ìš”ì†ŒëŠ” ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ë©ë‹ˆë‹¤('num_inference_steps' ë§Œí¼). ë§¤ë²ˆ UNetì˜ ì„œë¡œ ë‹¤ë¥¸ ì„œë¸Œëª¨ë“ˆì´ ìˆœì°¨ì ìœ¼ë¡œ ì˜¨ë¡œë“œëœ ë‹¤ìŒ í•„ìš”ì— ë”°ë¼ ì˜¤í”„ë¡œë“œë˜ë¯€ë¡œ ë©”ëª¨ë¦¬ ì´ë™ íšŸìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤.

> [!TIP]
> ë˜ ë‹¤ë¥¸ ìµœì í™” ë°©ë²•ì¸ <a href="#model_offloading">ëª¨ë¸ ì˜¤í”„ë¡œë”©</a>ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì‹­ì‹œì˜¤. ì´ëŠ” í›¨ì”¬ ë¹ ë¥´ì§€ë§Œ ë©”ëª¨ë¦¬ ì ˆì•½ì´ í¬ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.

ë˜í•œ ttention slicingê³¼ ì—°ê²°í•´ì„œ ìµœì†Œ ë©”ëª¨ë¦¬(< 2GB)ë¡œë„ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```Python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",

    torch_dtype=torch.float16,
)

prompt = "a photo of an astronaut riding a horse on mars"
pipe.enable_sequential_cpu_offload()
pipe.enable_attention_slicing(1)

image = pipe(prompt).images[0]
```

**ì°¸ê³ **: 'enable_sequential_cpu_offload()'ë¥¼ ì‚¬ìš©í•  ë•Œ, ë¯¸ë¦¬ íŒŒì´í”„ë¼ì¸ì„ CUDAë¡œ ì´ë™í•˜ì§€ **ì•ŠëŠ”** ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë©”ëª¨ë¦¬ ì†Œë¹„ì˜ ì´ë“ì´ ìµœì†Œí™”ë©ë‹ˆë‹¤. ë” ë§ì€ ì •ë³´ë¥¼ ìœ„í•´ [ì´ ì´ìŠˆ](https://github.com/huggingface/diffusers/issues/1934)ë¥¼ ë³´ì„¸ìš”.

<a name="model_offloading"></a>
## ë¹ ë¥¸ ì¶”ë¡ ê³¼ ë©”ëª¨ë¦¬ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ëª¨ë¸ ì˜¤í”„ë¡œë”©

[ìˆœì°¨ì  CPU ì˜¤í”„ë¡œë”©](#sequential_offloading)ì€ ì´ì „ ì„¹ì…˜ì—ì„œ ì„¤ëª…í•œ ê²ƒì²˜ëŸ¼ ë§ì€ ë©”ëª¨ë¦¬ë¥¼ ë³´ì¡´í•˜ì§€ë§Œ í•„ìš”ì— ë”°ë¼ ì„œë¸Œëª¨ë“ˆì„ GPUë¡œ ì´ë™í•˜ê³  ìƒˆ ëª¨ë“ˆì´ ì‹¤í–‰ë  ë•Œ ì¦‰ì‹œ CPUë¡œ ë°˜í™˜ë˜ê¸° ë•Œë¬¸ì— ì¶”ë¡  ì†ë„ê°€ ëŠë ¤ì§‘ë‹ˆë‹¤.

ì „ì²´ ëª¨ë¸ ì˜¤í”„ë¡œë”©ì€ ê° ëª¨ë¸ì˜ êµ¬ì„± ìš”ì†Œì¸ _modules_ì„ ì²˜ë¦¬í•˜ëŠ” ëŒ€ì‹ , ì „ì²´ ëª¨ë¸ì„ GPUë¡œ ì´ë™í•˜ëŠ” ëŒ€ì•ˆì…ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì¶”ë¡  ì‹œê°„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ë¯¸ë¯¸í•˜ì§€ë§Œ(íŒŒì´í”„ë¼ì¸ì„ 'cuda'ë¡œ ì´ë™í•˜ëŠ” ê²ƒê³¼ ë¹„êµí•˜ì—¬) ì—¬ì „íˆ ì•½ê°„ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” íŒŒì´í”„ë¼ì¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ ì¤‘ í•˜ë‚˜ë§Œ(ì¼ë°˜ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¸ì½”ë”, unet ë° vae) GPUì— ìˆê³ , ë‚˜ë¨¸ì§€ëŠ” CPUì—ì„œ ëŒ€ê¸°í•  ê²ƒì…ë‹ˆë‹¤.
ì—¬ëŸ¬ ë°˜ë³µì„ ìœ„í•´ ì‹¤í–‰ë˜ëŠ” UNetê³¼ ê°™ì€ êµ¬ì„± ìš”ì†ŒëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œê¹Œì§€ GPUì— ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.

ì´ ê¸°ëŠ¥ì€ ì•„ë˜ì™€ ê°™ì´ íŒŒì´í”„ë¼ì¸ì—ì„œ `enable_model_cpu_offload()`ë¥¼ í˜¸ì¶œí•˜ì—¬ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```Python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
)

prompt = "a photo of an astronaut riding a horse on mars"
pipe.enable_model_cpu_offload()
image = pipe(prompt).images[0]
```

ì´ëŠ” ì¶”ê°€ì ì¸ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ attention slicingê³¼ë„ í˜¸í™˜ë©ë‹ˆë‹¤.

```Python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
)

prompt = "a photo of an astronaut riding a horse on mars"
pipe.enable_model_cpu_offload()
pipe.enable_attention_slicing(1)

image = pipe(prompt).images[0]
```

> [!TIP]
> ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'accelerate' ë²„ì „ 0.17.0 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.

## Channels Last ë©”ëª¨ë¦¬ í˜•ì‹ ì‚¬ìš©í•˜ê¸°

Channels Last ë©”ëª¨ë¦¬ í˜•ì‹ì€ ì°¨ì› ìˆœì„œë¥¼ ë³´ì¡´í•˜ëŠ” ë©”ëª¨ë¦¬ì—ì„œ NCHW í…ì„œ ë°°ì—´ì„ ëŒ€ì²´í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
Channels Last í…ì„œëŠ” ì±„ë„ì´ ê°€ì¥ ì¡°ë°€í•œ ì°¨ì›ì´ ë˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë ¬ë©ë‹ˆë‹¤(ì¼ëª… í”½ì…€ë‹¹ ì´ë¯¸ì§€ë¥¼ ì €ì¥).
í˜„ì¬ ëª¨ë“  ì—°ì‚°ì Channels Last í˜•ì‹ì„ ì§€ì›í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë¼ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‚¬ìš©í•´ë³´ê³  ëª¨ë¸ì— ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.


ì˜ˆë¥¼ ë“¤ì–´ íŒŒì´í”„ë¼ì¸ì˜ UNet ëª¨ë¸ì´ channels Last í˜•ì‹ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
print(pipe.unet.conv_out.state_dict()["weight"].stride())  # (2880, 9, 3, 1)
pipe.unet.to(memory_format=torch.channels_last)  # in-place ì—°ì‚°
# 2ë²ˆì§¸ ì°¨ì›ì—ì„œ ìŠ¤íŠ¸ë¼ì´ë“œ 1ì„ ê°€ì§€ëŠ” (2880, 1, 960, 320)ë¡œ, ì—°ì‚°ì´ ì‘ë™í•¨ì„ ì¦ëª…í•©ë‹ˆë‹¤.
print(pipe.unet.conv_out.state_dict()["weight"].stride())
```

## ì¶”ì (tracing)

ì¶”ì ì€ ëª¨ë¸ì„ í†µí•´ ì˜ˆì œ ì…ë ¥ í…ì„œë¥¼ í†µí•´ ì‹¤í–‰ë˜ëŠ”ë°, í•´ë‹¹ ì…ë ¥ì´ ëª¨ë¸ì˜ ë ˆì´ì–´ë¥¼ í†µê³¼í•  ë•Œ í˜¸ì¶œë˜ëŠ” ì‘ì—…ì„ ìº¡ì²˜í•˜ì—¬ ì‹¤í–‰ íŒŒì¼ ë˜ëŠ” 'ScriptFunction'ì´ ë°˜í™˜ë˜ë„ë¡ í•˜ê³ , ì´ëŠ” just-in-time ì»´íŒŒì¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤.

UNet ëª¨ë¸ì„ ì¶”ì í•˜ê¸° ìœ„í•´ ë‹¤ìŒì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import time
import torch
from diffusers import StableDiffusionPipeline
import functools

# torch ê¸°ìš¸ê¸° ë¹„í™œì„±í™”
torch.set_grad_enabled(False)

# ë³€ìˆ˜ ì„¤ì •
n_experiments = 2
unet_runs_per_experiment = 50


# ì…ë ¥ ë¶ˆëŸ¬ì˜¤ê¸°
def generate_inputs():
    sample = torch.randn((2, 4, 64, 64), device="cuda", dtype=torch.float16)
    timestep = torch.rand(1, device="cuda", dtype=torch.float16) * 999
    encoder_hidden_states = torch.randn((2, 77, 768), device="cuda", dtype=torch.float16)
    return sample, timestep, encoder_hidden_states


pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
).to("cuda")
unet = pipe.unet
unet.eval()
unet.to(memory_format=torch.channels_last)  # Channels Last ë©”ëª¨ë¦¬ í˜•ì‹ ì‚¬ìš©
unet.forward = functools.partial(unet.forward, return_dict=False)  # return_dict=Falseì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •

# ì›Œë°ì—…
for _ in range(3):
    with torch.inference_mode():
        inputs = generate_inputs()
        orig_output = unet(*inputs)

# ì¶”ì 
print("tracing..")
unet_traced = torch.jit.trace(unet, inputs)
unet_traced.eval()
print("done tracing")


# ì›Œë°ì—… ë° ê·¸ë˜í”„ ìµœì í™”
for _ in range(5):
    with torch.inference_mode():
        inputs = generate_inputs()
        orig_output = unet_traced(*inputs)


# ë²¤ì¹˜ë§ˆí‚¹
with torch.inference_mode():
    for _ in range(n_experiments):
        torch.cuda.synchronize()
        start_time = time.time()
        for _ in range(unet_runs_per_experiment):
            orig_output = unet_traced(*inputs)
        torch.cuda.synchronize()
        print(f"unet traced inference took {time.time() - start_time:.2f} seconds")
    for _ in range(n_experiments):
        torch.cuda.synchronize()
        start_time = time.time()
        for _ in range(unet_runs_per_experiment):
            orig_output = unet(*inputs)
        torch.cuda.synchronize()
        print(f"unet inference took {time.time() - start_time:.2f} seconds")

# ëª¨ë¸ ì €ì¥
unet_traced.save("unet_traced.pt")
```

ê·¸ ë‹¤ìŒ, íŒŒì´í”„ë¼ì¸ì˜ `unet` íŠ¹ì„±ì„ ë‹¤ìŒê³¼ ê°™ì´ ì¶”ì ëœ ëª¨ë¸ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from diffusers import StableDiffusionPipeline
import torch
from dataclasses import dataclass


@dataclass
class UNet2DConditionOutput:
    sample: torch.Tensor


pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
).to("cuda")

# jitted unet ì‚¬ìš©
unet_traced = torch.jit.load("unet_traced.pt")


# pipe.unet ì‚­ì œ
class TracedUNet(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.in_channels = pipe.unet.config.in_channels
        self.device = pipe.unet.device

    def forward(self, latent_model_input, t, encoder_hidden_states):
        sample = unet_traced(latent_model_input, t, encoder_hidden_states)[0]
        return UNet2DConditionOutput(sample=sample)


pipe.unet = TracedUNet()

with torch.inference_mode():
    image = pipe([prompt] * 1, num_inference_steps=50).images[0]
```


## Memory-efficient attention

ì–´í…ì…˜ ë¸”ë¡ì˜ ëŒ€ì—­í­ì„ ìµœì í™”í•˜ëŠ” ìµœê·¼ ì‘ì—…ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ê²Œ í–¥ìƒë˜ê³  í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
@tridaoì˜ ê°€ì¥ ìµœê·¼ì˜ í”Œë˜ì‹œ ì–´í…ì…˜: [code](https://github.com/HazyResearch/flash-attention), [paper](https://huggingface.co/papers/2205.14135).

ë°°ì¹˜ í¬ê¸° 1(í”„ë¡¬í”„íŠ¸ 1ê°œ)ì˜ 512x512 í¬ê¸°ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•  ë•Œ ëª‡ ê°€ì§€ Nvidia GPUì—ì„œ ì–»ì€ ì†ë„ í–¥ìƒì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

| GPU              	| ê¸°ì¤€ ì–´í…ì…˜ FP16 	       | ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì–´í…ì…˜ FP16 	|
|------------------	|---------------------	|---------------------------------	|
| NVIDIA Tesla T4  	| 3.5it/s             	| 5.5it/s                         	|
| NVIDIA 3060 RTX  	| 4.6it/s             	| 7.8it/s                         	|
| NVIDIA A10G      	| 8.88it/s            	| 15.6it/s                        	|
| NVIDIA RTX A6000 	| 11.7it/s            	| 21.09it/s                       	|
| NVIDIA TITAN RTX  | 12.51it/s         	| 18.22it/s                       	|
| A100-SXM4-40GB    	| 18.6it/s            	| 29.it/s                        	|
| A100-SXM-80GB    	| 18.7it/s            	| 29.5it/s                        	|

ì´ë¥¼ í™œìš©í•˜ë ¤ë©´ ë‹¤ìŒì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:
 - PyTorch > 1.12
 - Cuda ì‚¬ìš© ê°€ëŠ¥
 - [xformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•¨](xformers)
```python
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
).to("cuda")

pipe.enable_xformers_memory_efficient_attention()

with torch.inference_mode():
    sample = pipe("a small cat")

# ì„ íƒ: ì´ë¥¼ ë¹„í™œì„±í™” í•˜ê¸° ìœ„í•´ ë‹¤ìŒì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# pipe.disable_xformers_memory_efficient_attention()
```
