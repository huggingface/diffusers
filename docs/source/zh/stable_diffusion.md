<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->
                                                               
# æœ‰æ•ˆä¸”é«˜æ•ˆçš„æ‰©æ•£

[[open-in-colab]]

è®© [`DiffusionPipeline`] ç”Ÿæˆç‰¹å®šé£æ ¼æˆ–åŒ…å«ä½ æ‰€æƒ³è¦çš„å†…å®¹çš„å›¾åƒå¯èƒ½ä¼šæœ‰äº›æ£˜æ‰‹ã€‚ é€šå¸¸æƒ…å†µä¸‹ï¼Œä½ éœ€è¦å¤šæ¬¡è¿è¡Œ [`DiffusionPipeline`] æ‰èƒ½å¾—åˆ°æ»¡æ„çš„å›¾åƒã€‚ä½†æ˜¯ä»æ— åˆ°æœ‰ç”Ÿæˆå›¾åƒæ˜¯ä¸€ä¸ªè®¡ç®—å¯†é›†çš„è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯å¦‚æœä½ è¦ä¸€éåˆä¸€éåœ°è¿›è¡Œæ¨ç†è¿ç®—ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»pipelineä¸­è·å¾—æœ€é«˜çš„ *computational* (speed) å’Œ *memory* (GPU RAM) éå¸¸é‡è¦ ï¼Œä»¥å‡å°‘æ¨ç†å‘¨æœŸä¹‹é—´çš„æ—¶é—´ï¼Œä»è€Œä½¿è¿­ä»£é€Ÿåº¦æ›´å¿«ã€‚


æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨å¦‚ä½•é€šè¿‡ [`DiffusionPipeline`]  æ›´å¿«ã€æ›´å¥½åœ°ç”Ÿæˆå›¾åƒã€‚


é¦–å…ˆï¼ŒåŠ è½½ [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5) æ¨¡å‹:

```python
from diffusers import DiffusionPipeline

model_id = "runwayml/stable-diffusion-v1-5"
pipeline = DiffusionPipeline.from_pretrained(model_id, use_safetensors=True)
```

æœ¬æ•™ç¨‹å°†ä½¿ç”¨çš„æç¤ºè¯æ˜¯ [`portrait photo of a old warrior chief`] ï¼Œä½†æ˜¯ä½ å¯ä»¥éšå¿ƒæ‰€æ¬²çš„æƒ³è±¡å’Œæ„é€ è‡ªå·±çš„æç¤ºè¯ï¼š

```python
prompt = "portrait photo of a old warrior chief"
```

## é€Ÿåº¦

<Tip>

ğŸ’¡ å¦‚æœä½ æ²¡æœ‰ GPU, ä½ å¯ä»¥ä»åƒ [Colab](https://colab.research.google.com/) è¿™æ ·çš„ GPU æä¾›å•†è·å–å…è´¹çš„ GPU !

</Tip>

åŠ é€Ÿæ¨ç†çš„æœ€ç®€å•æ–¹æ³•ä¹‹ä¸€æ˜¯å°† pipeline æ”¾åœ¨ GPU ä¸Š ï¼Œå°±åƒä½¿ç”¨ä»»ä½• PyTorch æ¨¡å—ä¸€æ ·ï¼š

```python
pipeline = pipeline.to("cuda")
```

ä¸ºäº†ç¡®ä¿æ‚¨å¯ä»¥ä½¿ç”¨ç›¸åŒçš„å›¾åƒå¹¶å¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œä½¿ç”¨ [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html) æ–¹æ³•ï¼Œç„¶åè®¾ç½®ä¸€ä¸ªéšæœºæ•°ç§å­ ä»¥ç¡®ä¿å…¶ [å¤ç°æ€§](./using-diffusers/reproducibility):

```python
import torch

generator = torch.Generator("cuda").manual_seed(0)
```

ç°åœ¨ï¼Œä½ å¯ä»¥ç”Ÿæˆä¸€ä¸ªå›¾åƒï¼š

```python
image = pipeline(prompt, generator=generator).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_1.png">
</div>

åœ¨ T4 GPU ä¸Šï¼Œè¿™ä¸ªè¿‡ç¨‹å¤§æ¦‚è¦30ç§’ï¼ˆå¦‚æœä½ çš„ GPU æ¯” T4 å¥½ï¼Œå¯èƒ½ä¼šæ›´å¿«ï¼‰ã€‚åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œ[`DiffusionPipeline`] ä½¿ç”¨å®Œæ•´çš„ `float32` ç²¾åº¦è¿›è¡Œ 50 æ­¥æ¨ç†ã€‚ä½ å¯ä»¥é€šè¿‡é™ä½ç²¾åº¦ï¼ˆå¦‚ `float16` ï¼‰æˆ–è€…å‡å°‘æ¨ç†æ­¥æ•°æ¥åŠ é€Ÿæ•´ä¸ªè¿‡ç¨‹


è®©æˆ‘ä»¬æŠŠæ¨¡å‹çš„ç²¾åº¦é™ä½è‡³ `float16` ï¼Œç„¶åç”Ÿæˆä¸€å¼ å›¾åƒï¼š

```python
import torch

pipeline = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True)
pipeline = pipeline.to("cuda")
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_2.png">
</div>

è¿™ä¸€æ¬¡ï¼Œç”Ÿæˆå›¾åƒåªèŠ±äº†çº¦ 11 ç§’ï¼Œæ¯”ä¹‹å‰å¿«äº†è¿‘ 3 å€ï¼

<Tip>

ğŸ’¡ æˆ‘ä»¬å¼ºçƒˆå»ºè®®æŠŠ pipeline ç²¾åº¦é™ä½è‡³ `float16` , åˆ°ç›®å‰ä¸ºæ­¢, æˆ‘ä»¬å¾ˆå°‘çœ‹åˆ°è¾“å‡ºè´¨é‡æœ‰ä»»ä½•ä¸‹é™ã€‚

</Tip>

å¦ä¸€ä¸ªé€‰æ‹©æ˜¯å‡å°‘æ¨ç†æ­¥æ•°ã€‚ ä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªæ›´é«˜æ•ˆçš„è°ƒåº¦å™¨ (*scheduler*) å¯ä»¥å‡å°‘æ¨ç†æ­¥æ•°åŒæ—¶ä¿è¯è¾“å‡ºè´¨é‡ã€‚æ‚¨å¯ä»¥åœ¨ [DiffusionPipeline] ä¸­é€šè¿‡è°ƒç”¨compatiblesæ–¹æ³•æ‰¾åˆ°ä¸å½“å‰æ¨¡å‹å…¼å®¹çš„è°ƒåº¦å™¨ (*scheduler*)ã€‚ 

```python
pipeline.scheduler.compatibles
[
    diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,
    diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,
    diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,
    diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,
    diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,
    diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,
    diffusers.schedulers.scheduling_ddpm.DDPMScheduler,
    diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,
    diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,
    diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,
    diffusers.schedulers.scheduling_pndm.PNDMScheduler,
    diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,
    diffusers.schedulers.scheduling_ddim.DDIMScheduler,
]
```

Stable Diffusion æ¨¡å‹é»˜è®¤ä½¿ç”¨çš„æ˜¯ [`PNDMScheduler`] ï¼Œé€šå¸¸è¦å¤§æ¦‚50æ­¥æ¨ç†, ä½†æ˜¯åƒ [`DPMSolverMultistepScheduler`] è¿™æ ·æ›´é«˜æ•ˆçš„è°ƒåº¦å™¨åªè¦å¤§æ¦‚ 20 æˆ– 25 æ­¥æ¨ç†. ä½¿ç”¨ [`ConfigMixin.from_config`] æ–¹æ³•åŠ è½½æ–°çš„è°ƒåº¦å™¨:

```python
from diffusers import DPMSolverMultistepScheduler

pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)
```

ç°åœ¨å°† `num_inference_steps` è®¾ç½®ä¸º 20:

```python
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator, num_inference_steps=20).images[0]
image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_3.png">
</div>

å¤ªæ£’äº†ï¼ä½ æˆåŠŸæŠŠæ¨ç†æ—¶é—´ç¼©çŸ­åˆ° 4 ç§’ï¼âš¡ï¸

## å†…å­˜

æ”¹å–„ pipeline æ€§èƒ½çš„å¦ä¸€ä¸ªå…³é”®æ˜¯å‡å°‘å†…å­˜çš„ä½¿ç”¨é‡ï¼Œè¿™é—´æ¥æ„å‘³ç€é€Ÿåº¦æ›´å¿«ï¼Œå› ä¸ºä½ ç»å¸¸è¯•å›¾æœ€å¤§åŒ–æ¯ç§’ç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚è¦æƒ³çŸ¥é“ä½ ä¸€æ¬¡å¯ä»¥ç”Ÿæˆå¤šå°‘å¼ å›¾ç‰‡ï¼Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯å°è¯•ä¸åŒçš„batch sizeï¼Œç›´åˆ°å‡ºç°`OutOfMemoryError` (OOM)ã€‚

åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä¸ºæ¯ä¸€æ‰¹è¦ç”Ÿæˆçš„å›¾åƒåˆ†é…æç¤ºè¯å’Œ `Generators` ã€‚è¯·åŠ¡å¿…ä¸ºæ¯ä¸ª`Generator` åˆ†é…ä¸€ä¸ªç§å­ï¼Œä»¥ä¾¿äºå¤ç°è‰¯å¥½çš„ç»“æœã€‚


```python
def get_inputs(batch_size=1):
    generator = [torch.Generator("cuda").manual_seed(i) for i in range(batch_size)]
    prompts = batch_size * [prompt]
    num_inference_steps = 20

    return {"prompt": prompts, "generator": generator, "num_inference_steps": num_inference_steps}
```

è®¾ç½® `batch_size=4` ï¼Œç„¶åçœ‹ä¸€çœ‹æˆ‘ä»¬æ¶ˆè€—äº†å¤šå°‘å†…å­˜:

```python
from diffusers.utils import make_image_grid 

images = pipeline(**get_inputs(batch_size=4)).images
make_image_grid(images, 2, 2)
```

é™¤éä½ æœ‰ä¸€ä¸ªæ›´å¤§å†…å­˜çš„GPU, å¦åˆ™ä¸Šè¿°ä»£ç ä¼šè¿”å› `OOM` é”™è¯¯! å¤§éƒ¨åˆ†å†…å­˜è¢« cross-attention å±‚ä½¿ç”¨ã€‚æŒ‰é¡ºåºè¿è¡Œå¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ï¼Œè€Œä¸æ˜¯åœ¨æ‰¹å¤„ç†ä¸­è¿›è¡Œã€‚ä½ å¯ä»¥ä¸º pipeline é…ç½® [`~DiffusionPipeline.enable_attention_slicing`] å‡½æ•°:

```python
pipeline.enable_attention_slicing()
```

ç°åœ¨å°è¯•æŠŠ `batch_size` å¢åŠ åˆ° 8!

```python
images = pipeline(**get_inputs(batch_size=8)).images
make_image_grid(images, rows=2, cols=4)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_5.png">
</div>

ä»¥å‰ä½ ä¸èƒ½ä¸€æ‰¹ç”Ÿæˆ 4 å¼ å›¾ç‰‡ï¼Œè€Œç°åœ¨ä½ å¯ä»¥åœ¨ä¸€å¼ å›¾ç‰‡é‡Œé¢ç”Ÿæˆå…«å¼ å›¾ç‰‡è€Œåªéœ€è¦å¤§æ¦‚3.5ç§’ï¼è¿™å¯èƒ½æ˜¯ T4 GPU åœ¨ä¸ç‰ºç‰²è´¨é‡çš„æƒ…å†µè¿è¡Œé€Ÿåº¦æœ€å¿«çš„ä¸€ç§æ–¹æ³•ã€‚

## è´¨é‡

åœ¨æœ€åä¸¤èŠ‚ä¸­, ä½ è¦å­¦ä¹ å¦‚ä½•é€šè¿‡ `fp16` æ¥ä¼˜åŒ– pipeline çš„é€Ÿåº¦, é€šè¿‡ä½¿ç”¨æ€§èƒ½æ›´é«˜çš„è°ƒåº¦å™¨æ¥å‡å°‘æ¨ç†æ­¥æ•°, ä½¿ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ï¼ˆ*enabling attention slicing*ï¼‰æ–¹æ³•æ¥èŠ‚çœå†…å­˜ã€‚ç°åœ¨ï¼Œä½ å°†å…³æ³¨çš„æ˜¯å¦‚ä½•æé«˜å›¾åƒçš„è´¨é‡ã€‚

### æ›´å¥½çš„ checkpoints

æœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„æ–¹æ³•æ˜¯ä½¿ç”¨æ›´å¥½çš„ checkpointsã€‚ Stable Diffusion æ¨¡å‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹, è‡ªæ­£å¼å‘å¸ƒä»¥æ¥ï¼Œè¿˜å‘å¸ƒäº†å‡ ä¸ªæ”¹è¿›ç‰ˆæœ¬ã€‚ç„¶è€Œ, ä½¿ç”¨æ›´æ–°çš„ç‰ˆæœ¬å¹¶ä¸æ„å‘³ç€ä½ ä¼šå¾—åˆ°æ›´å¥½çš„ç»“æœã€‚ä½ ä»ç„¶éœ€è¦å°è¯•ä¸åŒçš„ checkpoints ï¼Œå¹¶åšä¸€äº›ç ”ç©¶ (ä¾‹å¦‚ä½¿ç”¨ [negative prompts](https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/)) æ¥è·å¾—æ›´å¥½çš„ç»“æœã€‚

éšç€è¯¥é¢†åŸŸçš„å‘å±•, æœ‰è¶Šæ¥è¶Šå¤šç»è¿‡å¾®è°ƒçš„é«˜è´¨é‡çš„ checkpoints ç”¨æ¥ç”Ÿæˆä¸ä¸€æ ·çš„é£æ ¼. åœ¨ [Hub](https://huggingface.co/models?library=diffusers&sort=downloads) å’Œ [Diffusers Gallery](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery) å¯»æ‰¾ä½ æ„Ÿå…´è¶£çš„ä¸€ç§!

### æ›´å¥½çš„ pipeline ç»„ä»¶

ä¹Ÿå¯ä»¥å°è¯•ç”¨æ–°ç‰ˆæœ¬æ›¿æ¢å½“å‰ pipeline ç»„ä»¶ã€‚è®©æˆ‘ä»¬åŠ è½½æœ€æ–°çš„ [autodecoder](https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main/vae) ä» Stability AI åŠ è½½åˆ° pipeline, å¹¶ç”Ÿæˆä¸€äº›å›¾åƒ:

```python
from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float16).to("cuda")
pipeline.vae = vae
images = pipeline(**get_inputs(batch_size=8)).images
make_image_grid(images, rows=2, cols=4)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_6.png">
</div>

### æ›´å¥½çš„æç¤ºè¯å·¥ç¨‹

ç”¨äºç”Ÿæˆå›¾åƒçš„æ–‡æœ¬éå¸¸é‡è¦, å› æ­¤è¢«ç§°ä¸º *æç¤ºè¯å·¥ç¨‹*ã€‚ åœ¨è®¾è®¡æç¤ºè¯å·¥ç¨‹åº”æ³¨æ„å¦‚ä¸‹äº‹é¡¹:

- æˆ‘æƒ³ç”Ÿæˆçš„å›¾åƒæˆ–ç±»ä¼¼å›¾åƒå¦‚ä½•å­˜å‚¨åœ¨äº’è”ç½‘ä¸Šï¼Ÿ
- æˆ‘å¯ä»¥æä¾›å“ªäº›é¢å¤–çš„ç»†èŠ‚æ¥å¼•å¯¼æ¨¡å‹æœç€æˆ‘æƒ³è¦çš„é£æ ¼ç”Ÿæˆï¼Ÿ

è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ”¹è¿›æç¤ºè¯ï¼Œä»¥åŒ…å«é¢œè‰²å’Œæ›´é«˜è´¨é‡çš„ç»†èŠ‚ï¼š

```python
prompt += ", tribal panther make up, blue on red, side profile, looking away, serious eyes"
prompt += " 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta"
```

ä½¿ç”¨æ–°çš„æç¤ºè¯ç”Ÿæˆä¸€æ‰¹å›¾åƒ:

```python
images = pipeline(**get_inputs(batch_size=8)).images
make_image_grid(images, rows=2, cols=4)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_7.png">
</div>

éå¸¸çš„ä»¤äººå°è±¡æ·±åˆ»! Let's tweak the second image - æŠŠ `Generator` çš„ç§å­è®¾ç½®ä¸º `1` - æ·»åŠ ä¸€äº›å…³äºå¹´é¾„çš„ä¸»é¢˜æ–‡æœ¬:

```python
prompts = [
    "portrait photo of the oldest warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a old warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a young warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
]

generator = [torch.Generator("cuda").manual_seed(1) for _ in range(len(prompts))]
images = pipeline(prompt=prompts, generator=generator, num_inference_steps=25).images
make_image_grid(images, 2, 2)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_8.png">
</div>

## æœ€å

åœ¨æœ¬æ•™ç¨‹ä¸­, æ‚¨å­¦ä¹ äº†å¦‚ä½•ä¼˜åŒ–[`DiffusionPipeline`]ä»¥æé«˜è®¡ç®—å’Œå†…å­˜æ•ˆç‡ï¼Œä»¥åŠæé«˜ç”Ÿæˆè¾“å‡ºçš„è´¨é‡. å¦‚æœä½ æœ‰å…´è¶£è®©ä½ çš„ pipeline æ›´å¿«, å¯ä»¥çœ‹ä¸€çœ‹ä»¥ä¸‹èµ„æº:

- å­¦ä¹  [PyTorch 2.0](./optimization/torch2.0) å’Œ [`torch.compile`](https://pytorch.org/docs/stable/generated/torch.compile.html) å¯ä»¥è®©æ¨ç†é€Ÿåº¦æé«˜ 5 - 300% . åœ¨ A100 GPU ä¸Š, æ¨ç†é€Ÿåº¦å¯ä»¥æé«˜ 50% !
- å¦‚æœä½ æ²¡æ³•ç”¨ PyTorch 2, æˆ‘ä»¬å»ºè®®ä½ å®‰è£… [xFormers](./optimization/xformers)ã€‚å®ƒçš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ï¼ˆ*memory-efficient attention mechanism*ï¼‰ä¸PyTorch 1.13.1é…åˆä½¿ç”¨ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œå†…å­˜æ¶ˆè€—æ›´å°‘ã€‚
- å…¶ä»–çš„ä¼˜åŒ–æŠ€æœ¯, å¦‚ï¼šæ¨¡å‹å¸è½½ï¼ˆ*model offloading*ï¼‰, åŒ…å«åœ¨ [è¿™ä»½æŒ‡å—](./optimization/fp16).
