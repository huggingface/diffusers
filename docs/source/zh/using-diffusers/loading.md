# åŠ è½½æµç¨‹ç®¡é“

[[åœ¨Colabä¸­æ‰“å¼€]]

æ‰©æ•£ç³»ç»Ÿç”±å‚æ•°åŒ–æ¨¡å‹å’Œè°ƒåº¦å™¨ç­‰å¤šä¸ªç»„ä»¶ç»„æˆï¼Œè¿™äº›ç»„ä»¶ä»¥å¤æ‚çš„æ–¹å¼äº¤äº’ã€‚ä¸ºæ­¤æˆ‘ä»¬è®¾è®¡äº†[`DiffusionPipeline`]ï¼Œå°†æ•´ä¸ªæ‰©æ•£ç³»ç»Ÿçš„å¤æ‚æ€§å°è£…æˆç®€å•æ˜“ç”¨çš„APIã€‚åŒæ—¶[`DiffusionPipeline`]å®Œå…¨å¯å®šåˆ¶ï¼Œæ‚¨å¯ä»¥ä¿®æ”¹æ¯ä¸ªç»„ä»¶æ¥æ„å»ºé€‚åˆè‡ªå·±éœ€æ±‚çš„æ‰©æ•£ç³»ç»Ÿã€‚

æœ¬æŒ‡å—å°†å±•ç¤ºå¦‚ä½•åŠ è½½ï¼š
- ä»Hubå’Œæœ¬åœ°åŠ è½½æµç¨‹ç®¡é“
- å°†ä¸åŒç»„ä»¶åŠ è½½åˆ°æµç¨‹ç®¡é“ä¸­
- åœ¨ä¸å¢åŠ å†…å­˜ä½¿ç”¨çš„æƒ…å†µä¸‹åŠ è½½å¤šä¸ªæµç¨‹ç®¡é“
- æ£€æŸ¥ç‚¹å˜ä½“ï¼Œå¦‚ä¸åŒçš„æµ®ç‚¹ç±»å‹æˆ–éæŒ‡æ•°ç§»åŠ¨å¹³å‡(EMA)æƒé‡

## åŠ è½½æµç¨‹ç®¡é“

> [!TIP]
> å¦‚æœæ‚¨å¯¹[`DiffusionPipeline`]ç±»çš„å·¥ä½œåŸç†æ„Ÿå…´è¶£ï¼Œå¯ç›´æ¥è·³è½¬åˆ°[DiffusionPipelineè¯¦è§£](#diffusionpipeline-explained)éƒ¨åˆ†ã€‚

åŠ è½½ä»»åŠ¡æµç¨‹ç®¡é“æœ‰ä¸¤ç§æ–¹å¼ï¼š
1. åŠ è½½é€šç”¨çš„[`DiffusionPipeline`]ç±»ï¼Œè®©å®ƒè‡ªåŠ¨ä»æ£€æŸ¥ç‚¹æ£€æµ‹æ­£ç¡®çš„æµç¨‹ç®¡é“ç±»
2. ä¸ºç‰¹å®šä»»åŠ¡åŠ è½½ç‰¹å®šçš„æµç¨‹ç®¡é“ç±»

<hfoptions id="pipelines">
<hfoption id="é€šç”¨æµç¨‹ç®¡é“">

[`DiffusionPipeline`]ç±»æ˜¯ä»[Hub](https://huggingface.co/models?library=diffusers&sort=trending)åŠ è½½æœ€æ–°çƒ­é—¨æ‰©æ•£æ¨¡å‹çš„ç®€å•é€šç”¨æ–¹æ³•ã€‚å®ƒä½¿ç”¨[`~DiffusionPipeline.from_pretrained`]æ–¹æ³•è‡ªåŠ¨ä»æ£€æŸ¥ç‚¹æ£€æµ‹ä»»åŠ¡çš„æ­£ç¡®æµç¨‹ç®¡é“ç±»ï¼Œä¸‹è½½å¹¶ç¼“å­˜æ‰€æœ‰éœ€è¦çš„é…ç½®å’Œæƒé‡æ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ªå¯ç”¨äºæ¨ç†çš„æµç¨‹ç®¡é“ã€‚

```python
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", use_safetensors=True)
```

åŒæ ·çš„æ£€æŸ¥ç‚¹ä¹Ÿå¯ä»¥ç”¨äºå›¾åƒåˆ°å›¾åƒä»»åŠ¡ã€‚[`DiffusionPipeline`]ç±»å¯ä»¥å¤„ç†ä»»ä½•ä»»åŠ¡ï¼Œåªè¦æ‚¨æä¾›é€‚å½“çš„è¾“å…¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºå›¾åƒåˆ°å›¾åƒä»»åŠ¡ï¼Œæ‚¨éœ€è¦å‘æµç¨‹ç®¡é“ä¼ é€’åˆå§‹å›¾åƒã€‚

```py
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", use_safetensors=True)

init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png")
prompt = "ä¸›æ—ä¸­çš„å®‡èˆªå‘˜ï¼Œå½©è‰²"
```
ä»¥ä¸‹æ˜¯æ‚¨æä¾›çš„è‹±æ–‡å†…å®¹çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä¿æŒDiffusersã€stable_diffusionã€consisidç­‰ä¸“æœ‰åè¯ä¸è¯‘ï¼Œå¹¶ä¿ç•™Markdownæ ¼å¼ï¼š

---

### ç‰¹å®šä»»åŠ¡ç®¡é“

è‹¥å·²çŸ¥æ¨¡å‹å¯¹åº”çš„å…·ä½“ç®¡é“ç±»ï¼Œå¯ç›´æ¥é€šè¿‡è¯¥ç±»åŠ è½½æ£€æŸ¥ç‚¹ã€‚ä¾‹å¦‚åŠ è½½Stable Diffusionæ¨¡å‹æ—¶ï¼Œä½¿ç”¨[`StableDiffusionPipeline`]ç±»ï¼š

```python
from diffusers import StableDiffusionPipeline

pipeline = StableDiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", use_safetensors=True)
```

åŒä¸€æ£€æŸ¥ç‚¹ä¹Ÿå¯ç”¨äºå…¶ä»–ä»»åŠ¡ï¼ˆå¦‚å›¾åƒåˆ°å›¾åƒç”Ÿæˆï¼‰ã€‚æ­¤æ—¶éœ€æ”¹ç”¨å¯¹åº”ä»»åŠ¡çš„ç®¡é“ç±»ï¼Œä¾‹å¦‚ä½¿ç”¨[`StableDiffusionImg2ImgPipeline`]åŠ è½½ç›¸åŒæ£€æŸ¥ç‚¹ï¼š

```python
from diffusers import StableDiffusionImg2ImgPipeline

pipeline = StableDiffusionImg2ImgPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", use_safetensors=True)
```

---

### ç»„ä»¶çº§æ•°æ®ç±»å‹æŒ‡å®š

é€šè¿‡å‘`torch_dtype`å‚æ•°ä¼ é€’å­—å…¸ï¼Œå¯ä¸ºä¸åŒå­æ¨¡å‹å®šåˆ¶æ•°æ®ç±»å‹ã€‚ä¾‹å¦‚ä»¥`torch.bfloat16`ç²¾åº¦åŠ è½½transformerç»„ä»¶ï¼Œå…¶ä»–ç»„ä»¶é»˜è®¤ä½¿ç”¨`torch.float16`ï¼š

```python
from diffusers import HunyuanVideoPipeline
import torch

pipe = HunyuanVideoPipeline.from_pretrained(
    "hunyuanvideo-community/HunyuanVideo",
    torch_dtype={"transformer": torch.bfloat16, "default": torch.float16},
)
print(pipe.transformer.dtype, pipe.vae.dtype)  # è¾“å‡º: (torch.bfloat16, torch.float16)
```

è‹¥ç»„ä»¶æœªåœ¨å­—å…¸ä¸­æ˜¾å¼æŒ‡å®šä¸”æœªè®¾ç½®`default`ï¼Œå°†é»˜è®¤åŠ è½½ä¸º`torch.float32`ã€‚

---

### æœ¬åœ°ç®¡é“åŠ è½½

ä½¿ç”¨[git-lfs](https://git-lfs.github.com/)æ‰‹åŠ¨ä¸‹è½½æ£€æŸ¥ç‚¹åˆ°æœ¬åœ°ååŠ è½½ï¼š

```bash
git-lfs install
git clone https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5
```

ä¸‹è½½å®Œæˆåï¼Œå°†æœ¬åœ°è·¯å¾„ï¼ˆå¦‚`./stable-diffusion-v1-5`ï¼‰ä¼ é€’ç»™[`~DiffusionPipeline.from_pretrained`]ï¼š

```python
from diffusers import DiffusionPipeline

stable_diffusion = DiffusionPipeline.from_pretrained("./stable-diffusion-v1-5", use_safetensors=True)
```

---

### å†…å­˜éœ€æ±‚è¯„ä¼°å·¥å…·

åœ¨ä¸‹è½½å‰ï¼Œå¯é€šè¿‡ä¸‹æ–¹ç©ºé—´è¯„ä¼°ç®¡é“å†…å­˜éœ€æ±‚ä»¥ç¡®è®¤ç¡¬ä»¶å…¼å®¹æ€§ï¼š

<div class="block dark:hidden">
	<iframe
        src="https://diffusers-compute-pipeline-size.hf.space?__theme=light"
        width="850"
        height="1600"
    ></iframe>
</div>
<div class="hidden dark:block">
    <iframe
        src="https://diffusers-compute-pipeline-size.hf.space?__theme=dark"
        width="850"
        height="1600"
    ></iframe>
</div>
### è‡ªå®šä¹‰ç®¡é“

æ‚¨å¯ä»¥é€šè¿‡å‘ç®¡é“ä¸­åŠ è½½ä¸åŒçš„ç»„ä»¶æ¥å®ç°å®šåˆ¶åŒ–ã€‚è¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºæ‚¨å¯ä»¥ï¼š

- æ ¹æ®éœ€æ±‚åˆ‡æ¢ä¸ºç”Ÿæˆé€Ÿåº¦æ›´å¿«æˆ–ç”Ÿæˆè´¨é‡æ›´é«˜çš„è°ƒåº¦å™¨ï¼ˆé€šè¿‡è°ƒç”¨ç®¡é“ä¸Šçš„`scheduler.compatibles`æ–¹æ³•æŸ¥çœ‹å…¼å®¹çš„è°ƒåº¦å™¨ï¼‰
- å°†é»˜è®¤ç®¡é“ç»„ä»¶æ›¿æ¢ä¸ºæ›´æ–°ä¸”æ€§èƒ½æ›´ä¼˜çš„ç‰ˆæœ¬

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ç”¨ä»¥ä¸‹ç»„ä»¶å®šåˆ¶é»˜è®¤çš„[stabilityai/stable-diffusion-xl-base-1.0](https://hf.co/stabilityai/stable-diffusion-xl-base-1.0)æ¨¡å‹ï¼š

- ä½¿ç”¨[`HeunDiscreteScheduler`]ä»¥ç‰ºç‰²ç”Ÿæˆé€Ÿåº¦ä¸ºä»£ä»·æ¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒã€‚å¿…é¡»ä¼ å…¥`subfolder="scheduler"`å‚æ•°åˆ°[`~HeunDiscreteScheduler.from_pretrained`]ï¼Œä»¥ä¾¿ä»ç®¡é“ä»“åº“çš„æ­£ç¡®[å­æ–‡ä»¶å¤¹](https://hf.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main/scheduler)åŠ è½½è°ƒåº¦å™¨é…ç½®ã€‚
- ä½¿ç”¨åœ¨fp16æ¨¡å¼ä¸‹è¿è¡Œæ›´ç¨³å®šçš„VAEã€‚

```python
from diffusers import StableDiffusionXLPipeline, HeunDiscreteScheduler, AutoencoderKL
import torch

scheduler = HeunDiscreteScheduler.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", subfolder="scheduler")
vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16, use_safetensors=True)
```

ç°åœ¨å°†æ–°çš„è°ƒåº¦å™¨å’ŒVAEä¼ å…¥[`StableDiffusionXLPipeline`]ï¼š

```python
pipeline = StableDiffusionXLPipeline.from_pretrained(
  "stabilityai/stable-diffusion-xl-base-1.0",
  scheduler=scheduler,
  vae=vae,
  torch_dtype=torch.float16,
  variant="fp16",
  use_safetensors=True
).to("cuda")
```

### å¤ç”¨ç®¡é“

å½“æ‚¨åŠ è½½å¤šä¸ªå…±äº«ç›¸åŒæ¨¡å‹ç»„ä»¶çš„ç®¡é“æ—¶ï¼Œå¤ç”¨è¿™äº›å…±äº«ç»„ä»¶æ¯”é‡æ–°å°†æ‰€æœ‰å†…å®¹åŠ è½½åˆ°å†…å­˜ä¸­æ›´æœ‰æ„ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨ç¡¬ä»¶å†…å­˜å—é™çš„æƒ…å†µä¸‹ã€‚ä¾‹å¦‚ï¼š

1. æ‚¨ä½¿ç”¨[`StableDiffusionPipeline`]ç”Ÿæˆäº†ä¸€å¼ å›¾åƒï¼Œä½†æƒ³é€šè¿‡[`StableDiffusionSAGPipeline`]æå‡å…¶è´¨é‡ã€‚è¿™ä¸¤ä¸ªç®¡é“å…±äº«ç›¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå› æ­¤åŠ è½½ä¸¤æ¬¡ä¼šæµªè´¹å†…å­˜ã€‚
2. æ‚¨æƒ³å‘ä»ç°æœ‰[`StableDiffusionPipeline`]å®ä¾‹åŒ–çš„[`AnimateDiffPipeline`]ä¸­æ·»åŠ ä¸€ä¸ªæ¨¡å‹ç»„ä»¶ï¼ˆå¦‚[`MotionAdapter`](../api/pipelines/animatediff#animatediffpipeline)ï¼‰ã€‚åŒæ ·ï¼Œè¿™ä¸¤ä¸ªç®¡é“å…±äº«ç›¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŠ è½½å…¨æ–°ç®¡é“ä¼šæµªè´¹å†…å­˜ã€‚

é€šè¿‡[`DiffusionPipeline.from_pipe`] APIï¼Œæ‚¨å¯ä»¥åœ¨å¤šä¸ªç®¡é“ä¹‹é—´åˆ‡æ¢ï¼Œåˆ©ç”¨å®ƒä»¬çš„ä¸åŒç‰¹æ€§è€Œä¸ä¼šå¢åŠ å†…å­˜ä½¿ç”¨ã€‚è¿™ç±»ä¼¼äºåœ¨ç®¡é“ä¸­å¼€å¯æˆ–å…³é—­æŸä¸ªåŠŸèƒ½ã€‚

> [!æç¤º]
> è‹¥è¦åœ¨ä¸åŒä»»åŠ¡ï¼ˆè€ŒéåŠŸèƒ½ï¼‰ä¹‹é—´åˆ‡æ¢ï¼Œè¯·ä½¿ç”¨[`~DiffusionPipeline`]æ–¹æ³•ã€‚
ä»¥ä¸‹æ˜¯æ‚¨æä¾›çš„è‹±æ–‡å†…å®¹çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä¿æŒDiffusersã€stable_diffusionã€consisidç­‰ä¸“æœ‰åè¯ä¸å˜ï¼Œå¹¶ä¿ç•™Markdownæ ¼å¼ï¼š

ï¼ˆæ­¤ä¸ºæ–‡æ¡£10éƒ¨åˆ†ä¸­çš„ç¬¬4éƒ¨åˆ†ï¼‰

ä½¿ç”¨[`AutoPipeline`](../api/pipelines/auto_pipeline)ç±»çš„[`~DiffusionPipeline.from_pipe`]æ–¹æ³•å¯ä»¥è‡ªåŠ¨æ ¹æ®ä»»åŠ¡è¯†åˆ«ç®¡é“ç±»åˆ«ï¼ˆæ›´å¤šç»†èŠ‚è¯·å‚é˜…[AutoPipelineæ•™ç¨‹](../tutorials/autopipeline)ï¼‰ã€‚

è®©æˆ‘ä»¬ä»[`StableDiffusionPipeline`]å¼€å§‹ï¼Œç„¶åå¤ç”¨å·²åŠ è½½çš„æ¨¡å‹ç»„ä»¶åˆ›å»º[`StableDiffusionSAGPipeline`]æ¥æå‡ç”Ÿæˆè´¨é‡ã€‚æ‚¨å°†ä½¿ç”¨æ­è½½[IP-Adapter](./ip_adapter)çš„[`StableDiffusionPipeline`]ç”Ÿæˆä¸€å¼ ç†ŠåƒæŠ«è¨çš„å›¾ç‰‡ã€‚

```python
from diffusers import DiffusionPipeline, StableDiffusionSAGPipeline
import torch
import gc
from diffusers.utils import load_image
from accelerate.utils import compute_module_sizes

image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_neg_embed.png")

pipe_sd = DiffusionPipeline.from_pretrained("SG161222/Realistic_Vision_V6.0_B1_noVAE", torch_dtype=torch.float16)
pipe_sd.load_ip_adapter("h94/IP-Adapter", subfolder="models", weight_name="ip-adapter_sd15.bin")
pipe_sd.set_ip_adapter_scale(0.6)
pipe_sd.to("cuda")

generator = torch.Generator(device="cpu").manual_seed(33)
out_sd = pipe_sd(
    prompt="ç†ŠåƒæŠ«è¨",
    negative_prompt="ç™½å¹³è¡¡é”™è¯¯, æ˜æš—, è‰å›¾, æœ€å·®è´¨é‡, ä½è´¨é‡",
    ip_adapter_image=image,
    num_inference_steps=50,
    generator=generator,
).images[0]
out_sd
```

<div class="flex justify-center">
  <img class="rounded-xl" src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/from_pipe_out_sd_0.png"/>
</div>

ä½œä¸ºå‚è€ƒï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æ­¤è¿‡ç¨‹æ¶ˆè€—çš„å†…å­˜æƒ…å†µã€‚

```python
def bytes_to_giga_bytes(bytes):
    return bytes / 1024 / 1024 / 1024
print(f"æœ€å¤§å†…å­˜å ç”¨: {bytes_to_giga_bytes(torch.cuda.max_memory_allocated())} GB")
"æœ€å¤§å†…å­˜å ç”¨: 4.406213283538818 GB"
```

ç°åœ¨é€šè¿‡[`~DiffusionPipeline.from_pipe`]æ–¹æ³•ï¼Œå°†[`StableDiffusionPipeline`]ä¸­çš„ç®¡é“ç»„ä»¶å¤ç”¨åˆ°[`StableDiffusionSAGPipeline`]ä¸­ã€‚

> [!è­¦å‘Š]
> æŸäº›ç®¡é“æ–¹æ³•åœ¨é€šè¿‡[`~DiffusionPipeline.from_pipe`]åˆ›å»ºçš„æ–°ç®¡é“ä¸Šå¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚ä¾‹å¦‚[`~DiffusionPipeline.enable_model_cpu_offload`]æ–¹æ³•ä¼šæ ¹æ®æ¯ä¸ªç®¡é“ç‹¬ç‰¹çš„å¸è½½åºåˆ—åœ¨æ¨¡å‹ç»„ä»¶ä¸Šå®‰è£…é’©å­ã€‚å¦‚æœæ–°ç®¡é“ä¸­æ¨¡å‹æ‰§è¡Œé¡ºåºä¸åŒï¼ŒCPUå¸è½½å¯èƒ½æ— æ³•æ­£ç¡®å·¥ä½œã€‚
>
> ä¸ºç¡®ä¿åŠŸèƒ½æ­£å¸¸ï¼Œæˆ‘ä»¬å»ºè®®å¯¹é€šè¿‡[`~DiffusionPipeline.from_pipe`]åˆ›å»ºçš„æ–°ç®¡é“é‡æ–°åº”ç”¨ç®¡é“æ–¹æ³•ã€‚

```python
pipe_sag = StableDiffusionSAGPipeline.from_pipe(
    pipe_sd
)

generator = torch.Generator(device="cpu").manual_seed(33)
out_sag = pipe_sag(
    prompt="ç†ŠåƒæŠ«è¨",
    negative_prompt="ç™½å¹³è¡¡é”™è¯¯, æ˜æš—, è‰å›¾, æœ€å·®è´¨é‡, ä½è´¨é‡",
    ip_adapter_image=image,
    num_inference_steps=50,
    generator=generator,
    guidance_scale=1.0,
    sag_scale=0.75
).images[0]
out_sag
```

<div class="flex justify-center">
  <!-- å›¾ç‰‡å°†åœ¨æ­¤å¤„æ˜¾ç¤º -->
</div>
<div class="flex justify-center">
  <img class="rounded-xl" src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/from_pipe_out_sag_1.png"/>
</div>

å¦‚æœæ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œä¼šå‘ç°ä¸ä¹‹å‰ä¿æŒä¸€è‡´ï¼Œå› ä¸º [`StableDiffusionPipeline`] å’Œ [`StableDiffusionSAGPipeline`] å…±äº«ç›¸åŒçš„ç®¡é“ç»„ä»¶ã€‚è¿™ä½¿å¾—æ‚¨å¯ä»¥äº’æ¢ä½¿ç”¨å®ƒä»¬ï¼Œè€Œæ— éœ€é¢å¤–çš„å†…å­˜å¼€é”€ã€‚

```py
print(f"æœ€å¤§å†…å­˜åˆ†é…é‡: {bytes_to_giga_bytes(torch.cuda.max_memory_allocated())} GB")
"æœ€å¤§å†…å­˜åˆ†é…é‡: 4.406213283538818 GB"
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ [`AnimateDiffPipeline`] ä¸ºå›¾åƒæ·»åŠ åŠ¨ç”»æ•ˆæœï¼ŒåŒæ—¶å‘ç®¡é“ä¸­æ·»åŠ  [`MotionAdapter`] æ¨¡å—ã€‚å¯¹äº [`AnimateDiffPipeline`]ï¼Œéœ€è¦å…ˆå¸è½½ IP-Adapterï¼Œå¹¶åœ¨åˆ›å»ºæ–°ç®¡é“åé‡æ–°åŠ è½½ï¼ˆè¿™ä¸€æ­¥éª¤ä»…é€‚ç”¨äº [`AnimateDiffPipeline`]ï¼‰ã€‚

```py
from diffusers import AnimateDiffPipeline, MotionAdapter, DDIMScheduler
from diffusers.utils import export_to_gif

pipe_sag.unload_ip_adapter()
adapter = MotionAdapter.from_pretrained("guoyww/animatediff-motion-adapter-v1-5-2", torch_dtype=torch.float16)

pipe_animate = AnimateDiffPipeline.from_pipe(pipe_sd, motion_adapter=adapter)
pipe_animate.scheduler = DDIMScheduler.from_config(pipe_animate.scheduler.config, beta_schedule="linear")
# é‡æ–°åŠ è½½ IP-Adapter å’Œ LoRA æƒé‡
pipe_animate.load_ip_adapter("h94/IP-Adapter", subfolder="models", weight_name="ip-adapter_sd15.bin")
pipe_animate.load_lora_weights("guoyww/animatediff-motion-lora-zoom-out", adapter_name="zoom-out")
pipe_animate.to("cuda")

generator = torch.Generator(device="cpu").manual_seed(33)
pipe_animate.set_adapters("zoom-out", adapter_weights=0.75)
out = pipe_animate(
    prompt="ç†ŠåƒæŠ«è¨",
    num_frames=16,
    num_inference_steps=50,
    ip_adapter_image=image,
    generator=generator,
).frames[0]
export_to_gif(out, "out_animate.gif")
```

<div class="flex justify-center">
  <img class="rounded-xl" src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/from_pipe_out_animate_3.gif"/>
</div>

[`AnimateDiffPipeline`] å¯¹å†…å­˜çš„éœ€æ±‚æ›´é«˜ï¼Œä¼šæ¶ˆè€— 15GB å†…å­˜ï¼ˆå…³äºè¿™å¯¹å†…å­˜ä½¿ç”¨çš„å½±å“ï¼Œè¯·å‚é˜… [from_pipe çš„å†…å­˜ä½¿ç”¨æƒ…å†µ](#memory-usage-of-from_pipe) éƒ¨åˆ†ï¼‰ã€‚

```py
print(f"æœ€å¤§å†…å­˜åˆ†é…é‡: {bytes_to_giga_bytes(torch.cuda.max_memory_allocated())} GB")
"æœ€å¤§å†…å­˜åˆ†é…é‡: 15.178664207458496 GB"
```

### ä¿®æ”¹ from_pipe ç»„ä»¶

é€šè¿‡ [`~DiffusionPipeline.from_pipe`] åŠ è½½çš„ç®¡é“å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ç»„ä»¶æˆ–æ–¹æ³•è¿›è¡Œè‡ªå®šä¹‰ã€‚ä½†æ˜¯ï¼Œæ¯å½“ä¿®æ”¹æ¨¡å‹ç»„ä»¶çš„çŠ¶æ€æ—¶ï¼Œä¼šå½±å“å…±äº«ç›¸åŒç»„ä»¶çš„æ‰€æœ‰å…¶ä»–ç®¡é“ã€‚ä¾‹å¦‚ï¼Œå¦‚æœåœ¨ [`StableDiffusionSAGPipeline`] ä¸Šè°ƒç”¨ [`~diffusers.loaders.IPAdapterMixin.unload_ip_adapter`]ï¼Œé‚£ä¹ˆå°†æ— æ³•åœ¨ [`StableDiffusionPipeline`] ä¸­ä½¿ç”¨ IP-Adapterï¼Œå› ä¸ºå®ƒå·²ä»å…±äº«ç»„ä»¶ä¸­ç§»é™¤ã€‚

```py
pipe.sag_unload_ip_adapter()

generator = to
```markdown
rch.Generator(device="cpu").manual_seed(33)
out_sd = pipe_sd(
    prompt="ç†ŠåƒæŠ«è¨",
    negative_prompt="ç™½å¹³è¡¡é”™è¯¯, é»‘æš—, è‰å›¾, æœ€å·®è´¨é‡, ä½è´¨é‡",
    ip_adapter_image=image,
    num_inference_steps=50,
    generator=generator,
).images[0]
"AttributeError: 'NoneType' object has no attribute 'image_projection_layers'"
```

### from_pipeçš„å†…å­˜å ç”¨

ä½¿ç”¨[`~DiffusionPipeline.from_pipe`]åŠ è½½å¤šä¸ªæµç¨‹æ—¶ï¼Œå†…å­˜éœ€æ±‚å–å†³äºå†…å­˜å ç”¨æœ€é«˜çš„æµç¨‹ï¼Œä¸åˆ›å»ºçš„æµç¨‹æ•°é‡æ— å…³ã€‚

| æµç¨‹ç±»å‹ | å†…å­˜å ç”¨ (GB) |
|---|---|
| StableDiffusionPipeline | 4.400 |
| StableDiffusionSAGPipeline | 4.400 |
| AnimateDiffPipeline | 15.178 |

ç”±äº[`AnimateDiffPipeline`]å†…å­˜éœ€æ±‚æœ€é«˜ï¼Œå› æ­¤*æ€»å†…å­˜å ç”¨*ä»…åŸºäºè¯¥æµç¨‹ã€‚åªè¦åç»­åˆ›å»ºçš„æµç¨‹å†…å­˜éœ€æ±‚ä¸è¶…è¿‡[`AnimateDiffPipeline`]ï¼Œå†…å­˜å ç”¨å°±ä¸ä¼šå¢åŠ ã€‚å„æµç¨‹å¯äº¤æ›¿ä½¿ç”¨ï¼Œä¸ä¼šäº§ç”Ÿé¢å¤–å†…å­˜å¼€é”€ã€‚

## å®‰å…¨æ£€æµ‹å™¨

Diffusersä¸ºStable Diffusionæ¨¡å‹å®ç°äº†[å®‰å…¨æ£€æµ‹å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py)ï¼Œç”¨äºç­›æŸ¥å¯èƒ½ç”Ÿæˆçš„æœ‰å®³å†…å®¹ã€‚è¯¥æ£€æµ‹å™¨ä¼šå°†ç”Ÿæˆè¾“å‡ºä¸å·²çŸ¥çš„NSFWå†…å®¹ç¡¬ç¼–ç åº“è¿›è¡Œæ¯”å¯¹ã€‚å¦‚éœ€ç¦ç”¨å®‰å…¨æ£€æµ‹å™¨ï¼Œå¯å‘[`~DiffusionPipeline.from_pretrained`]æ–¹æ³•ä¼ é€’`safety_checker=None`å‚æ•°ã€‚

```python
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", safety_checker=None, use_safetensors=True)
"""
æ‚¨å·²é€šè¿‡ä¼ é€’`safety_checker=None`ç¦ç”¨äº†<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>çš„å®‰å…¨æ£€æµ‹å™¨ã€‚è¯·ç¡®ä¿éµå®ˆStable Diffusionè®¸å¯æ¡æ¬¾ï¼Œé¿å…åœ¨å…¬å¼€æœåŠ¡æˆ–åº”ç”¨ä¸­å±•ç¤ºæœªè¿‡æ»¤ç»“æœã€‚Diffuserså›¢é˜Ÿå’ŒHugging Faceå¼ºçƒˆå»ºè®®åœ¨æ‰€æœ‰é¢å‘å…¬ä¼—çš„åœºæ™¯ä¸­ä¿æŒå®‰å…¨è¿‡æ»¤å™¨å¯ç”¨ï¼Œä»…åœ¨è¿›è¡Œç½‘ç»œè¡Œä¸ºåˆ†ææˆ–ç»“æœå®¡è®¡æ—¶ç¦ç”¨ã€‚æ›´å¤šä¿¡æ¯è¯·å‚é˜…https://github.com/huggingface/diffusers/pull/254ã€‚
"""
```

## æ£€æŸ¥ç‚¹å˜ä½“

æ£€æŸ¥ç‚¹å˜ä½“é€šå¸¸æŒ‡ä»¥ä¸‹ä¸¤ç§æƒé‡ç±»å‹ï¼š

- å­˜å‚¨ä¸ºä¸åŒæµ®ç‚¹ç±»å‹ï¼ˆå¦‚[torch.float16](https://pytorch.org/docs/stable/tensors.html#data-types)ï¼‰çš„æ£€æŸ¥ç‚¹ï¼Œä¸‹è½½ä»…éœ€ä¸€åŠå¸¦å®½å’Œå­˜å‚¨ç©ºé—´ã€‚ä½†ç»§ç»­è®­ç»ƒæˆ–ä½¿ç”¨CPUæ—¶ä¸å¯ç”¨æ­¤å˜ä½“ã€‚
- éæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆNon-EMAï¼‰æƒé‡ï¼Œæ­¤ç±»å˜ä½“ä¸åº”ç”¨äºæ¨ç†ï¼Œä»…é€‚ç”¨äºç»§ç»­å¾®è°ƒæ¨¡å‹ã€‚

> [!æç¤º]
> å½“æ£€æŸ¥ç‚¹åŒ…å«...ï¼ˆåç»­å†…å®¹å¾…è¡¥å……ï¼‰
### æ¨¡å‹å˜ä½“

å³ä½¿æ¨¡å‹ç»“æ„å®Œå…¨ç›¸åŒï¼Œä½†å¦‚æœå®ƒä»¬åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šè®­ç»ƒæˆ–é‡‡ç”¨äº†ä¸åŒçš„è®­ç»ƒé…ç½®ï¼Œå°±åº”å½“å­˜æ”¾åœ¨ç‹¬ç«‹çš„ä»£ç åº“ä¸­ã€‚ä¾‹å¦‚ï¼Œ[stabilityai/stable-diffusion-2](https://hf.co/stabilityai/stable-diffusion-2) å’Œ [stabilityai/stable-diffusion-2-1](https://hf.co/stabilityai/stable-diffusion-2-1) å°±åˆ†åˆ«å­˜å‚¨åœ¨ä¸åŒçš„ä»£ç åº“ä¸­ã€‚

åä¹‹ï¼Œè‹¥æŸä¸ªå˜ä½“ä¸åŸæ£€æŸ¥ç‚¹**å®Œå…¨ä¸€è‡´**ï¼Œåˆ™æ„å‘³ç€å®ƒä»¬å…·æœ‰ç›¸åŒçš„åºåˆ—åŒ–æ ¼å¼ï¼ˆå¦‚ [safetensors](./using_safetensors)ï¼‰ã€å®Œå…¨ä¸€è‡´çš„æ¨¡å‹ç»“æ„ï¼Œä¸”æ‰€æœ‰å¼ é‡æƒé‡å½¢çŠ¶å‡ç›¸åŒã€‚

| **æ£€æŸ¥ç‚¹ç±»å‹**       | **æƒé‡æ–‡ä»¶å**                             | **åŠ è½½å‚æ•°**               |
|----------------------|-------------------------------------------|---------------------------|
| åŸå§‹ç‰ˆæœ¬             | diffusion_pytorch_model.safetensors        | -                         |
| æµ®ç‚¹ç²¾åº¦å˜ä½“         | diffusion_pytorch_model.fp16.safetensors   | `variant`, `torch_dtype`  |
| éEMAå˜ä½“            | diffusion_pytorch_model.non_ema.safetensors| `variant`                 |

åŠ è½½å˜ä½“æ—¶æœ‰ä¸¤ä¸ªå…³é”®å‚æ•°ï¼š

- `torch_dtype` æŒ‡å®šåŠ è½½æƒé‡çš„æµ®ç‚¹ç²¾åº¦ã€‚ä¾‹å¦‚ï¼Œè‹¥æƒ³é€šè¿‡åŠ è½½ fp16 å˜ä½“èŠ‚çœå¸¦å®½ï¼Œéœ€åŒæ—¶è®¾ç½® `variant="fp16"` å’Œ `torch_dtype=torch.float16` ä»¥*å°†æƒé‡è½¬æ¢ä¸º fp16*ã€‚è‹¥ä»…è®¾ç½® `torch_dtype=torch.float16`ï¼Œç³»ç»Ÿä¼šå…ˆä¸‹è½½é»˜è®¤çš„ fp32 æƒé‡å†æ‰§è¡Œè½¬æ¢ã€‚

- `variant` æŒ‡å®šä»ä»£ç åº“åŠ è½½å“ªä¸ªæ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œè¦ä» [stable-diffusion-v1-5](https://hf.co/stable-diffusion-v1-5/stable-diffusion-v1-5/tree/main/unet) åŠ è½½ UNet çš„éEMAå˜ä½“ï¼Œéœ€è®¾ç½® `variant="non_ema"` æ¥ä¸‹è½½å¯¹åº”çš„ `non_ema` æ–‡ä»¶ã€‚

<hfoptions id="variants">
<hfoption id="fp16">

```python
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5", 
    variant="fp16", 
    torch_dtype=torch.float16, 
    use_safetensors=True
)
```

</hfoption>
<hfoption id="non-EMA">

```python
pipeline = DiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5", 
    variant="non_ema", 
    use_safetensors=True
)
```

</hfoption>
</hfoptions>

é€šè¿‡ [`DiffusionPipeline.save_pretrained`] æ–¹æ³•çš„ `variant` å‚æ•°ï¼Œå¯å°†æ£€æŸ¥ç‚¹ä¿å­˜ä¸ºä¸åŒæµ®ç‚¹ç²¾åº¦æˆ–éEMAå˜ä½“ã€‚å»ºè®®å°†å˜ä½“ä¿å­˜åœ¨åŸå§‹æ£€æŸ¥ç‚¹åŒä¸€ç›®å½•ä¸‹ï¼Œä»¥ä¾¿ä»åŒä¸€ä½ç½®åŠ è½½ä¸åŒç‰ˆæœ¬ã€‚

<hfoptions id="save">
<hfoption id="fp16">

```python
from diffusers import DiffusionPipeline

pipeline.save_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", variant="fp16")
```

</hfoption>
<hfoption id="non_ema">

```python
pipeline.save_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", variant="non_ema")
```

</hfoption>
</hfoptions>
ä»¥ä¸‹æ˜¯æ‚¨æä¾›çš„è‹±æ–‡å†…å®¹çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä¿ç•™äº†Diffusersã€stable_diffusionã€consisidç­‰ä¸“æœ‰åè¯çš„è‹±æ–‡å½¢å¼ï¼Œå¹¶ç»´æŒäº†Markdownæ ¼å¼ï¼š

```markdown
on-v1-5/stable-diffusion-v1-5", variant="non_ema")
```

</hfoption>
</hfoptions>

å¦‚æœä¸å°†å˜ä½“ä¿å­˜åˆ°ç°æœ‰æ–‡ä»¶å¤¹ä¸­ï¼Œåˆ™å¿…é¡»æŒ‡å®š `variant` å‚æ•°ï¼Œå¦åˆ™ä¼šæŠ›å‡º `Exception` å¼‚å¸¸ï¼Œå› ä¸ºå®ƒæ— æ³•æ‰¾åˆ°åŸå§‹æ£€æŸ¥ç‚¹ã€‚

```python
# ğŸ‘ è¿™ç§æ–¹å¼ä¸å¯è¡Œ
pipeline = DiffusionPipeline.from_pretrained(
    "./stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
# ğŸ‘ è¿™ç§æ–¹å¼å¯è¡Œ
pipeline = DiffusionPipeline.from_pretrained(
    "./stable-diffusion-v1-5", variant="fp16", torch_dtype=torch.float16, use_safetensors=True
)
```

## DiffusionPipeline åŸç†è§£æ

ä½œä¸ºç±»æ–¹æ³•ï¼Œ[`DiffusionPipeline.from_pretrained`] ä¸»è¦æ‰¿æ‹…ä¸¤é¡¹èŒè´£ï¼š

- ä¸‹è½½æ¨ç†æ‰€éœ€çš„æœ€æ–°ç‰ˆæ–‡ä»¶å¤¹ç»“æ„å¹¶ç¼“å­˜ã€‚è‹¥æœ¬åœ°ç¼“å­˜ä¸­å·²å­˜åœ¨æœ€æ–°æ–‡ä»¶å¤¹ç»“æ„ï¼Œ[`DiffusionPipeline.from_pretrained`] ä¼šç›´æ¥å¤ç”¨ç¼“å­˜è€Œä¸ä¼šé‡å¤ä¸‹è½½æ–‡ä»¶ã€‚
- å°†ç¼“å­˜çš„æƒé‡åŠ è½½è‡³æ­£ç¡®çš„æµæ°´çº¿[ç±»](../api/pipelines/overview#diffusers-summary)ï¼ˆè¯¥ä¿¡æ¯ä» `model_index.json` æ–‡ä»¶ä¸­è·å–ï¼‰ï¼Œå¹¶è¿”å›å…¶å®ä¾‹ã€‚

æµæ°´çº¿çš„åº•å±‚æ–‡ä»¶å¤¹ç»“æ„ä¸å…¶ç±»å®ä¾‹ç›´æ¥å¯¹åº”ã€‚ä¾‹å¦‚ï¼Œ[`StableDiffusionPipeline`] å¯¹åº” [`stable-diffusion-v1-5/stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5) ä¸­çš„æ–‡ä»¶å¤¹ç»“æ„ã€‚

```python
from diffusers import DiffusionPipeline

repo_id = "stable-diffusion-v1-5/stable-diffusion-v1-5"
pipeline = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)
print(pipeline)
```

æ‚¨ä¼šçœ‹åˆ° pipeline æ˜¯ [`StableDiffusionPipeline`] çš„å®ä¾‹ï¼Œç”±ä¸ƒä¸ªç»„ä»¶æ„æˆï¼š

- `"feature_extractor"`ï¼šæ¥è‡ª ğŸ¤— Transformers çš„ [`~transformers.CLIPImageProcessor`]ã€‚
- `"safety_checker"`ï¼šç”¨äºå±è”½æœ‰å®³å†…å®¹çš„[ç»„ä»¶](https://github.com/huggingface/diffusers/blob/e55687e1e15407f60f32242027b7bb8170e58266/src/diffusers/pipelines/stable_diffusion/safety_checker.py#L32)ã€‚
- `"scheduler"`ï¼š[`PNDMScheduler`] çš„å®ä¾‹ã€‚
- `"text_encoder"`ï¼šæ¥è‡ª ğŸ¤— Transformers çš„ [`~transformers.CLIPTextModel`]ã€‚
- `"tokenizer"`ï¼šæ¥è‡ª ğŸ¤— Transformers çš„ [`~transformers.CLIPTokenizer`]ã€‚
- `"unet"`ï¼š[`UNet2DConditionModel`] çš„å®ä¾‹ã€‚
- `"vae"`ï¼š[`AutoencoderKL`] çš„å®ä¾‹ã€‚

```json
StableDiffusionPipeline {
  "feature_extractor": [
    "transformers",
    "CLIPImageProcessor"
  ],
  "safety_checker": [
    "stable_diffusion",
    "StableDiffusionSafetyChecker"
  ],
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
    "CLIPTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```

å°†æµæ°´çº¿å®ä¾‹çš„ç»„ä»¶ä¸ [`stable-diffusion-v1-5/stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusio
```

ï¼ˆæ³¨ï¼šç”±äºæ‚¨æä¾›çš„è‹±æ–‡å†…å®¹åœ¨ç»“å°¾å¤„è¢«æˆªæ–­ï¼Œä¸­æ–‡ç¿»è¯‘ä¹Ÿä¿æŒç›¸åŒæˆªæ–­ä½ç½®ã€‚è‹¥éœ€å®Œæ•´ç¿»è¯‘æœ€åéƒ¨åˆ†ï¼Œè¯·æä¾›å‰©ä½™å†…å®¹ã€‚ï¼‰
ä»¥ä¸‹æ˜¯æ‚¨æä¾›çš„è‹±æ–‡å†…å®¹çš„ä¸­æ–‡ç¿»è¯‘ï¼Œå·²æŒ‰è¦æ±‚ä¿ç•™Diffusersã€stable_diffusionç­‰ä¸“æœ‰åè¯ä¸ç¿»è¯‘ï¼Œå¹¶ä¿æŒMarkdownæ ¼å¼ï¼š

ï¼ˆè¿™æ˜¯æ–‡æ¡£10éƒ¨åˆ†ä¸­çš„ç¬¬9éƒ¨åˆ†ï¼‰

è§‚å¯Ÿ[stable_diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)çš„æ–‡ä»¶å¤¹ç»“æ„ï¼Œæ‚¨ä¼šå‘ç°ä»“åº“ä¸­æ¯ä¸ªç»„ä»¶éƒ½æœ‰ç‹¬ç«‹çš„æ–‡ä»¶å¤¹ï¼š

```
.
â”œâ”€â”€ feature_extractor
â”‚Â Â  â””â”€â”€ preprocessor_config.json
â”œâ”€â”€ model_index.json
â”œâ”€â”€ safety_checker
â”‚Â Â  â”œâ”€â”€ config.json
|   â”œâ”€â”€ model.fp16.safetensors
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ pytorch_model.bin
|   â””â”€â”€ pytorch_model.fp16.bin
â”œâ”€â”€ scheduler
â”‚Â Â  â””â”€â”€ scheduler_config.json
â”œâ”€â”€ text_encoder
â”‚Â Â  â”œâ”€â”€ config.json
|   â”œâ”€â”€ model.fp16.safetensors
â”‚   â”œâ”€â”€ model.safetensors
â”‚   |â”€â”€ pytorch_model.bin
|   â””â”€â”€ pytorch_model.fp16.bin
â”œâ”€â”€ tokenizer
â”‚Â Â  â”œâ”€â”€ merges.txt
â”‚Â Â  â”œâ”€â”€ special_tokens_map.json
â”‚Â Â  â”œâ”€â”€ tokenizer_config.json
â”‚Â Â  â””â”€â”€ vocab.json
â”œâ”€â”€ unet
â”‚Â Â  â”œâ”€â”€ config.json
â”‚Â Â  â”œâ”€â”€ diffusion_pytorch_model.bin
|   |â”€â”€ diffusion_pytorch_model.fp16.bin
â”‚   |â”€â”€ diffusion_pytorch_model.f16.safetensors
â”‚   |â”€â”€ diffusion_pytorch_model.non_ema.bin
â”‚   |â”€â”€ diffusion_pytorch_model.non_ema.safetensors
â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
|â”€â”€ vae
.   â”œâ”€â”€ config.json
.   â”œâ”€â”€ diffusion_pytorch_model.bin
    â”œâ”€â”€ diffusion_pytorch_model.fp16.bin
    â”œâ”€â”€ diffusion_pytorch_model.fp16.safetensors
    â””â”€â”€ diffusion_pytorch_model.safetensors
```

æ‚¨å¯ä»¥é€šè¿‡å±æ€§è®¿é—®ç®¡é“çš„æ¯ä¸ªç»„ä»¶æ¥æŸ¥çœ‹å…¶é…ç½®ï¼š

```py
pipeline.tokenizer
CLIPTokenizer(
    name_or_path="/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/39593d5650112b4cc580433f6b0435385882d819/tokenizer",
    vocab_size=49408,
    model_max_length=77,
    is_fast=False,
    padding_side="right",
    truncation_side="right",
    special_tokens={
        "bos_token": AddedToken("<|startoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True),
        "eos_token": AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True),
        "unk_token": AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True),
        "pad_token": "<|endoftext|>",
    },
    clean_up_tokenization_spaces=True
)
```

æ¯ä¸ªç®¡é“éƒ½éœ€è¦ä¸€ä¸ª[`model_index.json`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/blob/main/model_index.json)æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶ä¼šå‘Šè¯‰[`DiffusionPipeline`]ï¼š

- ä»`_class_name`åŠ è½½å“ªä¸ªç®¡é“ç±»
- åˆ›å»ºæ¨¡å‹æ—¶ä½¿ç”¨çš„ğŸ§¨ Diffusersç‰ˆæœ¬`_diffusers_version`
- å­æ–‡ä»¶å¤¹ä¸­å­˜å‚¨äº†å“ªäº›åº“çš„å“ªäº›ç»„ä»¶ï¼ˆ`name`å¯¹åº”ç»„ä»¶å’Œå­æ–‡ä»¶å¤¹åç§°ï¼Œ`library`å¯¹åº”è¦åŠ è½½ç±»çš„åº“åï¼Œ`class`å¯¹åº”ç±»åï¼‰

```json
{
  "_class_name": "StableDiffusionPipeline",
  "_diffusers_version": "0.6.0",
  "feature_extractor": [
    "transformers",
    "CLIPImageProcessor"
  ],
  "safety_checker": [
    "stable_diffusion",
    "StableDiffusionSafetyChecker"
  ],
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
```
```json
{
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
    "CLIPTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```
