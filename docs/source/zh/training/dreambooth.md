<!--ç‰ˆæƒæ‰€æœ‰ 2025 The HuggingFace Teamã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ® Apache è®¸å¯è¯ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰æˆæƒï¼›é™¤ééµå®ˆè®¸å¯è¯ï¼Œå¦åˆ™ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬ï¼š

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æŒ‰â€œåŸæ ·â€åˆ†å‘ï¼Œä¸é™„å¸¦ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯è¯ä»¥äº†è§£ç‰¹å®šçš„è¯­è¨€ç®¡ç†æƒé™å’Œé™åˆ¶ã€‚
-->

# DreamBooth

[DreamBooth](https://huggingface.co/papers/2208.12242) æ˜¯ä¸€ç§è®­ç»ƒæŠ€æœ¯ï¼Œé€šè¿‡ä»…è®­ç»ƒå°‘æ•°ä¸»é¢˜æˆ–é£æ ¼çš„å›¾åƒæ¥æ›´æ–°æ•´ä¸ªæ‰©æ•£æ¨¡å‹ã€‚å®ƒé€šè¿‡åœ¨æç¤ºä¸­å…³è”ä¸€ä¸ªç‰¹æ®Šè¯ä¸ç¤ºä¾‹å›¾åƒæ¥å·¥ä½œã€‚

å¦‚æœæ‚¨åœ¨ vRAM æœ‰é™çš„ GPU ä¸Šè®­ç»ƒï¼Œåº”å°è¯•åœ¨è®­ç»ƒå‘½ä»¤ä¸­å¯ç”¨ `gradient_checkpointing` å’Œ `mixed_precision` å‚æ•°ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡ä½¿ç”¨ [xFormers](../optimization/xformers) çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æ¥å‡å°‘å†…å­˜å ç”¨ã€‚JAX/Flax è®­ç»ƒä¹Ÿæ”¯æŒåœ¨ TPU å’Œ GPU ä¸Šè¿›è¡Œé«˜æ•ˆè®­ç»ƒï¼Œä½†ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹æˆ– xFormersã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨ Flax æ›´å¿«åœ°è®­ç»ƒï¼Œåº”æ‹¥æœ‰å†…å­˜ >30GB çš„ GPUã€‚

æœ¬æŒ‡å—å°†æ¢ç´¢ [train_dreambooth.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py) è„šæœ¬ï¼Œå¸®åŠ©æ‚¨æ›´ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•æ ¹æ®æ‚¨çš„ç”¨ä¾‹è¿›è¡Œé€‚é…ã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»æºä»£ç å®‰è£…åº“ï¼š

```bash
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

å¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

<hfoptions id="installation">
<hfoption id="PyTorch">

```bash
cd examples/dreambooth
pip install -r requirements.txt
```

</hfoption>
<hfoption id="Flax">

```bash
cd examples/dreambooth
pip install -r requirements_flax.txt
```

</hfoption>
</hfoptions>

> [!TIP]
> ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªåº“ï¼Œç”¨äºå¸®åŠ©æ‚¨åœ¨å¤šä¸ª GPU/TPU ä¸Šæˆ–ä½¿ç”¨æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒã€‚å®ƒä¼šæ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ ğŸ¤— Accelerate [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour) ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚

åˆå§‹åŒ– ğŸ¤— Accelerate ç¯å¢ƒï¼š

```bash
accelerate config
```

è¦è®¾ç½®é»˜è®¤çš„ ğŸ¤— Accelerate ç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š

```bash
accelerate config default
```

æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼Œä¾‹å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹ [åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset) æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºä¸
è®­ç»ƒè„šæœ¬ã€‚

> [!TIP]
> ä»¥ä¸‹éƒ¨åˆ†é‡ç‚¹ä»‹ç»äº†è®­ç»ƒè„šæœ¬ä¸­å¯¹äºç†è§£å¦‚ä½•ä¿®æ”¹å®ƒå¾ˆé‡è¦çš„éƒ¨åˆ†ï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚

## è„šæœ¬å‚æ•°

> [!WARNING]
> DreamBooth å¯¹è®­ç»ƒè¶…å‚æ•°éå¸¸æ•æ„Ÿï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆã€‚é˜…è¯» [ä½¿ç”¨ ğŸ§¨ Diffusers è®­ç»ƒ Stable Diffusion ä¸ Dreambooth](https://huggingface.co/blog/dreambooth) åšå®¢æ–‡ç« ï¼Œäº†è§£é’ˆå¯¹ä¸åŒä¸»é¢˜çš„æ¨èè®¾ç½®ï¼Œä»¥å¸®åŠ©æ‚¨é€‰æ‹©åˆé€‚çš„è¶…å‚æ•°ã€‚

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°æ¥è‡ªå®šä¹‰æ‚¨çš„è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨ [`parse_args()`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L228) å‡½æ•°ä¸­æ‰¾åˆ°ã€‚å‚æ•°è®¾ç½®äº†é»˜è®¤å€¼ï¼Œè¿™äº›é»˜è®¤å€¼åº”è¯¥å¼€ç®±å³ç”¨æ•ˆæœä¸é”™ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œè¦ä»¥ bf16 æ ¼å¼è¿›è¡Œè®­ç»ƒï¼š

```bash
accelerate launch train_dreambooth.py \
    --mixed_precision="bf16"
```

ä¸€äº›åŸºæœ¬ä¸”é‡è¦çš„å‚æ•°éœ€è¦äº†è§£å’ŒæŒ‡å®šï¼š

- `--pretrained_model_name_or_path`: Hub ä¸Šçš„æ¨¡å‹åç§°æˆ–é¢„è®­ç»ƒæ¨¡å‹çš„æœ¬åœ°è·¯å¾„
- `--instance_data_dir`: åŒ…å«è®­ç»ƒæ•°æ®é›†ï¼ˆç¤ºä¾‹å›¾åƒï¼‰çš„æ–‡ä»¶å¤¹è·¯å¾„
- `--instance_prompt`: åŒ…å«ç¤ºä¾‹å›¾åƒç‰¹æ®Šå•è¯çš„æ–‡æœ¬æç¤º
- `--train_text_encoder`: æ˜¯å¦ä¹Ÿè®­ç»ƒæ–‡æœ¬ç¼–ç å™¨
- `--output_dir`: ä¿å­˜è®­ç»ƒåæ¨¡å‹çš„ä½ç½®
- `--push_to_hub`: æ˜¯å¦å°†è®­ç»ƒåçš„æ¨¡å‹æ¨é€åˆ° Hub
- `--checkpointing_steps`: æ¨¡å‹è®­ç»ƒæ—¶ä¿å­˜æ£€æŸ¥ç‚¹çš„é¢‘ç‡ï¼›è¿™åœ¨è®­ç»ƒå› æŸç§åŸå› ä¸­æ–­æ—¶å¾ˆæœ‰ç”¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ  `--resume_from_checkpoint` æ¥ä»è¯¥æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ

### Min-SNR åŠ æƒ

[Min-SNR](https://huggingface.co/papers/2303.09556) åŠ æƒç­–ç•¥å¯ä»¥é€šè¿‡é‡æ–°å¹³è¡¡æŸå¤±æ¥å¸®åŠ©è®­ç»ƒï¼Œä»¥å®ç°æ›´å¿«çš„æ”¶æ•›ã€‚è®­ç»ƒè„šæœ¬æ”¯æŒé¢„æµ‹ `epsilon`ï¼ˆå™ªå£°ï¼‰æˆ– `v_prediction`ï¼Œä½† Min-SNR ä¸ä¸¤ç§é¢„æµ‹ç±»å‹éƒ½å…¼å®¹ã€‚æ­¤åŠ æƒç­–ç•¥ä»…ç”± PyTorch æ”¯æŒï¼Œåœ¨ Flax è®­ç»ƒè„šæœ¬ä¸­ä¸å¯ç”¨ã€‚

æ·»åŠ  `--snr_gamma` å‚æ•°å¹¶å°†å…¶è®¾ç½®ä¸ºæ¨èå€¼ 5.0ï¼š

```bash
accelerate launch train_dreambooth.py \
  --snr_gamma=5.0
```

### å…ˆéªŒä¿æŒæŸå¤±

å…ˆéªŒä¿æŒæŸå¤±æ˜¯ä¸€ç§ä½¿ç”¨æ¨¡å‹è‡ªèº«ç”Ÿæˆçš„æ ·æœ¬æ¥å¸®åŠ©å®ƒå­¦ä¹ å¦‚ä½•ç”Ÿæˆæ›´å¤šæ ·åŒ–å›¾åƒçš„æ–¹æ³•ã€‚å› ä¸ºè¿™äº›ç”Ÿæˆçš„æ ·æœ¬å›¾åƒå±äºæ‚¨æä¾›çš„å›¾åƒç›¸åŒçš„ç±»åˆ«ï¼Œå®ƒä»¬å¸®åŠ©æ¨¡å‹ r
etain å®ƒå·²ç»å­¦åˆ°çš„å…³äºç±»åˆ«çš„çŸ¥è¯†ï¼Œä»¥åŠå®ƒå¦‚ä½•åˆ©ç”¨å·²ç»äº†è§£çš„ç±»åˆ«ä¿¡æ¯æ¥åˆ›å»ºæ–°çš„ç»„åˆã€‚

- `--with_prior_preservation`: æ˜¯å¦ä½¿ç”¨å…ˆéªŒä¿ç•™æŸå¤±
- `--prior_loss_weight`: æ§åˆ¶å…ˆéªŒä¿ç•™æŸå¤±å¯¹æ¨¡å‹çš„å½±å“ç¨‹åº¦
- `--class_data_dir`: åŒ…å«ç”Ÿæˆçš„ç±»åˆ«æ ·æœ¬å›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„
- `--class_prompt`: æè¿°ç”Ÿæˆçš„æ ·æœ¬å›¾åƒç±»åˆ«çš„æ–‡æœ¬æç¤º

```bash
accelerate launch train_dreambooth.py \
  --with_prior_preservation \
  --prior_loss_weight=1.0 \
  --class_data_dir="path/to/class/images" \
  --class_prompt="text prompt describing class"
```

### è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨

ä¸ºäº†æé«˜ç”Ÿæˆè¾“å‡ºçš„è´¨é‡ï¼Œé™¤äº† UNet ä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ã€‚è¿™éœ€è¦é¢å¤–çš„å†…å­˜ï¼Œå¹¶ä¸”æ‚¨éœ€è¦ä¸€ä¸ªè‡³å°‘æœ‰ 24GB æ˜¾å­˜çš„ GPUã€‚å¦‚æœæ‚¨æ‹¥æœ‰å¿…è¦çš„ç¡¬ä»¶ï¼Œé‚£ä¹ˆè®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆé¢éƒ¨å›¾åƒæ—¶ã€‚é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨æ­¤é€‰é¡¹ï¼š

```bash
accelerate launch train_dreambooth.py \
  --train_text_encoder
```

## è®­ç»ƒè„šæœ¬

DreamBooth é™„å¸¦äº†è‡ªå·±çš„æ•°æ®é›†ç±»ï¼š

- [`DreamBoothDataset`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L604): é¢„å¤„ç†å›¾åƒå’Œç±»åˆ«å›¾åƒï¼Œå¹¶å¯¹æç¤ºè¿›è¡Œåˆ†è¯ä»¥ç”¨äºè®­ç»ƒ
- [`PromptDataset`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L738): ç”Ÿæˆæç¤ºåµŒå…¥ä»¥ç”Ÿæˆç±»åˆ«å›¾åƒ

å¦‚æœæ‚¨å¯ç”¨äº†[å…ˆéªŒä¿ç•™æŸå¤±](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L842)ï¼Œç±»åˆ«å›¾åƒåœ¨æ­¤å¤„ç”Ÿæˆï¼š

```py
sample_dataset = PromptDataset(args.class_prompt, num_new_images)
sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=args.sample_batch_size)

sample_dataloader = accelerator.prepare(sample_dataloader)
pipeline.to(accelerator.device)

for example in tqdm(
    sample_dataloader, desc="Generating class images", disable=not accelerator.is_local_main_process
):
    images = pipeline(example["prompt"]).images
```

æ¥ä¸‹æ¥æ˜¯ [`main()`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L799) å‡½æ•°ï¼Œå®ƒå¤„ç†è®¾ç½®è®­ç»ƒæ•°æ®é›†å’Œè®­ç»ƒå¾ªç¯æœ¬èº«ã€‚è„šæœ¬åŠ è½½ [tokenizer](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L898)ã€[scheduler å’Œ models](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L912C1-L912C1)ï¼š

```py
# Load the tokenizer
if args.tokenizer_name:
    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, revision=args.revision, use_fast=False)
elif args.pretrained_model_name_or_path:
    tokenizer = AutoTokenizer.from_pretrained(
        args.pretrained_model_name_or_path,
        subfolder="tokenizer",
        revision=args.revision,
        use_fast=False,
    )

# åŠ è½½è°ƒåº¦å™¨å’Œæ¨¡å‹
noise_scheduler = DDPMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder="scheduler")
text_encoder = text_encoder_cls.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="text_encoder", revision=args.revision
)

if model_has_vae(args):
    vae = AutoencoderKL.from_pretrained(
        args.pretrained_model_name_or_path, subfolder="vae", revision=args.revision
    )
else:
    vae = None

unet = UNet2DConditionModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="unet", revision=args.revision
)
```

ç„¶åï¼Œæ˜¯æ—¶å€™[åˆ›å»ºè®­ç»ƒæ•°æ®é›†](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L1073)å’Œä»`DreamBoothDataset`åˆ›å»ºDataLoaderï¼š

```py
train_dataset = DreamBoothDataset(
    instance_data_root=args.instance_data_dir,
    instance_prompt=args.instance_prompt,
    class_data_root=args.class_data_dir if args.with_prior_preservation else None,
    class_prompt=args.class_prompt,
    class_num=args.num_class_images,
    tokenizer=tokenizer,
    size=args.resolution,
    center_crop=args.center_crop,
    encoder_hidden_states=pre_computed_encoder_hidden_states,
    class_prompt_encoder_hidden_states=pre_computed_class_prompt_encoder_hidden_states,
    tokenizer_max_length=args.tokenizer_max_length,
)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset,
    batch_size=args.train_batch_size,
    shuffle=True,
    collate_fn=lambda examples: collate_fn(examples, args.with_prior_preservation),
    num_workers=args.dataloader_num_workers,
)
```

æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L1151)å¤„ç†å‰©ä½™æ­¥éª¤ï¼Œä¾‹å¦‚å°†å›¾åƒè½¬æ¢ä¸ºæ½œåœ¨ç©ºé—´ã€å‘è¾“å…¥æ·»åŠ å™ªå£°ã€é¢„æµ‹å™ªå£°æ®‹å·®å’Œè®¡ç®—æŸå¤±ã€‚

å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºè®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[ç†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨](../using-diffusers/write_own_pipeline)æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹åˆ†è§£äº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## å¯åŠ¨è„šæœ¬

æ‚¨ç°åœ¨å‡†å¤‡å¥½å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€

å¯¹äºæœ¬æŒ‡å—ï¼Œæ‚¨å°†ä¸‹è½½ä¸€äº›[ç‹—çš„å›¾ç‰‡](https://huggingface.co/datasets/diffusers/dog-example)çš„å›¾åƒå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªç›®å½•ä¸­ã€‚ä½†è¯·è®°ä½ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦åˆ›å»ºå’Œä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼ˆè¯·å‚é˜…[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼‰ã€‚

```py
from huggingface_hub import snapshot_download

local_dir = "./dog"
snapshot_download(
    "diffusers/dog-example",
    local_dir=local_dir,
    repo_type="dataset",
    ignore_patterns=".gitattributes",
)
```

è®¾ç½®ç¯å¢ƒå˜é‡ `MODEL_NAME` ä¸º Hub ä¸Šçš„æ¨¡å‹ ID æˆ–æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œ`INSTANCE_DIR` ä¸ºæ‚¨åˆšåˆšä¸‹è½½ç‹—å›¾åƒçš„è·¯å¾„ï¼Œ`OUTPUT_DIR` ä¸ºæ‚¨æƒ³ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚æ‚¨å°†ä½¿ç”¨ `sks` ä½œä¸ºç‰¹æ®Šè¯æ¥ç»‘å®šè®­ç»ƒã€‚

å¦‚æœæ‚¨æœ‰å…´è¶£è·Ÿéšè®­ç»ƒè¿‡ç¨‹ï¼Œå¯ä»¥å®šæœŸä¿å­˜ç”Ÿæˆçš„å›¾åƒä½œä¸ºè®­ç»ƒè¿›åº¦ã€‚å°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```bash
--validation_prompt="a photo of a sks dog"
--num_validation_images=4
--validation_steps=100
```

åœ¨å¯åŠ¨è„šæœ¬ä¹‹å‰ï¼Œè¿˜æœ‰ä¸€ä»¶äº‹ï¼æ ¹æ®æ‚¨æ‹¥æœ‰çš„ GPUï¼Œæ‚¨å¯èƒ½éœ€è¦å¯ç”¨æŸäº›ä¼˜åŒ–æ¥è®­ç»ƒ DreamBoothã€‚

<hfoptions id="gpu-select">
<hfoption id="16GB">

åœ¨ 16GB GPU ä¸Šï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ bitsandbytes 8 ä½ä¼˜åŒ–å™¨å’Œæ¢¯åº¦æ£€æŸ¥ç‚¹æ¥å¸®åŠ©è®­ç»ƒ DreamBooth æ¨¡å‹ã€‚å®‰è£… bitsandbytesï¼š

```py
pip install bitsandbytes
```

ç„¶åï¼Œå°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°æ‚¨çš„è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```bash
accelerate launch train_dreambooth.py \
  --gradient_checkpointing \
  --use_8bit_adam \
```

</hfoption>
<hfoption id="12GB">

åœ¨ 12GB GPU ä¸Šï¼Œæ‚¨éœ€è¦ bitsandbytes 8 ä½ä¼˜åŒ–å™¨ã€æ¢¯åº¦æ£€æŸ¥ç‚¹ã€xFormersï¼Œå¹¶å°†æ¢¯åº¦è®¾ç½®ä¸º `None` è€Œä¸æ˜¯é›¶ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ã€‚

```bash
accelerate launch train_dreambooth.py \
  --use_8bit_adam \
  --gradient_checkpointing \
  --enable_xformers_memory_efficient_attention \
  --set_grads_to_none \
```

</hfoption>
<hfoption id="8GB">

åœ¨ 8GB GPU ä¸Šï¼Œæ‚¨éœ€è¦ [DeepSpeed](https://www.deepspeed.ai/) å°†ä¸€äº›å¼ é‡ä» vRAM å¸è½½åˆ° CPU æˆ– NVMEï¼Œä»¥ä¾¿åœ¨æ›´å°‘çš„ GPU å†…å­˜ä¸‹è¿›è¡Œè®­ç»ƒã€‚

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥é…ç½®æ‚¨çš„ ğŸ¤— Accelerate ç¯å¢ƒï¼š

```bash
accelerate config
```

åœ¨é…ç½®è¿‡ç¨‹ä¸­ï¼Œç¡®è®¤æ‚¨æƒ³ä½¿ç”¨ DeepSpeedã€‚ç°åœ¨ï¼Œé€šè¿‡ç»“åˆ DeepSpeed é˜¶æ®µ 2ã€fp16 æ··åˆç²¾åº¦ä»¥åŠå°†æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ° CPUï¼Œåº”è¯¥å¯ä»¥åœ¨ä½äº 8GB vRAM çš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒã€‚ç¼ºç‚¹æ˜¯è¿™éœ€è¦æ›´å¤šçš„ç³»ç»Ÿ RAMï¼ˆçº¦ 25 GBï¼‰ã€‚æœ‰å…³æ›´å¤šé…ç½®é€‰é¡¹ï¼Œè¯·å‚é˜… [DeepSpeed æ–‡æ¡£](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)ã€‚

æ‚¨è¿˜åº”å°†é»˜è®¤çš„ Adam ä¼˜åŒ–å™¨æ›´æ”¹ä¸º DeepSpeed çš„ä¼˜åŒ–ç‰ˆæœ¬ [`deepspeed.ops.adam.DeepSpeedCPUAdam`](https://deepspeed.readthedocs.io/en/latest/optimizers.html#adam-cpu) ä»¥è·å¾—æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚å¯ç”¨ `DeepSpeedCPUAdam` è¦æ±‚æ‚¨çš„ç³»ç»Ÿ CUDA å·¥å…·é“¾ç‰ˆæœ¬ä¸ PyTorch å®‰è£…çš„ç‰ˆæœ¬ç›¸åŒã€‚

ç›®å‰ï¼Œbitsandbytes 8 ä½ä¼˜åŒ–å™¨ä¼¼ä¹ä¸ DeepSpeed ä¸å…¼å®¹ã€‚

å°±æ˜¯è¿™æ ·ï¼æ‚¨ä¸éœ€è¦å‘è®­ç»ƒå‘½ä»¤æ·»åŠ ä»»ä½•é¢å¤–å‚æ•°ã€‚

</hfoption>
</hfoptions>

<hfoptions id="training-inference">
<hfoption id="PyTorch">

```bash
export MODEL_NAME="stable-diffusion-v1-5/stable-diffusion-v1-5"
export INSTANCE_DIR="./dog"
export OUTPUT_DIR="path_to_
saved_model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=400 \
  --push_to_hub
```

</hfoption>
<hfoption id="Flax">

```bash
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="./dog"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --learning_rate=5e-6 \
  --max_train_steps=400 \
  --push_to_hub
```

</hfoption>
</hfoptions>

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼

> [!TIP]
> ç­‰ä¸åŠåœ¨è®­ç»ƒå®Œæˆå‰å°±å°è¯•æ‚¨çš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼ŸğŸ¤­ è¯·ç¡®ä¿å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ ğŸ¤— Accelerateã€‚
>
> ```py
> from diffusers import DiffusionPipeline, UNet2DConditionModel
> from transformers import CLIPTextModel
> import torch
>
> unet = UNet2DConditionModel.from_pretrained("path/to/model/checkpoint-100/unet")
>
> # å¦‚æœæ‚¨ä½¿ç”¨äº† `--args.train_text_encoder` è¿›è¡Œè®­ç»ƒï¼Œè¯·ç¡®ä¿ä¹ŸåŠ è½½æ–‡æœ¬ç¼–ç å™¨
> text_encoder = CLIPTextModel.from_pretrained("path/to/model/checkpoint-100/checkpoint-100/text_encoder")
>
> pipeline = DiffusionPipeline.from_pretrained(
>     "stable-diffusion-v1-5/stable-diffusion-v1-5", unet=unet, text_encoder=text_encoder, dtype=torch.float16,
> ).to("cuda")
>
> image = pipeline("A photo of sks dog in a bucket", num_inference_steps=50, guidance_scale=7.5).images[0]
> image.save("dog-bucket.png")
> ```

<hfoptions id="training-inference">
<hfoption id="PyTorch">

```py
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained("path_to_saved_model", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
image = pipeline("A photo of sks dog in a bucket", num_inference_steps=50, guidance_scale=7.5).images[0]
image.save("dog-bucket.png")
```

</hfoption>
<hfoption id="Flax">

```py
import jax
import numpy as np
from flax.jax_utils import replicate
from flax.training.common_utils import shard
from diffusers import FlaxStableDiffusionPipeline

pipeline, params = FlaxStableDiffusionPipeline.from_pretrained("path-to-your-trained-model", dtype=jax.numpy.bfloat16)

prompt = "A photo of sks dog in a bucket"
prng_seed = jax.random.PRNGKey(0)
num_inference_steps = 50

num_samples = jax.device_count()
prompt = num_samples * [prompt]
prompt_ids = pipeline.prepare_inputs(prompt)

# åˆ†ç‰‡è¾“å…¥å’Œéšæœºæ•°ç”Ÿæˆå™¨
params = replicate(params)
prng_seed = jax.random.split(prng_seed, jax.device_count())
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, params, prng_seed, num_inference_
steps, jit=True).images
images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
image.save("dog-bucket.png")
```

</hfoption>
</hfoptions>

## LoRA

LoRA æ˜¯ä¸€ç§è®­ç»ƒæŠ€æœ¯ï¼Œå¯æ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚å› æ­¤ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”æ›´å®¹æ˜“å­˜å‚¨ç”Ÿæˆçš„æƒé‡ï¼Œå› ä¸ºå®ƒä»¬å°å¾—å¤šï¼ˆçº¦ 100MBï¼‰ã€‚ä½¿ç”¨ [train_dreambooth_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py) è„šæœ¬é€šè¿‡ LoRA è¿›è¡Œè®­ç»ƒã€‚

LoRA è®­ç»ƒè„šæœ¬åœ¨ [LoRA è®­ç»ƒ](lora) æŒ‡å—ä¸­æœ‰æ›´è¯¦ç»†çš„è®¨è®ºã€‚

## Stable Diffusion XL

Stable Diffusion XL (SDXL) æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¹¶åœ¨å…¶æ¶æ„ä¸­æ·»åŠ äº†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚ä½¿ç”¨ [train_dreambooth_lora_sdxl.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora_sdxl.py) è„šæœ¬é€šè¿‡ LoRA è®­ç»ƒ SDXL æ¨¡å‹ã€‚

SDXL è®­ç»ƒè„šæœ¬åœ¨ [SDXL è®­ç»ƒ](sdxl) æŒ‡å—ä¸­æœ‰æ›´è¯¦ç»†çš„è®¨è®ºã€‚

## DeepFloyd IF

DeepFloyd IF æ˜¯ä¸€ä¸ªçº§è”åƒç´ æ‰©æ•£æ¨¡å‹ï¼ŒåŒ…å«ä¸‰ä¸ªé˜¶æ®µã€‚ç¬¬ä¸€é˜¶æ®µç”ŸæˆåŸºç¡€å›¾åƒï¼Œç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µé€æ­¥å°†åŸºç¡€å›¾åƒæ”¾å¤§ä¸ºé«˜åˆ†è¾¨ç‡ 1024x1024 å›¾åƒã€‚ä½¿ç”¨ [train_dreambooth_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py) æˆ– [train_dreambooth.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py) è„šæœ¬é€šè¿‡ LoRA æˆ–å®Œæ•´æ¨¡å‹è®­ç»ƒ DeepFloyd IF æ¨¡å‹ã€‚

DeepFloyd IF ä½¿ç”¨é¢„æµ‹æ–¹å·®ï¼Œä½† Diffusers è®­ç»ƒè„šæœ¬ä½¿ç”¨é¢„æµ‹è¯¯å·®ï¼Œå› æ­¤è®­ç»ƒçš„ DeepFloyd IF æ¨¡å‹è¢«åˆ‡æ¢åˆ°å›ºå®šæ–¹å·®è°ƒåº¦ã€‚è®­ç»ƒè„šæœ¬å°†ä¸ºæ‚¨æ›´æ–°å®Œå…¨è®­ç»ƒæ¨¡å‹çš„è°ƒåº¦å™¨é…ç½®ã€‚ä½†æ˜¯ï¼Œå½“æ‚¨åŠ è½½ä¿å­˜çš„ LoRA æƒé‡æ—¶ï¼Œè¿˜å¿…é¡»æ›´æ–°ç®¡é“çš„è°ƒåº¦å™¨é…ç½®ã€‚

```py
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", use_safetensors=True)

pipe.load_lora_weights("<lora weights path>")

# æ›´æ–°è°ƒåº¦å™¨é…ç½®ä¸ºå›ºå®šæ–¹å·®è°ƒåº¦
pipe.scheduler = pipe.scheduler.__class__.from_config(pipe.scheduler.config, variance_type="fixed_small")
```

ç¬¬äºŒé˜¶æ®µæ¨¡å‹éœ€è¦é¢å¤–çš„éªŒè¯å›¾åƒè¿›è¡Œæ”¾å¤§ã€‚æ‚¨å¯ä»¥ä¸‹è½½å¹¶ä½¿ç”¨è®­ç»ƒå›¾åƒçš„ç¼©å°ç‰ˆæœ¬ã€‚

```py
from huggingface_hub import snapshot_download

local_dir = "./dog_downsized"
snapshot_download(
    "diffusers/dog-example-downsized",
    local_dir=local_dir,
    repo_type="dataset",
    ignore_patterns=".gitattributes",
)
```

ä»¥ä¸‹ä»£ç ç¤ºä¾‹ç®€è¦æ¦‚è¿°äº†å¦‚ä½•ç»“åˆ DreamBooth å’Œ LoRA è®­ç»ƒ DeepFloyd IF æ¨¡å‹ã€‚ä¸€äº›éœ€è¦æ³¨æ„çš„é‡è¦å‚æ•°åŒ…æ‹¬ï¼š

* `--resolution=64`ï¼Œéœ€è¦æ›´å°çš„åˆ†è¾¨ç‡ï¼Œå› ä¸º DeepFloyd IF æ˜¯
ä¸€ä¸ªåƒç´ æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¤„ç†æœªå‹ç¼©çš„åƒç´ ï¼Œè¾“å…¥å›¾åƒå¿…é¡»æ›´å°
* `--pre_compute_text_embeddings`ï¼Œæå‰è®¡ç®—æ–‡æœ¬åµŒå…¥ä»¥èŠ‚çœå†…å­˜ï¼Œå› ä¸º [`~transformers.T5Model`] å¯èƒ½å ç”¨å¤§é‡å†…å­˜
* `--tokenizer_max_length=77`ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ›´é•¿çš„é»˜è®¤æ–‡æœ¬é•¿åº¦ä¸ T5 ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œä½†é»˜è®¤æ¨¡å‹ç¼–ç è¿‡ç¨‹ä½¿ç”¨è¾ƒçŸ­çš„æ–‡æœ¬é•¿åº¦
* `--text_encoder_use_attention_mask`ï¼Œå°†æ³¨æ„åŠ›æ©ç ä¼ é€’ç»™æ–‡æœ¬ç¼–ç å™¨

<hfoptions id="IF-DreamBooth">
<hfoption id="Stage 1 LoRA DreamBooth">

ä½¿ç”¨ LoRA å’Œ DreamBooth è®­ç»ƒ DeepFloyd IF çš„ç¬¬ 1 é˜¶æ®µéœ€è¦çº¦ 28GB å†…å­˜ã€‚

```bash
export MODEL_NAME="DeepFloyd/IF-I-XL-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth_dog_lora"

accelerate launch train_dreambooth_lora.py \
  --report_to wandb \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a sks dog" \
  --resolution=64 \
  --train_batch_size=4 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --scale_lr \
  --max_train_steps=1200 \
  --validation_prompt="a sks dog" \
  --validation_epochs=25 \
  --checkpointing_steps=100 \
  --pre_compute_text_embeddings \
  --tokenizer_max_length=77 \
  --text_encoder_use_attention_mask
```

</hfoption>
<hfoption id="Stage 2 LoRA DreamBooth">

å¯¹äºä½¿ç”¨ LoRA å’Œ DreamBooth çš„ DeepFloyd IF ç¬¬ 2 é˜¶æ®µï¼Œè¯·æ³¨æ„è¿™äº›å‚æ•°ï¼š

* `--validation_images`ï¼ŒéªŒè¯æœŸé—´ç”¨äºä¸Šé‡‡æ ·çš„å›¾åƒ
* `--class_labels_conditioning=timesteps`ï¼Œæ ¹æ®éœ€è¦é¢å¤–æ¡ä»¶åŒ– UNetï¼Œå¦‚ç¬¬ 2 é˜¶æ®µä¸­æ‰€éœ€
* `--learning_rate=1e-6`ï¼Œä¸ç¬¬ 1 é˜¶æ®µç›¸æ¯”ä½¿ç”¨è¾ƒä½çš„å­¦ä¹ ç‡
* `--resolution=256`ï¼Œä¸Šé‡‡æ ·å™¨çš„é¢„æœŸåˆ†è¾¨ç‡

```bash
export MODEL_NAME="DeepFloyd/IF-II-L-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth_dog_upscale"
export VALIDATION_IMAGES="dog_downsized/image_1.png dog_downsized/image_2.png dog_downsized/image_3.png dog_downsized/image_4.png"

python train_dreambooth_lora.py \
    --report_to wandb \
    --pretrained_model_name_or_path=$MODEL_NAME \
    --instance_data_dir=$INSTANCE_DIR \
    --output_dir=$OUTPUT_DIR \
    --instance_prompt="a sks dog" \
    --resolution=256 \
    --train_batch_size=4 \
    --gradient_accumulation_steps=1 \
    --learning_rate=1e-6 \
    --max_train_steps=2000 \
    --validation_prompt="a sks dog" \
    --validation_epochs=100 \
    --checkpointing_steps=500 \
    --pre_compute_text_embeddings \
    --tokenizer_max_length=77 \
    --text_encoder_use_attention_mask \
    --validation_images $VALIDATION_IMAGES \
    --class_labels_conditioning=timesteps
```

</hfoption>
<hfoption id="Stage 1 DreamBooth">

å¯¹äºä½¿ç”¨ DreamBooth çš„ DeepFloyd IF ç¬¬ 1 é˜¶æ®µï¼Œè¯·æ³¨æ„è¿™äº›å‚æ•°ï¼š

* `--skip_save_text_encoder`ï¼Œè·³è¿‡ä¿å­˜å®Œæ•´ T5 æ–‡æœ¬ç¼–ç å™¨ä¸å¾®è°ƒæ¨¡å‹
* `--use_8bit_adam`ï¼Œä½¿ç”¨ 8 ä½ Adam ä¼˜åŒ–å™¨ä»¥èŠ‚çœå†…å­˜ï¼Œå› ä¸º
     
ä¼˜åŒ–å™¨çŠ¶æ€çš„å¤§å°åœ¨è®­ç»ƒå®Œæ•´æ¨¡å‹æ—¶
* `--learning_rate=1e-7`ï¼Œå¯¹äºå®Œæ•´æ¨¡å‹è®­ç»ƒåº”ä½¿ç”¨éå¸¸ä½çš„å­¦ä¹ ç‡ï¼Œå¦åˆ™æ¨¡å‹è´¨é‡ä¼šä¸‹é™ï¼ˆæ‚¨å¯ä»¥ä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡å’Œæ›´å¤§çš„æ‰¹æ¬¡å¤§å°ï¼‰

ä½¿ç”¨8ä½Adamå’Œæ‰¹æ¬¡å¤§å°ä¸º4è¿›è¡Œè®­ç»ƒï¼Œå®Œæ•´æ¨¡å‹å¯ä»¥åœ¨çº¦48GBå†…å­˜ä¸‹è®­ç»ƒã€‚

```bash
export MODEL_NAME="DeepFloyd/IF-I-XL-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth_if"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=64 \
  --train_batch_size=4 \
  --gradient_accumulation_steps=1 \
  --learning_rate=1e-7 \
  --max_train_steps=150 \
  --validation_prompt "a photo of sks dog" \
  --validation_steps 25 \
  --text_encoder_use_attention_mask \
  --tokenizer_max_length 77 \
  --pre_compute_text_embeddings \
  --use_8bit_adam \
  --set_grads_to_none \
  --skip_save_text_encoder \
  --push_to_hub
```

</hfoption>
<hfoption id="Stage 2 DreamBooth">

å¯¹äºDeepFloyd IFçš„ç¬¬äºŒé˜¶æ®µDreamBoothï¼Œè¯·æ³¨æ„è¿™äº›å‚æ•°ï¼š

* `--learning_rate=5e-6`ï¼Œä½¿ç”¨è¾ƒä½çš„å­¦ä¹ ç‡å’Œè¾ƒå°çš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
* `--resolution=256`ï¼Œä¸Šé‡‡æ ·å™¨çš„é¢„æœŸåˆ†è¾¨ç‡
* `--train_batch_size=2` å’Œ `--gradient_accumulation_steps=6`ï¼Œä¸ºäº†æœ‰æ•ˆè®­ç»ƒåŒ…å«é¢éƒ¨çš„å›¾åƒï¼Œéœ€è¦æ›´å¤§çš„æ‰¹æ¬¡å¤§å°

```bash
export MODEL_NAME="DeepFloyd/IF-II-L-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth_dog_upscale"
export VALIDATION_IMAGES="dog_downsized/image_1.png dog_downsized/image_2.png dog_downsized/image_3.png dog_downsized/image_4.png"

accelerate launch train_dreambooth.py \
  --report_to wandb \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a sks dog" \
  --resolution=256 \
  --train_batch_size=2 \
  --gradient_accumulation_steps=6 \
  --learning_rate=5e-6 \
  --max_train_steps=2000 \
  --validation_prompt="a sks dog" \
  --validation_steps=150 \
  --checkpointing_steps=500 \
  --pre_compute_text_embeddings \
  --tokenizer_max_length=77 \
  --text_encoder_use_attention_mask \
  --validation_images $VALIDATION_IMAGES \
  --class_labels_conditioning timesteps \
  --push_to_hub
```

</hfoption>
</hfoptions>

### è®­ç»ƒæŠ€å·§

è®­ç»ƒDeepFloyd IFæ¨¡å‹å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä½†ä»¥ä¸‹æ˜¯æˆ‘ä»¬å‘ç°æœ‰ç”¨çš„æŠ€å·§ï¼š

- LoRAå¯¹äºè®­ç»ƒç¬¬ä¸€é˜¶æ®µæ¨¡å‹å·²è¶³å¤Ÿï¼Œå› ä¸ºæ¨¡å‹çš„ä½åˆ†è¾¨ç‡ä½¿å¾—è¡¨ç¤ºæ›´ç²¾ç»†çš„ç»†èŠ‚å˜å¾—å›°éš¾ï¼Œæ— è®ºå¦‚ä½•ã€‚
- å¯¹äºå¸¸è§æˆ–ç®€å•çš„å¯¹è±¡ï¼Œæ‚¨ä¸ä¸€å®šéœ€è¦å¾®è°ƒä¸Šé‡‡æ ·å™¨ã€‚ç¡®ä¿ä¼ é€’ç»™ä¸Šé‡‡æ ·å™¨çš„æç¤ºè¢«è°ƒæ•´ä»¥ç§»é™¤å®ä¾‹æç¤ºä¸­çš„æ–°ä»¤ç‰Œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ç¬¬ä¸€é˜¶æ®µæç¤ºæ˜¯"a sks dog"ï¼Œé‚£ä¹ˆæ‚¨ç¬¬äºŒé˜¶æ®µçš„æç¤ºåº”è¯¥æ˜¯"a dog"ã€‚
- å¯¹äºæ›´ç²¾ç»†çš„ç»†èŠ‚ï¼Œå¦‚é¢éƒ¨ï¼Œå®Œå…¨è®­ç»ƒ
ä½¿ç”¨é˜¶æ®µ2ä¸Šé‡‡æ ·å™¨æ¯”ä½¿ç”¨LoRAè®­ç»ƒé˜¶æ®µ2æ¨¡å‹æ›´å¥½ã€‚ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°å’Œè¾ƒä½çš„å­¦ä¹ ç‡ä¹Ÿæœ‰å¸®åŠ©ã€‚
- åº”ä½¿ç”¨è¾ƒä½çš„å­¦ä¹ ç‡æ¥è®­ç»ƒé˜¶æ®µ2æ¨¡å‹ã€‚
- [`DDPMScheduler`] æ¯”è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨çš„DPMSolveræ•ˆæœæ›´å¥½ã€‚

## ä¸‹ä¸€æ­¥

æ­å–œæ‚¨è®­ç»ƒäº†æ‚¨çš„DreamBoothæ¨¡å‹ï¼è¦äº†è§£æ›´å¤šå…³äºå¦‚ä½•ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹çš„ä¿¡æ¯ï¼Œä»¥ä¸‹æŒ‡å—å¯èƒ½æœ‰æ‰€å¸®åŠ©ï¼š
- å¦‚æœæ‚¨ä½¿ç”¨LoRAè®­ç»ƒäº†æ‚¨çš„æ¨¡å‹ï¼Œè¯·å­¦ä¹ å¦‚ä½•[åŠ è½½DreamBooth](../using-diffusers/loading_adapters)æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚