<!--Copyright 2025 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# ControlNet

[ControlNet](https://hf.co/papers/2302.05543) æ˜¯ä¸€ç§åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„é€‚é…å™¨æ¶æ„ã€‚å®ƒé€šè¿‡é¢å¤–è¾“å…¥çš„æ¡ä»¶å›¾åƒï¼ˆå¦‚è¾¹ç¼˜æ£€æµ‹å›¾ã€æ·±åº¦å›¾ã€äººä½“å§¿æ€å›¾ç­‰ï¼‰ï¼Œå®ç°å¯¹ç”Ÿæˆå›¾åƒçš„ç²¾ç»†åŒ–æ§åˆ¶ã€‚

åœ¨æ˜¾å­˜æœ‰é™çš„GPUä¸Šè®­ç»ƒæ—¶ï¼Œå»ºè®®å¯ç”¨è®­ç»ƒå‘½ä»¤ä¸­çš„ `gradient_checkpointing`ï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰ã€`gradient_accumulation_steps`ï¼ˆæ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼‰å’Œ `mixed_precision`ï¼ˆæ··åˆç²¾åº¦ï¼‰å‚æ•°ã€‚è¿˜å¯ä½¿ç”¨ [xFormers](../optimization/xformers) çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨ã€‚è™½ç„¶JAX/Flaxè®­ç»ƒæ”¯æŒåœ¨TPUå’ŒGPUä¸Šé«˜æ•ˆè¿è¡Œï¼Œä½†ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹å’ŒxFormersã€‚è‹¥éœ€é€šè¿‡FlaxåŠ é€Ÿè®­ç»ƒï¼Œå»ºè®®ä½¿ç”¨æ˜¾å­˜å¤§äº30GBçš„GPUã€‚

æœ¬æŒ‡å—å°†è§£æ [train_controlnet.py](https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet.py) è®­ç»ƒè„šæœ¬ï¼Œå¸®åŠ©æ‚¨ç†è§£å…¶é€»è¾‘å¹¶é€‚é…è‡ªå®šä¹‰éœ€æ±‚ã€‚

è¿è¡Œè„šæœ¬å‰ï¼Œè¯·ç¡®ä¿ä»æºç å®‰è£…åº“ï¼š

```bash
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

ç„¶åè¿›å…¥åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹ç›®å½•ï¼Œå®‰è£…æ‰€éœ€ä¾èµ–ï¼š

<hfoptions id="installation">
<hfoption id="PyTorch">
```bash
cd examples/controlnet
pip install -r requirements.txt
```
</hfoption>
<hfoption id="Flax">

è‹¥å¯è®¿é—®TPUè®¾å¤‡ï¼ŒFlaxè®­ç»ƒè„šæœ¬å°†è¿è¡Œå¾—æ›´å¿«ï¼ä»¥ä¸‹æ˜¯åœ¨ [Google Cloud TPU VM](https://cloud.google.com/tpu/docs/run-calculation-jax) ä¸Šçš„é…ç½®æµç¨‹ã€‚åˆ›å»ºå•ä¸ªTPU v4-8è™šæ‹Ÿæœºå¹¶è¿æ¥ï¼š

```bash
ZONE=us-central2-b
TPU_TYPE=v4-8
VM_NAME=hg_flax

gcloud alpha compute tpus tpu-vm create $VM_NAME \
 --zone $ZONE \
 --accelerator-type $TPU_TYPE \
 --version  tpu-vm-v4-base

gcloud alpha compute tpus tpu-vm ssh $VM_NAME --zone $ZONE -- \
```

å®‰è£…JAX 0.4.5ï¼š

```bash
pip install "jax[tpu]==0.4.5" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html
```

ç„¶åå®‰è£…Flaxè„šæœ¬çš„ä¾èµ–ï¼š

```bash
cd examples/controlnet
pip install -r requirements_flax.txt
```

</hfoption>
</hfoptions>

> [!TIP]
> ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªæ”¯æŒå¤šGPU/TPUè®­ç»ƒå’Œæ··åˆç²¾åº¦çš„åº“ï¼Œå®ƒèƒ½æ ¹æ®ç¡¬ä»¶ç¯å¢ƒè‡ªåŠ¨é…ç½®è®­ç»ƒæ–¹æ¡ˆã€‚å‚é˜… ğŸ¤— Accelerate [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour) äº†è§£æ›´å¤šã€‚

åˆå§‹åŒ–ğŸ¤— Accelerateç¯å¢ƒï¼š

```bash
accelerate config
```

è‹¥è¦åˆ›å»ºé»˜è®¤é…ç½®ï¼ˆä¸è¿›è¡Œäº¤äº’å¼é€‰æ‹©ï¼‰ï¼š

```bash
accelerate config default
```

è‹¥ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼shellï¼ˆå¦‚notebookï¼‰ï¼Œå¯ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

æœ€åï¼Œå¦‚éœ€è®­ç»ƒè‡ªå®šä¹‰æ•°æ®é›†ï¼Œè¯·å‚é˜… [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset) æŒ‡å—äº†è§£æ•°æ®å‡†å¤‡æ–¹æ³•ã€‚

> [!TIP]
> ä¸‹æ–‡é‡ç‚¹è§£æè„šæœ¬ä¸­çš„å…³é”®æ¨¡å—ï¼Œä½†ä¸ä¼šè¦†ç›–æ‰€æœ‰å®ç°ç»†èŠ‚ã€‚å¦‚éœ€æ·±å…¥äº†è§£ï¼Œå»ºè®®ç›´æ¥é˜…è¯» [è„šæœ¬æºç ](https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet.py)ï¼Œå¦‚æœ‰ç–‘é—®æ¬¢è¿åé¦ˆã€‚

## è„šæœ¬å‚æ•°

è®­ç»ƒè„šæœ¬æä¾›äº†ä¸°å¯Œçš„å¯é…ç½®å‚æ•°ï¼Œæ‰€æœ‰å‚æ•°åŠå…¶è¯´æ˜è¯¦è§ [`parse_args()`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/controlnet/train_controlnet.py#L231) å‡½æ•°ã€‚è™½ç„¶è¯¥å‡½æ•°å·²ä¸ºæ¯ä¸ªå‚æ•°æä¾›é»˜è®¤å€¼ï¼ˆå¦‚è®­ç»ƒæ‰¹å¤§å°ã€å­¦ä¹ ç‡ç­‰ï¼‰ï¼Œä½†æ‚¨å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–è¿™äº›é»˜è®¤å€¼ã€‚

ä¾‹å¦‚ï¼Œä½¿ç”¨fp16æ··åˆç²¾åº¦åŠ é€Ÿè®­ç»ƒ, å¯ä½¿ç”¨`--mixed_precision`å‚æ•°

```bash
accelerate launch train_controlnet.py \
  --mixed_precision="fp16"
```

åŸºç¡€å‚æ•°è¯´æ˜å¯å‚è€ƒ [æ–‡ç”Ÿå›¾](text2image#script-parameters) è®­ç»ƒæŒ‡å—ï¼Œæ­¤å¤„é‡ç‚¹ä»‹ç»ControlNetç›¸å…³å‚æ•°ï¼š

- `--max_train_samples`: è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œå‡å°‘è¯¥å€¼å¯åŠ å¿«è®­ç»ƒï¼Œä½†å¯¹è¶…å¤§æ•°æ®é›†éœ€é…åˆ `--streaming` å‚æ•°ä½¿ç”¨
- `--gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œé€šè¿‡åˆ†æ­¥è®¡ç®—å®ç°æ˜¾å­˜å—é™æƒ…å†µä¸‹çš„æ›´å¤§æ‰¹æ¬¡è®­ç»ƒ

### Min-SNRåŠ æƒç­–ç•¥

[Min-SNR](https://huggingface.co/papers/2303.09556) åŠ æƒç­–ç•¥é€šè¿‡é‡æ–°å¹³è¡¡æŸå¤±å‡½æ•°åŠ é€Ÿæ¨¡å‹æ”¶æ•›ã€‚è™½ç„¶è®­ç»ƒè„šæœ¬æ”¯æŒé¢„æµ‹ `epsilon`ï¼ˆå™ªå£°ï¼‰æˆ– `v_prediction`ï¼Œä½†Min-SNRå¯¹ä¸¤ç§é¢„æµ‹ç±»å‹å‡å…¼å®¹ã€‚è¯¥ç­–ç•¥ä»…é€‚ç”¨äºPyTorchç‰ˆæœ¬ï¼ŒFlaxè®­ç»ƒè„šæœ¬æš‚ä¸æ”¯æŒã€‚

æ¨èå€¼è®¾ä¸º5.0ï¼š

```bash
accelerate launch train_controlnet.py \
  --snr_gamma=5.0
```

## è®­ç»ƒè„šæœ¬

ä¸å‚æ•°è¯´æ˜ç±»ä¼¼ï¼Œè®­ç»ƒæµç¨‹çš„é€šç”¨è§£æå¯å‚è€ƒ [æ–‡ç”Ÿå›¾](text2image#training-script) æŒ‡å—ã€‚æ­¤å¤„é‡ç‚¹åˆ†æControlNetç‰¹æœ‰çš„å®ç°ã€‚

è„šæœ¬ä¸­çš„ [`make_train_dataset`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/controlnet/train_controlnet.py#L582) å‡½æ•°è´Ÿè´£æ•°æ®é¢„å¤„ç†ï¼Œé™¤å¸¸è§„çš„æ–‡æœ¬æ ‡æ³¨åˆ†è¯å’Œå›¾åƒå˜æ¢å¤–ï¼Œè¿˜åŒ…å«æ¡ä»¶å›¾åƒçš„ç‰¹æ•ˆå¤„ç†ï¼š

> [!TIP]
> åœ¨TPUä¸Šæµå¼åŠ è½½æ•°æ®é›†æ—¶ï¼ŒğŸ¤— Datasetsåº“å¯èƒ½æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼ˆå› å…¶æœªé’ˆå¯¹å›¾åƒæ•°æ®ä¼˜åŒ–ï¼‰ã€‚å»ºè®®è€ƒè™‘ [WebDataset](https://webdataset.github.io/webdataset/)ã€[TorchData](https://github.com/pytorch/data) æˆ– [TensorFlow Datasets](https://www.tensorflow.org/datasets/tfless_tfds) ç­‰é«˜æ•ˆæ•°æ®æ ¼å¼ã€‚

```py
conditioning_image_transforms = transforms.Compose(
    [
        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),
        transforms.CenterCrop(args.resolution),
        transforms.ToTensor(),
    ]
)
```

åœ¨ [`main()`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/controlnet/train_controlnet.py#L713) å‡½æ•°ä¸­ï¼Œä»£ç ä¼šåŠ è½½åˆ†è¯å™¨ã€æ–‡æœ¬ç¼–ç å™¨ã€è°ƒåº¦å™¨å’Œæ¨¡å‹ã€‚æ­¤å¤„ä¹Ÿæ˜¯ControlNetæ¨¡å‹çš„åŠ è½½ç‚¹ï¼ˆæ”¯æŒä»ç°æœ‰æƒé‡åŠ è½½æˆ–ä»UNetéšæœºåˆå§‹åŒ–ï¼‰ï¼š

```py
if args.controlnet_model_name_or_path:
    logger.info("Loading existing controlnet weights")
    controlnet = ControlNetModel.from_pretrained(args.controlnet_model_name_or_path)
else:
    logger.info("Initializing controlnet weights from unet")
    controlnet = ControlNetModel.from_unet(unet)
```

[ä¼˜åŒ–å™¨](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/controlnet/train_controlnet.py#L871) ä¸“é—¨é’ˆå¯¹ControlNetå‚æ•°è¿›è¡Œæ›´æ–°ï¼š

```py
params_to_optimize = controlnet.parameters()
optimizer = optimizer_class(
    params_to_optimize,
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```

åœ¨ [è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/controlnet/train_controlnet.py#L943) ä¸­ï¼Œæ¡ä»¶æ–‡æœ¬åµŒå…¥å’Œå›¾åƒè¢«è¾“å…¥åˆ°ControlNetçš„ä¸‹é‡‡æ ·å’Œä¸­å±‚æ¨¡å—ï¼š

```py
encoder_hidden_states = text_encoder(batch["input_ids"])[0]
controlnet_image = batch["conditioning_pixel_values"].to(dtype=weight_dtype)

down_block_res_samples, mid_block_res_sample = controlnet(
    noisy_latents,
    timesteps,
    encoder_hidden_states=encoder_hidden_states,
    controlnet_cond=controlnet_image,
    return_dict=False,
)
```

è‹¥æƒ³æ·±å…¥ç†è§£è®­ç»ƒå¾ªç¯æœºåˆ¶ï¼Œå¯å‚é˜… [ç†è§£ç®¡é“ã€æ¨¡å‹ä¸è°ƒåº¦å™¨](../using-diffusers/write_own_pipeline) æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è¯¦ç»†è§£æäº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬åŸç†ã€‚

## å¯åŠ¨è®­ç»ƒ

ç°åœ¨å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€

æœ¬æŒ‡å—ä½¿ç”¨ [fusing/fill50k](https://huggingface.co/datasets/fusing/fill50k) æ•°æ®é›†ï¼Œå½“ç„¶æ‚¨ä¹Ÿå¯ä»¥æŒ‰ç…§ [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset) æŒ‡å—å‡†å¤‡è‡ªå®šä¹‰æ•°æ®ã€‚

è®¾ç½®ç¯å¢ƒå˜é‡ `MODEL_NAME` ä¸ºHubæ¨¡å‹IDæˆ–æœ¬åœ°è·¯å¾„ï¼Œ`OUTPUT_DIR` ä¸ºæ¨¡å‹ä¿å­˜è·¯å¾„ã€‚

ä¸‹è½½è®­ç»ƒç”¨çš„æ¡ä»¶å›¾åƒï¼š

```bash
wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png
wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png
```

æ ¹æ®GPUå‹å·ï¼Œå¯èƒ½éœ€è¦å¯ç”¨ç‰¹å®šä¼˜åŒ–ã€‚é»˜è®¤é…ç½®éœ€è¦çº¦38GBæ˜¾å­˜ã€‚è‹¥ä½¿ç”¨å¤šGPUè®­ç»ƒï¼Œè¯·åœ¨ `accelerate launch` å‘½ä»¤ä¸­æ·»åŠ  `--multi_gpu` å‚æ•°ã€‚

<hfoptions id="gpu-select">
<hfoption id="16GB">

16GBæ˜¾å¡å¯ä½¿ç”¨bitsandbytes 8-bitä¼˜åŒ–å™¨å’Œæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼š

```py
pip install bitsandbytes
```

è®­ç»ƒå‘½ä»¤æ·»åŠ ä»¥ä¸‹å‚æ•°ï¼š

```bash
accelerate launch train_controlnet.py \
  --gradient_checkpointing \
  --use_8bit_adam \
```

</hfoption>
<hfoption id="12GB">

12GBæ˜¾å¡éœ€ç»„åˆä½¿ç”¨bitsandbytes 8-bitä¼˜åŒ–å™¨ã€æ¢¯åº¦æ£€æŸ¥ç‚¹ã€xFormersï¼Œå¹¶å°†æ¢¯åº¦ç½®ä¸ºNoneè€Œé0ï¼š

```bash
accelerate launch train_controlnet.py \
  --use_8bit_adam \
  --gradient_checkpointing \
  --enable_xformers_memory_efficient_attention \
  --set_grads_to_none \
```

</hfoption>
<hfoption id="8GB">

8GBæ˜¾å¡éœ€ä½¿ç”¨ [DeepSpeed](https://www.deepspeed.ai/) å°†å¼ é‡å¸è½½åˆ°CPUæˆ–NVMEï¼š

è¿è¡Œä»¥ä¸‹å‘½ä»¤é…ç½®ç¯å¢ƒï¼š

```bash
accelerate config
```

é€‰æ‹©DeepSpeed stage 2ï¼Œç»“åˆfp16æ··åˆç²¾åº¦å’Œå‚æ•°å¸è½½åˆ°CPUçš„æ–¹æ¡ˆã€‚æ³¨æ„è¿™ä¼šå¢åŠ çº¦25GBå†…å­˜å ç”¨ã€‚é…ç½®ç¤ºä¾‹å¦‚ä¸‹ï¼š

```bash
compute_environment: LOCAL_MACHINE
deepspeed_config:
  gradient_accumulation_steps: 4
  offload_optimizer_device: cpu
  offload_param_device: cpu
  zero3_init_flag: false
  zero_stage: 2
distributed_type: DEEPSPEED
```

å»ºè®®å°†ä¼˜åŒ–å™¨æ›¿æ¢ä¸ºDeepSpeedç‰¹åŒ–ç‰ˆ [`deepspeed.ops.adam.DeepSpeedCPUAdam`](https://deepspeed.readthedocs.io/en/latest/optimizers.html#adam-cpu)ï¼Œæ³¨æ„CUDAå·¥å…·é“¾ç‰ˆæœ¬éœ€ä¸PyTorchåŒ¹é…ã€‚

å½“å‰bitsandbytesä¸DeepSpeedå­˜åœ¨å…¼å®¹æ€§é—®é¢˜ã€‚

æ— éœ€é¢å¤–æ·»åŠ è®­ç»ƒå‚æ•°ã€‚

</hfoption>
</hfoptions>

<hfoptions id="training-inference">
<hfoption id="PyTorch">

```bash
export MODEL_DIR="stable-diffusion-v1-5/stable-diffusion-v1-5"
export OUTPUT_DIR="path/to/save/model"

accelerate launch train_controlnet.py \
 --pretrained_model_name_or_path=$MODEL_DIR \
 --output_dir=$OUTPUT_DIR \
 --dataset_name=fusing/fill50k \
 --resolution=512 \
 --learning_rate=1e-5 \
 --validation_image "./conditioning_image_1.png" "./conditioning_image_2.png" \
 --validation_prompt "red circle with blue background" "cyan circle with brown floral background" \
 --train_batch_size=1 \
 --gradient_accumulation_steps=4 \
 --push_to_hub
```

</hfoption>
<hfoption id="Flax">

Flaxç‰ˆæœ¬æ”¯æŒé€šè¿‡ `--profile_steps==5` å‚æ•°è¿›è¡Œæ€§èƒ½åˆ†æï¼š

```bash
pip install tensorflow tensorboard-plugin-profile
tensorboard --logdir runs/fill-circle-100steps-20230411_165612/
```

åœ¨ [http://localhost:6006/#profile](http://localhost:6006/#profile) æŸ¥çœ‹åˆ†æç»“æœã€‚

> [!WARNING]
> è‹¥é‡åˆ°æ’ä»¶ç‰ˆæœ¬å†²çªï¼Œå»ºè®®é‡æ–°å®‰è£…TensorFlowå’ŒTensorboardã€‚æ³¨æ„æ€§èƒ½åˆ†ææ’ä»¶ä»å¤„å®éªŒé˜¶æ®µï¼Œéƒ¨åˆ†è§†å›¾å¯èƒ½ä¸å®Œæ•´ã€‚`trace_viewer` ä¼šæˆªæ–­è¶…è¿‡1Mçš„äº‹ä»¶è®°å½•ï¼Œåœ¨ç¼–è¯‘æ­¥éª¤åˆ†ææ—¶å¯èƒ½å¯¼è‡´è®¾å¤‡è½¨è¿¹ä¸¢å¤±ã€‚

```bash
python3 train_controlnet_flax.py \
 --pretrained_model_name_or_path=$MODEL_DIR \
 --output_dir=$OUTPUT_DIR \
 --dataset_name=fusing/fill50k \
 --resolution=512 \
 --learning_rate=1e-5 \
 --validation_image "./conditioning_image_1.png" "./conditioning_image_2.png" \
 --validation_prompt "red circle with blue background" "cyan circle with brown floral background" \
 --validation_steps=1000 \
 --train_batch_size=2 \
 --revision="non-ema" \
 --from_pt \
 --report_to="wandb" \
 --tracker_project_name=$HUB_MODEL_ID \
 --num_train_epochs=11 \
 --push_to_hub \
 --hub_model_id=$HUB_MODEL_ID
```

</hfoption>
</hfoptions>

è®­ç»ƒå®Œæˆåå³å¯è¿›è¡Œæ¨ç†ï¼š

```py
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from diffusers.utils import load_image
import torch

controlnet = ControlNetModel.from_pretrained("path/to/controlnet", torch_dtype=torch.float16)
pipeline = StableDiffusionControlNetPipeline.from_pretrained(
    "path/to/base/model", controlnet=controlnet, torch_dtype=torch.float16
).to("cuda")

control_image = load_image("./conditioning_image_1.png")
prompt = "pale golden rod circle with old lace background"

generator = torch.manual_seed(0)
image = pipeline(prompt, num_inference_steps=20, generator=generator, image=control_image).images[0]
image.save("./output.png")
```

## Stable Diffusion XL

Stable Diffusion XL (SDXL) æ˜¯æ–°ä¸€ä»£æ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œé€šè¿‡æ·»åŠ ç¬¬äºŒæ–‡æœ¬ç¼–ç å™¨æ”¯æŒç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡å›¾åƒã€‚ä½¿ç”¨ [`train_controlnet_sdxl.py`](https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet_sdxl.py) è„šæœ¬å¯ä¸ºSDXLè®­ç»ƒControlNeté€‚é…å™¨ã€‚

SDXLè®­ç»ƒè„šæœ¬çš„è¯¦ç»†è§£æè¯·å‚é˜… [SDXLè®­ç»ƒ](sdxl) æŒ‡å—ã€‚

## åç»­æ­¥éª¤

æ­å–œå®ŒæˆControlNetè®­ç»ƒï¼å¦‚éœ€è¿›ä¸€æ­¥äº†è§£æ¨¡å‹åº”ç”¨ï¼Œä»¥ä¸‹æŒ‡å—å¯èƒ½æœ‰æ‰€å¸®åŠ©ï¼š

- å­¦ä¹ å¦‚ä½• [ä½¿ç”¨ControlNet](../using-diffusers/controlnet) è¿›è¡Œå¤šæ ·åŒ–ä»»åŠ¡çš„æ¨ç†
