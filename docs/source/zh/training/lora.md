<!--Copyright 2025 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# LoRA ä½ç§©é€‚é…

> [!WARNING]
> å½“å‰åŠŸèƒ½å¤„äºå®éªŒé˜¶æ®µï¼ŒAPIå¯èƒ½åœ¨æœªæ¥ç‰ˆæœ¬ä¸­å˜æ›´ã€‚

[LoRAï¼ˆå¤§è¯­è¨€æ¨¡å‹çš„ä½ç§©é€‚é…ï¼‰](https://hf.co/papers/2106.09685) æ˜¯ä¸€ç§è½»é‡çº§è®­ç»ƒæŠ€æœ¯ï¼Œèƒ½æ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°é‡ã€‚å…¶åŸç†æ˜¯é€šè¿‡å‘æ¨¡å‹æ³¨å…¥å°‘é‡æ–°æƒé‡å‚æ•°ï¼Œä»…è®­ç»ƒè¿™äº›æ–°å¢å‚æ•°ã€‚è¿™ä½¿å¾—LoRAè®­ç»ƒé€Ÿåº¦æ›´å¿«ã€å†…å­˜æ•ˆç‡æ›´é«˜ï¼Œå¹¶ç”Ÿæˆæ›´å°çš„æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆé€šå¸¸ä»…æ•°ç™¾MBï¼‰ï¼Œä¾¿äºå­˜å‚¨å’Œåˆ†äº«ã€‚LoRAè¿˜å¯ä¸DreamBoothç­‰å…¶ä»–è®­ç»ƒæŠ€æœ¯ç»“åˆä»¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚

> [!TIP]
> LoRAå…·æœ‰é«˜åº¦é€šç”¨æ€§ï¼Œç›®å‰å·²æ”¯æŒä»¥ä¸‹åº”ç”¨åœºæ™¯ï¼š[DreamBooth](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py)ã€[Kandinsky 2.2](https://github.com/huggingface/diffusers/blob/main/examples/kandinsky2_2/text_to_image/train_text_to_image_lora_decoder.py)ã€[Stable Diffusion XL](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora_sdxl.py)ã€[æ–‡ç”Ÿå›¾](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)ä»¥åŠ[Wuerstchen](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_lora_prior.py)ã€‚

æœ¬æŒ‡å—å°†é€šè¿‡è§£æ[train_text_to_image_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)è„šæœ¬ï¼Œå¸®åŠ©æ‚¨æ·±å…¥ç†è§£å…¶å·¥ä½œåŸç†ï¼Œå¹¶æŒæ¡å¦‚ä½•é’ˆå¯¹å…·ä½“éœ€æ±‚è¿›è¡Œå®šåˆ¶åŒ–ä¿®æ”¹ã€‚

è¿è¡Œè„šæœ¬å‰ï¼Œè¯·ç¡®ä¿ä»æºç å®‰è£…åº“ï¼š

```bash
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

è¿›å…¥åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹ç›®å½•ï¼Œå¹¶å®‰è£…æ‰€éœ€ä¾èµ–ï¼š

<hfoptions id="installation">
<hfoption id="PyTorch">

```bash
cd examples/text_to_image
pip install -r requirements.txt
```

</hfoption>
<hfoption id="Flax">

```bash
cd examples/text_to_image
pip install -r requirements_flax.txt
```

</hfoption>
</hfoptions>

> [!TIP]
> ğŸ¤— Accelerateæ˜¯ä¸€ä¸ªæ”¯æŒå¤šGPU/TPUè®­ç»ƒå’Œæ··åˆç²¾åº¦è®¡ç®—çš„åº“ï¼Œå®ƒèƒ½æ ¹æ®ç¡¬ä»¶ç¯å¢ƒè‡ªåŠ¨é…ç½®è®­ç»ƒæ–¹æ¡ˆã€‚å‚é˜…ğŸ¤— Accelerate[å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)äº†è§£æ›´å¤šã€‚

åˆå§‹åŒ–ğŸ¤— Accelerateç¯å¢ƒï¼š

```bash
accelerate config
```

è‹¥è¦åˆ›å»ºé»˜è®¤é…ç½®ç¯å¢ƒï¼ˆä¸è¿›è¡Œäº¤äº’å¼è®¾ç½®ï¼‰ï¼š

```bash
accelerate config default
```

è‹¥åœ¨éäº¤äº’ç¯å¢ƒï¼ˆå¦‚Jupyter notebookï¼‰ä¸­ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

å¦‚éœ€è®­ç»ƒè‡ªå®šä¹‰æ•°æ®é›†ï¼Œè¯·å‚è€ƒ[åˆ›å»ºè®­ç»ƒæ•°æ®é›†æŒ‡å—](create_dataset)äº†è§£æ•°æ®å‡†å¤‡æµç¨‹ã€‚

> [!TIP]
> ä»¥ä¸‹ç« èŠ‚é‡ç‚¹è§£æè®­ç»ƒè„šæœ¬ä¸­ä¸LoRAç›¸å…³çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œä½†ä¸ä¼šæ¶µç›–æ‰€æœ‰å®ç°ç»†èŠ‚ã€‚å¦‚éœ€å®Œæ•´ç†è§£ï¼Œå»ºè®®ç›´æ¥é˜…è¯»[è„šæœ¬æºç ](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)ï¼Œå¦‚æœ‰ç–‘é—®æ¬¢è¿åé¦ˆã€‚

## è„šæœ¬å‚æ•°

è®­ç»ƒè„šæœ¬æä¾›ä¼—å¤šå‚æ•°ç”¨äºå®šåˆ¶è®­ç»ƒè¿‡ç¨‹ã€‚æ‰€æœ‰å‚æ•°åŠå…¶è¯´æ˜å‡å®šä¹‰åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L85)å‡½æ•°ä¸­ã€‚å¤šæ•°å‚æ•°è®¾æœ‰é»˜è®¤å€¼ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ï¼š

ä¾‹å¦‚å¢åŠ è®­ç»ƒè½®æ¬¡ï¼š

```bash
accelerate launch train_text_to_image_lora.py \
  --num_train_epochs=150 \
```

åŸºç¡€å‚æ•°è¯´æ˜å¯å‚è€ƒ[æ–‡ç”Ÿå›¾è®­ç»ƒæŒ‡å—](text2image#script-parameters)ï¼Œæ­¤å¤„é‡ç‚¹ä»‹ç»LoRAç›¸å…³å‚æ•°ï¼š

- `--rank`ï¼šä½ç§©çŸ©é˜µçš„å†…éƒ¨ç»´åº¦ï¼Œæ•°å€¼è¶Šé«˜å¯è®­ç»ƒå‚æ•°è¶Šå¤š
- `--learning_rate`ï¼šé»˜è®¤å­¦ä¹ ç‡ä¸º1e-4ï¼Œä½†ä½¿ç”¨LoRAæ—¶å¯é€‚å½“æé«˜

## è®­ç»ƒè„šæœ¬å®ç°

æ•°æ®é›†é¢„å¤„ç†å’Œè®­ç»ƒå¾ªç¯é€»è¾‘ä½äº[`main()`](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L371)å‡½æ•°ï¼Œå¦‚éœ€å®šåˆ¶è®­ç»ƒæµç¨‹ï¼Œå¯åœ¨æ­¤å¤„è¿›è¡Œä¿®æ”¹ã€‚

ä¸å‚æ•°è¯´æ˜ç±»ä¼¼ï¼Œè®­ç»ƒæµç¨‹çš„å®Œæ•´è§£æè¯·å‚è€ƒ[æ–‡ç”Ÿå›¾æŒ‡å—](text2image#training-script)ï¼Œä¸‹æ–‡é‡ç‚¹ä»‹ç»LoRAç›¸å…³å®ç°ã€‚

<hfoptions id="lora">
<hfoption id="UNet">

Diffusersä½¿ç”¨[PEFT](https://hf.co/docs/peft)åº“çš„[`~peft.LoraConfig`]é…ç½®LoRAé€‚é…å™¨å‚æ•°ï¼ŒåŒ…æ‹¬ç§©(rank)ã€alphaå€¼ä»¥åŠç›®æ ‡æ¨¡å—ã€‚é€‚é…å™¨è¢«æ³¨å…¥UNetåï¼Œé€šè¿‡`lora_layers`ç­›é€‰å‡ºéœ€è¦ä¼˜åŒ–çš„LoRAå±‚ã€‚

```py
unet_lora_config = LoraConfig(
    r=args.rank,
    lora_alpha=args.rank,
    init_lora_weights="gaussian",
    target_modules=["to_k", "to_q", "to_v", "to_out.0"],
)

unet.add_adapter(unet_lora_config)
lora_layers = filter(lambda p: p.requires_grad, unet.parameters())
```

</hfoption>
<hfoption id="text encoder">

å½“éœ€è¦å¾®è°ƒæ–‡æœ¬ç¼–ç å™¨æ—¶ï¼ˆå¦‚SDXLæ¨¡å‹ï¼‰ï¼ŒDiffusersåŒæ ·æ”¯æŒé€šè¿‡[PEFT](https://hf.co/docs/peft)åº“å®ç°ã€‚[`~peft.LoraConfig`]é…ç½®é€‚é…å™¨å‚æ•°åæ³¨å…¥æ–‡æœ¬ç¼–ç å™¨ï¼Œå¹¶ç­›é€‰LoRAå±‚è¿›è¡Œè®­ç»ƒã€‚

```py
text_lora_config = LoraConfig(
    r=args.rank,
    lora_alpha=args.rank,
    init_lora_weights="gaussian",
    target_modules=["q_proj", "k_proj", "v_proj", "out_proj"],
)

text_encoder_one.add_adapter(text_lora_config)
text_encoder_two.add_adapter(text_lora_config)
text_lora_parameters_one = list(filter(lambda p: p.requires_grad, text_encoder_one.parameters()))
text_lora_parameters_two = list(filter(lambda p: p.requires_grad, text_encoder_two.parameters()))
```

</hfoption>
</hfoptions>

[ä¼˜åŒ–å™¨](https://github.com/huggingface/diffusers/blob/e4b8f173b97731686e290b2eb98e7f5df2b1b322/examples/text_to_image/train_text_to_image_lora.py#L529)ä»…å¯¹`lora_layers`å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼š

```py
optimizer = optimizer_cls(
    lora_layers,
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```

é™¤LoRAå±‚è®¾ç½®å¤–ï¼Œè¯¥è®­ç»ƒè„šæœ¬ä¸æ ‡å‡†train_text_to_image.pyåŸºæœ¬ç›¸åŒï¼

## å¯åŠ¨è®­ç»ƒ

å®Œæˆæ‰€æœ‰é…ç½®åï¼Œå³å¯å¯åŠ¨è®­ç»ƒè„šæœ¬ï¼ğŸš€

ä»¥ä¸‹ç¤ºä¾‹ä½¿ç”¨[Naruto BLIP captions](https://huggingface.co/datasets/lambdalabs/naruto-blip-captions)è®­ç»ƒç”Ÿæˆç«å½±è§’è‰²ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡`MODEL_NAME`å’Œ`DATASET_NAME`æŒ‡å®šåŸºç¡€æ¨¡å‹å’Œæ•°æ®é›†ï¼Œ`OUTPUT_DIR`è®¾ç½®è¾“å‡ºç›®å½•ï¼Œ`HUB_MODEL_ID`æŒ‡å®šHubå­˜å‚¨åº“åç§°ã€‚è„šæœ¬è¿è¡Œåå°†ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

- æ¨¡å‹æ£€æŸ¥ç‚¹
- `pytorch_lora_weights.safetensors`ï¼ˆè®­ç»ƒå¥½çš„LoRAæƒé‡ï¼‰

å¤šGPUè®­ç»ƒè¯·æ·»åŠ `--multi_gpu`å‚æ•°ã€‚

> [!WARNING]
> åœ¨11GBæ˜¾å­˜çš„2080 Tiæ˜¾å¡ä¸Šå®Œæ•´è®­ç»ƒçº¦éœ€5å°æ—¶ã€‚

```bash
export MODEL_NAME="stable-diffusion-v1-5/stable-diffusion-v1-5"
export OUTPUT_DIR="/sddata/finetune/lora/naruto"
export HUB_MODEL_ID="naruto-lora"
export DATASET_NAME="lambdalabs/naruto-blip-captions"

accelerate launch --mixed_precision="fp16"  train_text_to_image_lora.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$DATASET_NAME \
  --dataloader_num_workers=8 \
  --resolution=512 \
  --center_crop \
  --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --max_train_steps=15000 \
  --learning_rate=1e-04 \
  --max_grad_norm=1 \
  --lr_scheduler="cosine" \
  --lr_warmup_steps=0 \
  --output_dir=${OUTPUT_DIR} \
  --push_to_hub \
  --hub_model_id=${HUB_MODEL_ID} \
  --report_to=wandb \
  --checkpointing_steps=500 \
  --validation_prompt="è“è‰²çœ¼ç›çš„ç«å½±å¿è€…è§’è‰²" \
  --seed=1337
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›è¡Œæ¨ç†ï¼š

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", torch_dtype=torch.float16).to("cuda")
pipeline.load_lora_weights("path/to/lora/model", weight_name="pytorch_lora_weights.safetensors")
image = pipeline("A naruto with blue eyes").images[0]
```

## åç»­æ­¥éª¤

æ­å–œå®ŒæˆLoRAæ¨¡å‹è®­ç»ƒï¼å¦‚éœ€è¿›ä¸€æ­¥äº†è§£æ¨¡å‹ä½¿ç”¨æ–¹æ³•ï¼Œå¯å‚è€ƒä»¥ä¸‹æŒ‡å—ï¼š

- å­¦ä¹ å¦‚ä½•åŠ è½½[ä¸åŒæ ¼å¼çš„LoRAæƒé‡](../using-diffusers/loading_adapters#LoRA)ï¼ˆå¦‚Kohyaæˆ–TheLastBenè®­ç»ƒçš„æ¨¡å‹ï¼‰
- æŒæ¡ä½¿ç”¨PEFTè¿›è¡Œ[å¤šLoRAç»„åˆæ¨ç†](../tutorials/using_peft_for_inference)çš„æŠ€å·§